@online{2021NianDuGuoJiaLaoLingShiYeFaZhanGongBao,
  title = {2021年度国家老龄事业发展公报},
  url = {http://www.nhc.gov.cn/cms-search/xxgk/getManuscriptXxgk.htm?id=e09f046ab8f14967b19c3cb5c1d934b5},
  urldate = {2023-12-05},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/IIKGE67K/getManuscriptXxgk.html}
}

@article{abbassTrustedAutonomyCognitive2016,
  title = {Trusted {{Autonomy}} and {{Cognitive Cyber Symbiosis}}: {{Open Challenges}}},
  shorttitle = {Trusted {{Autonomy}} and {{Cognitive Cyber Symbiosis}}},
  author = {Abbass, Hussein A. and Petraki, Eleni and Merrick, Kathryn and Harvey, John and Barlow, Michael},
  date = {2016-06},
  journaltitle = {Cognitive Computation},
  shortjournal = {Cogn Comput},
  volume = {8},
  number = {3},
  pages = {385--408},
  issn = {1866-9956, 1866-9964},
  doi = {10.1007/s12559-015-9365-5},
  url = {http://link.springer.com/10.1007/s12559-015-9365-5},
  urldate = {2024-01-16},
  abstract = {This paper considers two emerging interdisciplinary, but related topics that are likely to create tipping points in advancing the engineering and science areas. Trusted Autonomy (TA) is a field of research that focuses on understanding and designing the interaction space between two entities each of which exhibits a level of autonomy. These entities can be humans, machines, or a mix of the two. Cognitive Cyber Symbiosis (CoCyS) is a cloud that uses humans and machines for decision-making. In CoCyS, human–machine teams are viewed as a network with each node comprising humans (as computational machines) or computers. CoCyS focuses on the architecture and interface of a Trusted Autonomous System. This paper examines these two concepts and seeks to remove ambiguity by introducing formal definitions for these concepts. It then discusses open challenges for TA and CoCyS, that is, whether a team made of humans and machines can work in fluid, seamless harmony.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/FEETV48C/Abbass 等 - 2016 - Trusted Autonomy and Cognitive Cyber Symbiosis Op.pdf}
}

@article{abeNarrativeReviewAlternate2021,
  title = {A {{Narrative Review}} of {{Alternate Gait Training Using Knee-ankle-foot Orthosis}} in {{Stroke Patients}} with {{Severe Hemiparesis}}},
  author = {Abe, Hiroaki and Kadowaki, Kei and Tsujimoto, Naohide and Okanuka, Toru},
  date = {2021-12-20},
  journaltitle = {Physical Therapy Research},
  shortjournal = {Phys Ther Res},
  volume = {24},
  number = {3},
  pages = {195--203},
  issn = {2189-8448},
  doi = {10.1298/ptr.R0015},
  url = {https://www.jstage.jst.go.jp/article/ptr/24/3/24_R0015/_article},
  urldate = {2022-06-16},
  abstract = {Impairments resulting from stroke lead to persistent difficulties with walking. Subsequently, an improved walking ability is one of the highest priorities for people living with stroke. The degree to which gait can be restored after a stroke is related to both the initial impairment in walking ability and the severity of paresis of the lower extremities. However, there are some patients with severe motor paralysis and a markedly disrupted corticospinal tract who regain their gait function. Recently, several case reports have described the recovery of gait function in stroke patients with severe hemiplegia by providing alternate gait training. Multiple studies have demonstrated that gait training can induce “locomotor-like” coordinated muscle activity of paralyzed lower limbs in people with spinal cord injury. In the present review, we discuss the neural mechanisms of gait, and then we review case reports on the restoration of gait function in stroke patients with severe hemiplegia.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/886QCBVF/ja.pdf}
}

@inproceedings{abi-farrajLearningbasedSharedControl2017,
  title = {A Learning-Based Shared Control Architecture for Interactive Task Execution},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Abi-Farraj, Firas and Osa, Takayuki and Peters, Nicolo Pedemonte Jan and Neumann, Gerhard and Giordano, Paolo Robuffo},
  date = {2017-05},
  pages = {329--335},
  publisher = {{IEEE}},
  location = {{Singapore, Singapore}},
  doi = {10.1109/ICRA.2017.7989042},
  url = {http://ieeexplore.ieee.org/document/7989042/},
  urldate = {2024-02-02},
  abstract = {Shared control is a key technology for various robotic applications in which a robotic system and a human operator are meant to collaborate efficiently. In order to achieve efficient task execution in shared control, it is essential to predict the desired behavior for a given situation or context in order to simplify the control task for the human operator. This prediction is obtained by exploiting Learning from Demonstration (LfD), which is a popular approach for transferring human skills to robots. We encode the demonstrated behavior as trajectory distributions and generalize the learned distributions to new situations. The goal of this paper is to present a shared control framework that uses learned expert distributions to gain more autonomy. Our approach controls the balance between the controller’s autonomy and the human preference based on the distributions of the demonstrated trajectories. Moreover, the learned distributions are autonomously refined from collaborative task executions, resulting in a master-slave system with increasing autonomy that requires less user input with an increasing number of task executions. We experimentally validated that our shared control approach enables efficient task executions. Moreover, the conducted experiments demonstrated that the developed system improves its performances through interactive task executions with our shared control.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5090-4633-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TWF8XZAX/Abi-Farraj 等 - 2017 - A learning-based shared control architecture for i.pdf}
}

@article{aguirre-ollingerInertiaCompensationControl2012,
  title = {Inertia {{Compensation Control}} of a {{One-Degree-of-Freedom Exoskeleton}} for {{Lower-Limb Assistance}}: {{Initial Experiments}}},
  shorttitle = {Inertia {{Compensation Control}} of a {{One-Degree-of-Freedom Exoskeleton}} for {{Lower-Limb Assistance}}},
  author = {Aguirre-Ollinger, Gabriel and Colgate, J. Edward and Peshkin, Michael A. and Goswami, Ambarish},
  date = {2012-01},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  shortjournal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
  volume = {20},
  number = {1},
  pages = {68--77},
  issn = {1534-4320, 1558-0210},
  doi = {10.1109/TNSRE.2011.2176960},
  url = {https://ieeexplore.ieee.org/document/6132638/},
  urldate = {2023-12-16},
  abstract = {A new method of lower-limb exoskeleton control aimed at improving the agility of leg-swing motion is presented. In the absence of control, an exoskeleton’s mechanism usually hinders agility by adding mechanical impedance to the legs. The uncompensated inertia of the exoskeleton will reduce the natural frequency of leg swing, probably leading to lower step frequency during walking as well as increased metabolic energy consumption. The proposed controller emulates inertia compensation by adding a feedback loop consisting of low-pass filtered angular acceleration multiplied by a negative gain. This gain simulates negative inertia in the low-frequency range. The resulting controller combines two assistive effects: increasing the natural frequency of the lower limbs and performing net work per swing cycle. The controller was tested on a statically mounted exoskeleton that assists knee flexion and extension. Subjects performed movement sequences, first unassisted and then using the exoskeleton, in the context of a computer-based task resembling a race. In the exoskeleton’s baseline state, the frequency of leg swing and the mean angular velocity were consistently reduced. The addition of inertia compensation enabled subjects to recover their normal frequency and increase their selected angular velocity. The work performed by the exoskeleton was evidenced by catch trials in the protocol.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/6LZTE3J6/Aguirre-Ollinger 等 - 2012 - Inertia Compensation Control of a One-Degree-of-Fr.pdf}
}

@article{araiAssessmentOperatorStress2010,
  title = {Assessment of Operator Stress Induced by Robot Collaboration in Assembly},
  author = {Arai, T. and Kato, R. and Fujita, M.},
  date = {2010},
  journaltitle = {CIRP Annals},
  shortjournal = {CIRP Annals},
  volume = {59},
  number = {1},
  pages = {5--8},
  issn = {00078506},
  doi = {10.1016/j.cirp.2010.03.043},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0007850610000442},
  urldate = {2024-01-30},
  abstract = {To improve productivity of assembly in cell production, a robot is introduced to help operators physically. A moving robot around a human operator however induces much stress on human operators because they need to work coexistently and compellingly with the robot. This paper deals with the strain measurement caused by industrial robots, and the discuss design criterions of robot collaboration with a human operator. Several basic strains are experimentally measured: distance from a swinging robot to an operator, speed at robot’s movement towards an operator and so on. The results are applied in a novel cell production assembly system.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/75I6FKUU/Arai 等 - 2010 - Assessment of operator stress induced by robot col.pdf}
}

@article{awadSoftRoboticExosuit2017,
  title = {A Soft Robotic Exosuit Improves Walking in Patients after Stroke},
  author = {Awad, Louis N. and Bae, Jaehyun and O’Donnell, Kathleen and De Rossi, Stefano M. M. and Hendron, Kathryn and Sloot, Lizeth H. and Kudzia, Pawel and Allen, Stephen and Holt, Kenneth G. and Ellis, Terry D. and Walsh, Conor J.},
  date = {2017-07-26},
  journaltitle = {Science Translational Medicine},
  shortjournal = {Sci. Transl. Med.},
  volume = {9},
  number = {400},
  pages = {eaai9084},
  issn = {1946-6234, 1946-6242},
  doi = {10.1126/scitranslmed.aai9084},
  url = {https://www.science.org/doi/10.1126/scitranslmed.aai9084},
  urldate = {2021-11-28},
  langid = {english},
  keywords = {已读,有价值},
  file = {/Users/liurongkai/Zotero/storage/2UIG3DV5/Awad 等。 - 2017 - A soft robotic exosuit improves walking in patient.pdf}
}

@article{balabanGaitDisturbancesPatients2014,
  title = {Gait {{Disturbances}} in {{Patients With Stroke}}},
  author = {Balaban, Birol and Tok, Fatih},
  date = {2014-07},
  journaltitle = {PM\&R},
  shortjournal = {PM\&R},
  volume = {6},
  number = {7},
  pages = {635--642},
  issn = {19341482},
  doi = {10.1016/j.pmrj.2013.12.017},
  url = {http://doi.wiley.com/10.1016/j.pmrj.2013.12.017},
  urldate = {2022-06-16},
  langid = {english},
  keywords = {已读,有价值,综述,重要文章},
  file = {/Users/liurongkai/Zotero/storage/DE8AMSLC/Balaban_Tok_2014_Gait Disturbances in Patients With Stroke.pdf}
}

@inproceedings{balachandranAdaptiveAuthorityAllocation2020a,
  title = {Adaptive {{Authority Allocation}} in {{Shared Control}} of {{Robots Using Bayesian Filters}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Balachandran, Ribin and Mishra, Hrishik and Cappelli, Matteo and Weber, Bernhard and Secchi, Cristian and Ott, Christian and Albu-Schaeffer, Alin},
  date = {2020-05},
  pages = {11298--11304},
  publisher = {{IEEE}},
  location = {{Paris, France}},
  doi = {10.1109/ICRA40945.2020.9196941},
  url = {https://ieeexplore.ieee.org/document/9196941/},
  urldate = {2024-02-02},
  abstract = {In the present paper, we propose a novel systemdriven adaptive shared control framework in which the autonomous system allocates the authority among the human operator and itself. Authority allocation is based on a metric derived from a Bayesian filter, which is being adapted online according to real measurements. In this way, time-varying measurement noise characteristics are incorporated. We present the stability proof for the proposed shared control architecture with adaptive authority allocation, which includes time delay in the communication channel between the operator and the robot. Furthermore, the proposed method is validated through experiments and a user-study evaluation. The obtained results indicate significant improvements in task execution compared with pure teleoperation.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-72817-395-5},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Y8RJF2RN/Balachandran 等 - 2020 - Adaptive Authority Allocation in Shared Control of.pdf}
}

@article{bianFacialPositionExpressionBased2016,
  title = {Facial {{Position}} and {{Expression-Based Human}}–{{Computer Interface}} for {{Persons With Tetraplegia}}},
  author = {Bian, Zhen-Peng and Hou, Junhui and Chau, Lap-Pui and Magnenat-Thalmann, Nadia},
  date = {2016-05},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  shortjournal = {IEEE J. Biomed. Health Inform.},
  volume = {20},
  number = {3},
  pages = {915--924},
  issn = {2168-2194, 2168-2208},
  doi = {10.1109/JBHI.2015.2412125},
  url = {https://ieeexplore.ieee.org/document/7058374/},
  urldate = {2024-01-09},
  abstract = {A human–computer interface (namely Facial position and expression Mouse system, FM) for the persons with tetraplegia based on a monocular infrared depth camera is presented in this paper. The nose position along with the mouth status (close/open) is detected by the proposed algorithm to control and navigate the cursor as computer user input. The algorithm is based on an improved Randomized Decision Tree, which is capable of detecting the facial information efficiently and accurately. A more comfortable user experience is achieved by mapping the nose motion to the cursor motion via a nonlinear function. The infrared depth camera enables the system to be independent of illumination and color changes both from the background and on human face, which is a critical advantage over RGB camera-based options. Extensive experimental results show that the proposed system outperforms existing assistive technologies in terms of quantitative and qualitative assessments.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/YS595FJW/Bian 等 - 2016 - Facial Position and Expression-Based Human–Compute.pdf}
}

@article{bianFacialPositionExpressionBased2016a,
  title = {Facial {{Position}} and {{Expression-Based Human}}–{{Computer Interface}} for {{Persons With Tetraplegia}}},
  author = {Bian, Zhen-Peng and Hou, Junhui and Chau, Lap-Pui and Magnenat-Thalmann, Nadia},
  date = {2016-05},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  volume = {20},
  number = {3},
  pages = {915--924},
  issn = {2168-2208},
  doi = {10.1109/JBHI.2015.2412125},
  abstract = {A human-computer interface (namely Facial position and expression Mouse system, FM) for the persons with tetraplegia based on a monocular infrared depth camera is presented in this paper. The nose position along with the mouth status (close/open) is detected by the proposed algorithm to control and navigate the cursor as computer user input. The algorithm is based on an improved Randomized Decision Tree, which is capable of detecting the facial information efficiently and accurately. A more comfortable user experience is achieved by mapping the nose motion to the cursor motion via a nonlinear function. The infrared depth camera enables the system to be independent of illumination and color changes both from the background and on human face, which is a critical advantage over RGB camera-based options. Extensive experimental results show that the proposed system outperforms existing assistive technologies in terms of quantitative and qualitative assessments.},
  eventtitle = {{{IEEE Journal}} of {{Biomedical}} and {{Health Informatics}}},
  keywords = {assistive technology (AT),Assistive technology (AT),camera mouse,Camera mouse,Cameras,computer access,computer access.,fitts’ law,Fitts’ law,hand-free control,human–computer interaction (HCI),humancomputer interaction (HCI),Informatics,Mice,Mouth,Nose,perceptual user interface,severe disabilities,Training,引用},
  file = {/Users/liurongkai/Zotero/storage/S6EUAGRA/Bian et al_2016_Facial Position and Expression-Based Human–Computer Interface for Persons With.pdf;/Users/liurongkai/Zotero/storage/WA9ZVQ54/7058374.html}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-31073-2},
  langid = {english},
  pagetotal = {738},
  keywords = {Machine learning,Pattern perception,引用},
  file = {/Users/liurongkai/Zotero/storage/X6BGHIKN/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{blabeAssessmentBrainMachine2015,
  title = {Assessment of Brain–Machine Interfaces from the Perspective of People with Paralysis},
  author = {Blabe, Christine H and Gilja, Vikash and Chestek, Cindy A and Shenoy, Krishna V and Anderson, Kim D and Henderson, Jaimie M},
  date = {2015-08-01},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {12},
  number = {4},
  pages = {043002},
  issn = {1741-2560, 1741-2552},
  doi = {10.1088/1741-2560/12/4/043002},
  url = {https://iopscience.iop.org/article/10.1088/1741-2560/12/4/043002},
  urldate = {2024-01-07},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/J3XRGAQK/Blabe et al_2015_Assessment of brain–machine interfaces from the perspective of people with.pdf}
}

@article{brandmanRapidCalibrationIntracortical2018,
  title = {Rapid Calibration of an Intracortical Brain–Computer Interface for People with Tetraplegia},
  author = {Brandman, David M and Hosman, Tommy and Saab, Jad and Burkhart, Michael C and Shanahan, Benjamin E and Ciancibello, John G and Sarma, Anish A and Milstein, Daniel J and Vargas-Irwin, Carlos E and Franco, Brian and Kelemen, Jessica and Blabe, Christine and Murphy, Brian A and Young, Daniel R and Willett, Francis R and Pandarinath, Chethan and Stavisky, Sergey D and Kirsch, Robert F and Walter, Benjamin L and Bolu Ajiboye, A and Cash, Sydney S and Eskandar, Emad N and Miller, Jonathan P and Sweet, Jennifer A and Shenoy, Krishna V and Henderson, Jaimie M and Jarosiewicz, Beata and Harrison, Matthew T and Simeral, John D and Hochberg, Leigh R},
  date = {2018-04-01},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {15},
  number = {2},
  pages = {026007},
  issn = {1741-2560, 1741-2552},
  doi = {10.1088/1741-2552/aa9ee7},
  url = {https://iopscience.iop.org/article/10.1088/1741-2552/aa9ee7},
  urldate = {2022-11-07},
  abstract = {Objective. Brain–computer interfaces (BCIs) can enable individuals with tetraplegia to communicate and control external devices. Though much progress has been made in improving the speed and robustness of neural control provided by intracortical BCIs, little research has been devoted to minimizing the amount of time spent on decoder calibration. Approach. We investigated the amount of time users needed to calibrate decoders and achieve performance saturation using two markedly different decoding algorithms: the steady-state Kalman filter, and a novel technique using Gaussian process regression (GP-DKF). Main results. Three people with tetraplegia gained rapid closed-loop neural cursor control and peak, plateaued decoder performance within 3\,min of initializing calibration. We also show that a BCI-naïve user (T5) was able to rapidly attain closed-loop neural cursor control with the GP-DKF using self-selected movement imagery on his first-ever day of closed-loop BCI use, acquiring a target 37\,s after initiating calibration. Significance. These results demonstrate the potential for an intracortical BCI to be used immediately after deployment by people with paralysis, without the need for user learning or extensive system calibration.},
  langid = {english},
  keywords = {在读,引用,有价值,综述},
  file = {/Users/liurongkai/Zotero/storage/X5IP22IY/Brandman 等 - 2018 - Rapid calibration of an intracortical brain–comput.pdf}
}

@inproceedings{briouzaConvolutionalNeuralNetworkBased2021,
  title = {A {{Convolutional Neural Network-Based Architecture}} for {{EMG Signal Classification}}},
  booktitle = {2021 {{International Conference}} on {{Data Analytics}} for {{Business}} and {{Industry}} ({{ICDABI}})},
  author = {Briouza, Sami and Gritli, Hassene and Khraief, Nahla and Belghith, Safya and Singh, Dilbag},
  date = {2021-10-25},
  pages = {107--112},
  publisher = {{IEEE}},
  location = {{Sakheer, Bahrain}},
  doi = {10.1109/ICDABI53623.2021.9655876},
  url = {https://ieeexplore.ieee.org/document/9655876/},
  urldate = {2024-01-07},
  abstract = {Electromyography (EMG) signals represent the electrical manifestation of neuromuscular activation and they contain valuable information on muscle activity. Recently, the use of EMG has increased in prostheses, rehabilitation, human-machine interaction applications, among others. Deep Learning (DL) methods showed effectiveness in the classification of EMG signals. In this paper, we propose a featureless approach using a Convolutional Neural Network (CNN) for EMG signal classification to identify different wrist and finger motions. The proposed approach does not need a set of features selected as an input. However, it automatically learns from the input EMG signals. Some simulation results are realized at the end of this work in order to evaluate the performance of the proposed CNN-based architecture. The used data set is the Ninapro Database 2, which includes 40 different subjects and 49 different motions.},
  eventtitle = {2021 {{International Conference}} on {{Data Analytics}} for {{Business}} and {{Industry}} ({{ICDABI}})},
  isbn = {978-1-66541-656-6},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/BYGGPRRG/Briouza 等 - 2021 - A Convolutional Neural Network-Based Architecture .pdf}
}

@article{campaniniMethodDifferentiateCauses2013,
  title = {A Method to Differentiate the Causes of Stiff-Knee Gait in Stroke Patients},
  author = {Campanini, I. and Merlo, A. and Damiano, B.},
  date = {2013-06},
  journaltitle = {Gait \& Posture},
  shortjournal = {Gait \& Posture},
  volume = {38},
  number = {2},
  pages = {165--169},
  issn = {09666362},
  doi = {10.1016/j.gaitpost.2013.05.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636213002208},
  urldate = {2022-06-17},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/8IEBVBE7/Campanini 等。 - 2013 - A method to differentiate the causes of stiff-knee.pdf}
}

@inproceedings{carringtonWearablesChairablesInclusive2014,
  title = {Wearables and Chairables: Inclusive Design of Mobile Input and Output Techniques for Power Wheelchair Users},
  shorttitle = {Wearables and Chairables},
  booktitle = {Proceedings of the {{SIGCHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Carrington, Patrick and Hurst, Amy and Kane, Shaun K.},
  date = {2014-04-26},
  pages = {3103--3112},
  publisher = {{ACM}},
  location = {{Toronto Ontario Canada}},
  doi = {10.1145/2556288.2557237},
  url = {https://dl.acm.org/doi/10.1145/2556288.2557237},
  urldate = {2023-12-20},
  eventtitle = {{{CHI}} '14: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-2473-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/UKUEZ7BC/Carrington et al_2014_Wearables and chairables.pdf}
}

@inproceedings{casadioBodyMachineInterface2011,
  title = {Body Machine Interface: {{Remapping}} Motor Skills after Spinal Cord Injury},
  shorttitle = {Body Machine Interface},
  booktitle = {2011 {{IEEE International Conference}} on {{Rehabilitation Robotics}}},
  author = {Casadio, M. and Pressman, A. and Acosta, S. and Danzinger, Z. and Fishbach, A. and Mussa-Ivaldi, F. A. and Muir, K. and Tseng, H. and Chen, D.},
  date = {2011-06},
  pages = {1--6},
  issn = {1945-7901},
  doi = {10.1109/ICORR.2011.5975384},
  url = {10.1109/ICORR.2011.5975384},
  abstract = {The goal of a body-machine interface (BMI) is to map the residual motor skills of the users into efficient patterns of control. The interface is subject to two processes of learning: while users practice controlling the assistive device, the interface modifies itself based on the user's residual abilities and preferences. In this study, we combined virtual reality and movement capture technologies to investigate the reorganization of movements that occurs when individuals with spinal cord injury (SCI) are allowed to use a broad spectrum of body motions to perform different tasks. Subjects, over multiple sessions, used their upper body movements to engage in exercises that required different operational functions such as controlling a keyboard for playing a videogame, driving a simulated wheelchair in a virtual reality (VR) environment, and piloting a cursor on a screen for reaching targets. In particular, we investigated the possibility of reducing the dimensionality of the control signals by finding repeatable and stable correlations of movement signals, established both by the presence of biomechanical constraints and by learned patterns of coordination. The outcomes of these investigations will provide guidance for further studies of efficient remapping of motor coordination for the control of assistive devices and are a basis for a new training paradigm in which the burden of learning is significantly removed from the impaired subjects and shifted to the devices.},
  eventtitle = {2011 {{IEEE International Conference}} on {{Rehabilitation Robotics}}},
  keywords = {Adult,Aerospace electronics,assistive devices,biomechanical constraints,biomechanics,Biomechanics,body machine interface,body motion broad spectrum,body-machine interface,Calibration,Female,Force,Humans,injuries,Injuries,Learning,Male,man-machine systems,Motor Skills,Movement,movement capture technologies,Movement reorganization,neurophysiology,patient rehabilitation,remapping motor skills,residual motor skills,simulated wheelchair,Spinal Cord Injuries,spinal cord injury,Spinal cord Injury,Training,upper body movements,user interfaces,user practice controlling,videogame,virtual reality,Visualization,Wheelchair,wheelchairs,Wheelchairs,Young Adult,引用,重要文章},
  file = {/Users/liurongkai/Zotero/storage/YDA5FV5R/Casadio et al_2011_Body machine interface.pdf;/Users/liurongkai/Zotero/storage/HPKTJ4T8/5975384.html}
}

@article{chadwickRealTimeSimulationThreeDimensional2014,
  title = {Real-{{Time Simulation}} of {{Three-Dimensional Shoulder Girdle}} and {{Arm Dynamics}}},
  author = {Chadwick, E. K. and Blana, D. and Kirsch, R. F. and family=Bogert, given=A. J., prefix=van den, useprefix=false},
  date = {2014-07},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  volume = {61},
  number = {7},
  pages = {1947--1956},
  issn = {1558-2531},
  doi = {10.1109/TBME.2014.2309727},
  url = {10.1109/TBME.2014.2309727},
  abstract = {Electrical stimulation is a promising technology for the restoration of arm function in paralyzed individuals. Control of the paralyzed arm under electrical stimulation, however, is a challenging problem that requires advanced controllers and command interfaces for the user. A real-time model describing the complex dynamics of the arm would allow user-in-the-loop type experiments where the command interface and controller could be assessed. Real-time models of the arm previously described have not included the ability to model the independently controlled scapula and clavicle, limiting their utility for clinical applications of this nature. The goal of this study therefore was to evaluate the performance and mechanical behavior of a real-time, dynamic model of the arm and shoulder girdle. The model comprises seven segments linked by eleven degrees of freedom and actuated by 138 muscle elements. Polynomials were generated to describe the muscle lines of action to reduce computation time, and an implicit, first-order Rosenbrock formulation of the equations of motion was used to increase simulation step-size. The model simulated flexion of the arm faster than real time, simulation time being 92\% of actual movement time on standard desktop hardware. Modeled maximum isometric torque values agreed well with values from the literature, showing that the model simulates the moment-generating behavior of a real human arm. The speed of the model enables experiments where the user controls the virtual arm and receives visual feedback in real time. The ability to optimize potential solutions in simulation greatly reduces the burden on the user during development.},
  eventtitle = {{{IEEE Transactions}} on {{Biomedical Engineering}}},
  keywords = {advanced controllers,arm dynamics,arm function restoration,bioelectric potentials,Biomechanical Phenomena,biomechanics,Biomechanics,bone,clinical applications,command user interfaces,complex dynamics,computation time,Computer Simulation,controllers,Dynamics,electrical stimulation,Equations,equations-of-motion,feedback,Force,forward dynamics,Humans,implicit first-order Rosenbrock formulation,independently controlled clavicle,independently controlled scapula,Joints,Mathematical model,mechanical behavior,medical control systems,model simulated flexion,modeled maximum isometric torque values,Models Biological,muscle,muscle elements,Muscles,musculoskeletal modeling,neuromuscular stimulation,paralyzed individuals,polynomials,Range of Motion Articular,real human arm,real-time simulation,Real-time systems,shoulder,Shoulder,simulation step-size,standard desktop hardware,three-dimensional shoulder girdle,torque,torque control,Upper Extremity,user modelling,user-in-the-loop type experiments,virtual arm,virtual reality,visual feedback,引用,感兴趣的,有价值},
  file = {/Users/liurongkai/Zotero/storage/3TRTSWZN/Chadwick et al_2014_Real-Time Simulation of Three-Dimensional Shoulder Girdle and Arm Dynamics.pdf;/Users/liurongkai/Zotero/storage/FU3JK8HW/6755458.html}
}

@inproceedings{chaurasiyaSequentialStudyEmotions2019,
  title = {A {{Sequential Study}} of {{Emotions}} through {{EEG}} Using {{HMM}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Computational Science}} and {{Engineering}} ({{CSE}}) and {{IEEE International Conference}} on {{Embedded}} and {{Ubiquitous Computing}} ({{EUC}})},
  author = {Chaurasiya, Rahul Kumar and Shukla, Shourya and Sahu, Tirath Prasad},
  date = {2019-08},
  pages = {104--109},
  publisher = {{IEEE}},
  location = {{New York, NY, USA}},
  doi = {10.1109/CSE/EUC.2019.00029},
  url = {https://ieeexplore.ieee.org/document/8919558/},
  urldate = {2024-01-07},
  abstract = {Changes in emotional state of an individual are the result of changes in brain signals. The brain signals are transduced in form of time dependent electrical signals by electroencephalogram (EEG). The method for study of EEG signals for detection of emotional state of the subject is proposed in this paper. The sequential study of changes in emotions is described using the hidden Markov model (HMM). The HMM is used on the normally distributed (ND) data to depict the series of changes in emotions as the subject is evoked through video stimulations. The data set used in this paper is the standard DEAP dataset. The standard valence-arousal plane is analyzed for detection of emotional states. HMM is employed for sequentially classifying the features extracted from the given data. HMM predictions for transition and emission probabilities are compared to resulting probabilities. The aim of this paper is to propose a method to depict the transition of emotions from state into another, hence, transition matrix of the HMM are used to measure the accuracy of the system. To determine the accuracy of the system absolute mean value of the transition matrix is obtained, and accuracy is found out to be 97.21\%. Hence, a model is developed using HMM to describe the sequential change in emotional state as the EEG changes.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Computational Science}} and {{Engineering}} ({{CSE}}) and {{IEEE International Conference}} on {{Embedded}} and {{Ubiquitous Computing}} ({{EUC}})},
  isbn = {978-1-72811-664-8},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/SIWCALVA/Chaurasiya 等 - 2019 - A Sequential Study of Emotions through EEG using H.pdf}
}

@article{chenDevelopmentWearableUpper2022,
  title = {Development of a {{Wearable Upper Limb Rehabilitation Robot Based}} on {{Reinforced Soft Pneumatic Actuators}}},
  author = {Chen, Xinbo and Zhang, Shuai and Cao, Kaibin and Wei, Chunjie and Zhao, Wumian and Yao, Jiantao},
  date = {2022-12},
  journaltitle = {Chinese Journal of Mechanical Engineering},
  shortjournal = {Chin. J. Mech. Eng.},
  volume = {35},
  number = {1},
  pages = {83},
  issn = {1000-9345, 2192-8258},
  doi = {10.1186/s10033-022-00749-6},
  url = {https://cjme.springeropen.com/articles/10.1186/s10033-022-00749-6},
  urldate = {2024-01-09},
  abstract = {Dyskinesia of the upper limbs caused by stroke, sports injury, or traffic accidents limits the ability to perform the activities of daily living. Besides the necessary medical treatment, correct and scientific rehabilitation training for the injured joint is an important auxiliary means during the treatment of the effected upper limb. Conventional upperlimb rehabilitation robots have some disadvantages, such as a complex structure, poor compliance, high cost, and poor portability. In this study, a novel soft wearable upper limb rehabilitation robot (SWULRR) with reinforced soft pneumatic actuators (RSPAs) that can withstand high pressure and featuring excellent loading characteristics was developed. Driven by RSPAs, this portable SWULRR can perform rehabilitation training of the wrist and elbow joints. In this study, the kinematics of an SWULRR were analyzed, and the force and motion characteristics of RSPA were studied experimentally. The results provide a reference for the development and application of wearable upper limb rehabilitation robots. An experimental study on the rotation angle of the wrist and the pressure of the RSPA was conducted to test the effect of the rehabilitation training and verify the rationality of the theoretical model. The process of wrist rehabilitation training was tested and evaluated, indicating that SWULRR with RSPAs will enhance the flexibility, comfort, and safety of rehabilitation training. This work is expected to promote the development of wearable upper-limb rehabilitation robots based on modular reinforced soft pneumatic actuators.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/UAAJZGPB/Chen 等 - 2022 - Development of a Wearable Upper Limb Rehabilitatio.pdf}
}

@inproceedings{chengOcclusionAwareNetworks3D2019,
  title = {Occlusion-{{Aware Networks}} for {{3D Human Pose Estimation}} in {{Video}}},
  booktitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Cheng, Yu and Yang, Bo and Wang, Bo and Wending, Yan and Tan, Robby},
  date = {2019-10},
  pages = {723--732},
  publisher = {{IEEE}},
  location = {{Seoul, Korea (South)}},
  doi = {10.1109/ICCV.2019.00081},
  url = {https://ieeexplore.ieee.org/document/9010921/},
  urldate = {2024-01-10},
  abstract = {Occlusion is a key problem in 3D human pose estimation from a monocular video. To address this problem, we introduce an occlusion-aware deep-learning framework. By employing estimated 2D confidence heatmaps of keypoints and an optical-flow consistency constraint, we filter out the unreliable estimations of occluded keypoints. When occlusion occurs, we have incomplete 2D keypoints and feed them to our 2D and 3D temporal convolutional networks (2D and 3D TCNs) that enforce temporal smoothness to produce a complete 3D pose. By using incomplete 2D keypoints, instead of complete but incorrect ones, our networks are less affected by the error-prone estimations of occluded keypoints. Training the occlusion-aware 3D TCN requires pairs of a 3D pose and a 2D pose with occlusion labels. As no such a dataset is available, we introduce a “Cylinder Man Model” to approximate the occupation of body parts in 3D space. By projecting the model onto a 2D plane in different viewing angles, we obtain and label the occluded keypoints, providing us plenty of training data. In addition, we use this model to create a pose regularization constraint, preferring the 2D estimations of unreliable keypoints to be occluded. Our method outperforms state-of-the-art methods on Human 3.6M and HumanEva-I datasets.},
  eventtitle = {2019 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-72814-803-8},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/WRRRUVZN/Cheng 等 - 2019 - Occlusion-Aware Networks for 3D Human Pose Estimat.pdf}
}

@inproceedings{chenUnsupervised3DPose2019,
  title = {Unsupervised {{3D Pose Estimation With Geometric Self-Supervision}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Chen, Ching-Hang and Tyagi, Ambrish and Agrawal, Amit and Drover, Dylan and Mv, Rohith and Stojanov, Stefan and Rehg, James M.},
  date = {2019-06},
  pages = {5707--5717},
  publisher = {{IEEE}},
  location = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPR.2019.00586},
  url = {https://ieeexplore.ieee.org/document/8953799/},
  urldate = {2024-01-10},
  abstract = {We present an unsupervised learning approach to recover 3D human pose from 2D skeletal joints extracted from a single image. Our method does not require any multiview image data, 3D skeletons, correspondences between 2D-3D points, or use previously learned 3D priors during training. A lifting network accepts 2D landmarks as inputs and generates a corresponding 3D skeleton estimate. During training, the recovered 3D skeleton is reprojected on random camera viewpoints to generate new ‘synthetic’ 2D poses. By lifting the synthetic 2D poses back to 3D and re-projecting them in the original camera view, we can define self-consistency loss both in 3D and in 2D. The training can thus be self supervised by exploiting the geometric selfconsistency of the lift-reproject-lift process. We show that self-consistency alone is not sufficient to generate realistic skeletons, however adding a 2D pose discriminator enables the lifter to output valid 3D poses. Additionally, to learn from 2D poses ‘in the wild’, we train an unsupervised 2D domain adapter network to allow for an expansion of 2D data. This improves results and demonstrates the usefulness of 2D pose data for unsupervised 3D lifting. Results on Human3.6M dataset for 3D human pose estimation demonstrate that our approach improves upon the previous unsupervised methods by 30\% and outperforms many weakly supervised approaches that explicitly use 3D data.},
  eventtitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-72813-293-8},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/K94ZGMCS/Chen 等 - 2019 - Unsupervised 3D Pose Estimation With Geometric Sel.pdf}
}

@inproceedings{chowdhurySimplisticApproachDesign2018,
  title = {Simplistic {{Approach}} to {{Design}} a {{Prototype}} of an {{Automated Wheelchair Based}} on {{Electrooculography}}},
  booktitle = {2018 {{International Conference}} on {{Computer}}, {{Communication}}, {{Chemical}}, {{Material}} and {{Electronic Engineering}} ({{IC4ME2}})},
  author = {Chowdhury, Mubtasim Rafid and Poonguzhali, S. and K.R., Aravind Balan and R., Suresh and Mollah, Nurunnabi and Raihan, M. and Ahmed, Abu Shakil},
  date = {2018-02},
  pages = {1--4},
  doi = {10.1109/IC4ME2.2018.8465638},
  abstract = {Many people suffer from the disability to control different limbs of their bodies inherently or due to an accident. Immobility impedes their daily activities and detaches themselves from various social events to a certain extent. Although motorized mechanical systems such as wheelchair enhance the movability, it is not beneficial for the patients suffering from quadriplegia whose entire body is paralyzed. We have proposed a prototype of an automated wheelchair which can be controlled by directional movement of the eye using electrooculography (EOG) signal. The performance appraisal of the proposed prototype after proper assembly justifies its effectiveness.},
  eventtitle = {2018 {{International Conference}} on {{Computer}}, {{Communication}}, {{Chemical}}, {{Material}} and {{Electronic Engineering}} ({{IC4ME2}})},
  keywords = {assistive devices,Band-pass filters,electrode,Electrodes,Electrooculography,EOG,human-computer interaction.,microcontroller,Microcontrollers,paralysis,Pins,Prototypes,wheelchair,Wheelchairs,引用},
  file = {/Users/liurongkai/Zotero/storage/T4XV2K44/Textile-Sensing Wearable Systems for Continuous Motion Angle Estimation  A Systematic Review.pdf;/Users/liurongkai/Zotero/storage/XBT63VLR/Chowdhury et al_2018_Simplistic Approach to Design a Prototype of an Automated Wheelchair Based on.pdf;/Users/liurongkai/Zotero/storage/FBMZXNQB/8465638.html}
}

@article{churchlandCentralSourceMovement2006,
  title = {A {{Central Source}} of {{Movement Variability}}},
  author = {Churchland, Mark M. and Afshar, Afsheen and Shenoy, Krishna V.},
  date = {2006-12},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {52},
  number = {6},
  pages = {1085--1096},
  issn = {08966273},
  doi = {10.1016/j.neuron.2006.10.034},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627306008713},
  urldate = {2021-12-06},
  abstract = {Movements are universally, sometimes frustratingly, variable. When such variability causes error, we typically assume that something went wrong during the movement. The same assumption is made by recent and influential models of motor control. These posit that the principal limit on repeatable performance is neuromuscular noise that corrupts movement as it occurs. An alternative hypothesis is that movement variability arises before movements begin, during motor preparation. We examined this possibility directly by recording the preparatory activity of single cortical neurons during a highly practiced reach task. Small variations in preparatory neural activity were predictive of small variations in the upcoming reach. Effect magnitudes were such that at least half of the observed movement variability likely had its source during motor preparation. Thus, even for a highly practiced task, the ability to repeatedly plan the same movement limits our ability to repeatedly execute the same movement.},
  langid = {english},
  keywords = {引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/JTTX3FNA/Churchland 等。 - 2006 - A Central Source of Movement Variability.pdf}
}

@article{collingerFunctionalPrioritiesAssistive2013,
  title = {Functional {{Priorities}}, {{Assistive Technology}}, and {{Brain-Computer Interfaces}} after {{Spinal Cord Injury}}},
  author = {Collinger, Jennifer L. and Boninger, Michael L. and Bruns, Tim M. and Curley, Kenneth and Wang, Wei and Weber, Douglas J.},
  date = {2013-04},
  journaltitle = {Journal of rehabilitation research and development},
  shortjournal = {J Rehabil Res Dev},
  volume = {50},
  number = {2},
  eprint = {23760996},
  eprinttype = {pmid},
  pages = {145--160},
  issn = {0748-7711},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3684986/},
  urldate = {2024-01-07},
  abstract = {Spinal cord injury often impacts a person’s ability to perform critical activities of daily living and can have a negative impact on their quality of life. Assistive technology aims to bridge this gap to augment function and increase independence. It is critical to involve consumers in the design and evaluation process as new technologies, like brain-computer interfaces (BCIs), are developed. In a survey study of fifty-seven veterans with spinal cord injury who were participating in the National Veterans Wheelchair Games, we found that restoration of bladder/bowel control, walking, and arm/hand function (tetraplegia only) were all high priorities for improving quality of life. Many of the participants had not used or heard of some currently available technologies designed to improve function or the ability to interact with their environment. The majority of individuals in this study were interested in using a BCI, particularly for controlling functional electrical stimulation to restore lost function. Independent operation was considered to be the most important design criteria. Interestingly, many participants reported that they would be willing to consider surgery to implant a BCI even though non-invasiveness was a high priority design requirement. This survey demonstrates the interest of individuals with spinal cord injury in receiving and contributing to the design of BCI.},
  pmcid = {PMC3684986},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/BA27EJNC/Collinger et al_2013_Functional Priorities, Assistive Technology, and Brain-Computer Interfaces.pdf}
}

@article{collinsReducingEnergyCost2015,
  title = {Reducing the Energy Cost of Human Walking Using an Unpowered Exoskeleton},
  author = {Collins, Steven H. and Wiggin, M. Bruce and Sawicki, Gregory S.},
  date = {2015-06},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {522},
  number = {7555},
  pages = {212--215},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14288},
  url = {https://www.nature.com/articles/nature14288},
  urldate = {2023-12-16},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TR6QD6TA/Collins 等 - 2015 - Reducing the energy cost of human walking using an.pdf}
}

@article{contreras-gonzalezEfficientUpperLimb2020,
  title = {Efficient {{Upper Limb Position Estimation Based}} on {{Angular Displacement Sensors}} for {{Wearable Devices}}},
  author = {Contreras-González, Aldo-Francisco and Ferre, Manuel and Sánchez-Urán, Miguel Ángel and Sáez-Sáez, Francisco Javier and Blaya Haro, Fernando},
  date = {2020-11-12},
  journaltitle = {Sensors},
  shortjournal = {Sensors},
  volume = {20},
  number = {22},
  pages = {6452},
  issn = {1424-8220},
  doi = {10.3390/s20226452},
  url = {https://www.mdpi.com/1424-8220/20/22/6452},
  urldate = {2020-12-04},
  abstract = {Motion tracking techniques have been extensively studied in recent years. However, capturing movements of the upper limbs is a challenging task. This document presents the estimation of arm orientation and elbow and wrist position using wearable flexible sensors (WFSs). A study was developed to obtain the highest range of motion (ROM) of the shoulder with as few sensors as possible, and a method for estimating arm length and a calibration procedure was proposed. Performance was verified by comparing measurement of the shoulder joint angles obtained from commercial two-axis soft angular displacement sensors (sADS) from Bend Labs and from the ground truth system (GTS) OptiTrack. The global root-mean-square error (RMSE) for the shoulder angle is 2.93 degrees and 37.5 mm for the position estimation of the wrist in cyclical movements; this measure of RMSE was improved to 13.6 mm by implementing a gesture classifier.},
  langid = {english},
  keywords = {已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/8I6NY2LY/Contreras-González 等。 - 2020 - Efficient Upper Limb Position Estimation Based on .pdf}
}

@article{cruzBiomechanicalImpairmentsGait2009,
  title = {Biomechanical Impairments and Gait Adaptations Post-Stroke: {{Multi-factorial}} Associations},
  shorttitle = {Biomechanical Impairments and Gait Adaptations Post-Stroke},
  author = {Cruz, Theresa Hayes and Lewek, Michael D. and Dhaher, Yasin Y.},
  date = {2009-08},
  journaltitle = {Journal of Biomechanics},
  shortjournal = {Journal of Biomechanics},
  volume = {42},
  number = {11},
  pages = {1673--1677},
  issn = {00219290},
  doi = {10.1016/j.jbiomech.2009.04.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021929009002218},
  urldate = {2022-06-16},
  abstract = {Understanding the potential causes of both reduced gait speed and compensatory frontal plane kinematics during walking in individuals post-stroke may be useful in developing effective rehabilitation strategies. Multiple linear regression analysis was used to select the combination of paretic limb impairments (frontal and sagittal plane hip strength, sagittal plane knee and ankle strength, and multi-joint knee/hip torque coupling) which best estimate gait speed and compensatory pelvic obliquity velocities at toeoff. Compensatory behaviors were defined as deviations from control subjects’ values. The gait speed model (n ¼ 18; p ¼ 0.003) revealed that greater hip abduction strength and multi-joint coupling of sagittal plane knee and frontal plane hip torques were associated with decreased velocity; however, gait speed was positively associated with paretic hip extension strength. Multi-joint coupling was the most influential predictor of gait speed. The second model (n ¼ 15; po0.001) revealed that multi-joint coupling was associated with increased compensatory pelvic movement at toeoff; while hip extension and flexion and knee flexion strength were associated with reduced frontal plane pelvic compensations. In this case, hip extension strength had the greatest influence on pelvic behavior. The analyses revealed that different yet overlapping sets of single joint strength and multi-joint coupling measures were associated with gait speed and compensatory pelvic behavior during walking post-stroke. These findings provide insight regarding the potential impact of targeted rehabilitation paradigms on improving speed and compensatory kinematics following stroke. \& 2009 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TEKENPS5/main.pdf}
}

@article{cruzSelfPacedBCICollaborative2021,
  title = {A {{Self-Paced BCI With}} a {{Collaborative Controller}} for {{Highly Reliable Wheelchair Driving}}: {{Experimental Tests With Physically Disabled Individuals}}},
  shorttitle = {A {{Self-Paced BCI With}} a {{Collaborative Controller}} for {{Highly Reliable Wheelchair Driving}}},
  author = {Cruz, Aniana and Pires, Gabriel and Lopes, Ana and Carona, Carlos and Nunes, Urbano J.},
  date = {2021-04},
  journaltitle = {IEEE Transactions on Human-Machine Systems},
  volume = {51},
  number = {2},
  pages = {109--119},
  issn = {2168-2305},
  doi = {10.1109/THMS.2020.3047597},
  abstract = {Brain-controlled wheelchairs (BCWs) are a promising solution for people with severe motor disabilities, who cannot use conventional interfaces. However, the low reliability of electroencephalographic signal decoding and the high user's workload imposed by continuous control of a wheelchair requires effective approaches. In this article, we propose a self-paced P300-based brain-computer interface (BCI) combined with dynamic time-window commands and a collaborative controller. The self-paced approach allows users to switch between control and noncontrol states without requiring any additional task or mental strategy, while the dynamic time-window commands allow balancing the reliability and speed of the BCI. The collaborative controller, combining user's intentions and navigation information, offers the possibility to navigate in complex environments and to improve the overall system reliability. The feasibility of the proposed approach and the impact of each system component (self-paced, dynamic time window, and collaborative controller) are systematically validated in a set of experiments conducted with seven able-bodied participants and six physically disabled participants steering a robotic wheelchair in real-office-like environments. These two groups controlled the BCW with a final driving accuracy greater than 99\%. Quantitative and subjective results, assessed through questionnaires, attest to the effectiveness of the proposed approach. Altogether, these findings contribute to improving the usability of BCWs and, hence, the potential for their use by target users in home settings.},
  eventtitle = {{{IEEE Transactions}} on {{Human-Machine Systems}}},
  keywords = {Brain–computer interface (BCI),Collaboration,collaborative control,Control systems,dynamic time window,Navigation,physically disabled,quantitative and subjective assessment,Reliability,robotic wheelchair (RW),self-paced,Task analysis,Usability,Wheelchairs,引用},
  file = {/Users/liurongkai/Zotero/storage/H9BPYMJY/Cruz et al_2021_A Self-Paced BCI With a Collaborative Controller for Highly Reliable Wheelchair.pdf;/Users/liurongkai/Zotero/storage/J6JL8EQ8/9336656.html}
}

@article{desantisGuidingFunctionalReorganization2020a,
  title = {Guiding Functional Reorganization of Motor Redundancy Using a Body-Machine Interface},
  author = {De Santis, Dalia and Mussa-Ivaldi, Ferdinando A.},
  date = {2020-12},
  journaltitle = {Journal of NeuroEngineering and Rehabilitation},
  shortjournal = {J NeuroEngineering Rehabil},
  volume = {17},
  number = {1},
  pages = {61},
  issn = {1743-0003},
  doi = {10.1186/s12984-020-00681-7},
  url = {https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-020-00681-7},
  urldate = {2023-08-16},
  abstract = {Background: Body-machine interfaces map movements onto commands to external devices. Redundant motion signals derived from inertial sensors are mapped onto lower-dimensional device commands. Then, the device users face two problems, a) the structural problem of understanding the operation of the interface and b) the performance problem of controlling the external device with high efficiency. We hypothesize that these problems, while being distinct are connected in that aligning the space of body movements with the space encoded by the interface, i.e. solving the structural problem, facilitates redundancy resolution towards increasing efficiency, i.e. solving the performance problem. Methods: Twenty unimpaired volunteers practiced controlling the movement of a computer cursor by moving their arms. Eight signals from four inertial sensors were mapped onto the two cursor’s coordinates on a screen. The mapping matrix was initialized by asking each user to perform free-form spontaneous upper-limb motions and deriving the two main principal components of the motion signals. Participants engaged in a reaching task for 18 min, followed by a tracking task. One group of 10 participants practiced with the same mapping throughout the experiment, while the other 10 with an adaptive mapping that was iteratively updated by recalculating the principal components based on ongoing movements. Results: Participants quickly reduced reaching time while also learning to distribute most movement variance over two dimensions. Participants with the fixed mapping distributed movement variance over a subspace that did not match the potent subspace defined by the interface map. In contrast, participant with the adaptive map reduced the difference between the two subspaces, resulting in a smaller amount of arm motions distributed over the null space of the interface map. This, in turn, enhanced movement efficiency without impairing generalization from reaching to tracking. Conclusions: Aligning the potent subspace encoded by the interface map to the user’s movement subspace guides redundancy resolution towards increasing movement efficiency, with implications for controlling assistive devices. In contrast, in the pursuit of rehabilitative goals, results would suggest that the interface must change to drive the statistics of user’s motions away from the established pattern and toward the engagement of movements to be recovered. (Continued on next page)},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/2RZB9DL4/De Santis 和 Mussa-Ivaldi - 2020 - Guiding functional reorganization of motor redunda.pdf}
}

@inproceedings{devigneDesignHapticGuidance2018,
  title = {Design of a {{Haptic Guidance Solution}} for {{Assisted Power Wheelchair Navigation}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Devigne, Louise and Pasteau, Francois and Babel, Marie and Narayanan, Vishnu K. and Guegan, Sylvain and Gallien, Philippe},
  date = {2018-10},
  pages = {3231--3236},
  publisher = {{IEEE}},
  location = {{Miyazaki, Japan}},
  doi = {10.1109/SMC.2018.00547},
  url = {https://ieeexplore.ieee.org/document/8616544/},
  urldate = {2023-12-22},
  abstract = {Smart powered wheelchairs can increase mobility and independence for people with disability by providing navigation support. This support can be supplied in the form of autonomous or semi-autonomous obstacle avoidance systems. However, for rehabilitation or learning purposes, it would be of great benefit for wheelchair users to have a better understanding of the surrounding environment while driving. Therefore, another way of providing navigation support is to communicate information through a dedicated and adapted feedback interface. We here propose a framework in which feedback is provided by sending forces through the wheelchair controller as the user steers the wheelchair. This solution is based on a low complex optimization framework able to perform smooth trajectory correction and to provide obstacle avoidance. The impact of the proposed haptic guidance solution on user driving performance was assessed during this pilot study for validation purposes through an experiment with 4 able-bodied participants. They were asked to drive a power wheelchair on an obstacle course with and without activation of the force feedback. Results of this pilot study showed that the number of collisions significantly decreased while force feedback was activated, thus validating the proposed framework.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  isbn = {978-1-5386-6650-0},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/GZF82WF8/Devigne 等 - 2018 - Design of a Haptic Guidance Solution for Assisted .pdf}
}

@article{dingHumanintheloopOptimizationHip2018a,
  title = {Human-in-the-Loop Optimization of Hip Assistance with a Soft Exosuit during Walking},
  author = {Ding, Ye and Kim, Myunghee and Kuindersma, Scott and Walsh, Conor J.},
  date = {2018-02-28},
  journaltitle = {Science Robotics},
  shortjournal = {Sci. Robot.},
  volume = {3},
  number = {15},
  pages = {eaar5438},
  issn = {2470-9476},
  doi = {10.1126/scirobotics.aar5438},
  url = {https://www.science.org/doi/10.1126/scirobotics.aar5438},
  urldate = {2022-06-19},
  abstract = {Human-in-the-loop optimization achieved a substantial metabolic reduction and demonstrated the value of individualization.           ,              Wearable robotic devices have been shown to substantially reduce the energy expenditure of human walking. However, response variance between participants for fixed control strategies can be high, leading to the hypothesis that individualized controllers could further improve walking economy. Recent studies on human-in-the-loop (HIL) control optimization have elucidated several practical challenges, such as long experimental protocols and low signal-to-noise ratios. Here, we used Bayesian optimization—an algorithm well suited to optimizing noisy performance signals with very limited data—to identify the peak and offset timing of hip extension assistance that minimizes the energy expenditure of walking with a textile-based wearable device. Optimal peak and offset timing were found over an average of 21.4 ± 1.0 min and reduced metabolic cost by 17.4 ± 3.2\% compared with walking without the device (mean ± SEM), which represents an improvement of more than 60\% on metabolic reduction compared with state-of-the-art devices that only assist hip extension. In addition, our results provide evidence for participant-specific metabolic distributions with respect to peak and offset timing and metabolic landscapes, lending support to the hypothesis that individualized control strategies can offer substantial benefits over fixed control strategies. These results also suggest that this method could have practical impact on improving the performance of wearable robotic devices.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/I62GE9M8/Ding et al_2018_Human-in-the-loop optimization of hip assistance with a soft exosuit during.pdf}
}

@online{dongHuBoVLMUnifiedVisionLanguage2023,
  title = {{{HuBo-VLM}}: {{Unified Vision-Language Model}} Designed for {{HUman roBOt}} Interaction Tasks},
  shorttitle = {{{HuBo-VLM}}},
  author = {Dong, Zichao and Zhang, Weikun and Huang, Xufeng and Ji, Hang and Zhan, Xin and Chen, Junbo},
  date = {2023-08-23},
  eprint = {2308.12537},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.12537},
  urldate = {2024-01-13},
  abstract = {Human robot interaction is an exciting task, which aimed to guide robots following instructions from human. Since huge gap lies between human natural language and machine codes, end to end human robot interaction models is fair challenging. Further, visual information receiving from sensors of robot is also a hard language for robot to perceive. In this work, HuBo-VLM is proposed to tackle perception tasks associated with human robot interaction including object detection and visual grounding by a unified transformer based vision language model. Extensive experiments on the Talk2Car benchmark demonstrate the effectiveness of our approach. Code would be publicly available in https://github.com/dzcgaara/HuBo-VLM.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics,引用}
}

@article{dongMultimodalBrainComputer2022a,
  title = {A Multi-Modal Brain–Computer Interface Based on Threshold Discrimination and Its Application in Wheelchair Control},
  author = {Dong, Enzeng and Zhang, Haoran and Zhu, Lin and Du, Shengzhi and Tong, Jigang},
  date = {2022-10},
  journaltitle = {Cognitive Neurodynamics},
  shortjournal = {Cogn Neurodyn},
  volume = {16},
  number = {5},
  pages = {1123--1133},
  issn = {1871-4080, 1871-4099},
  doi = {10.1007/s11571-021-09779-7},
  url = {https://link.springer.com/10.1007/s11571-021-09779-7},
  urldate = {2023-12-23},
  abstract = {In this study, we propose a novel multi-modal brain–computer interface (BCI) system based on the threshold discrimination, which is proposed for the first time to distinguish between SSVEP and MI potentials. The system combines these two heterogeneous signals to increase the number of control commands and improve the performance of asynchronous control of external devices. In this research, an electric wheelchair is controlled as an example. The user can continuously control the wheelchair to turn left/right through motion imagination (MI) by imagining left/right-hand movement and generate another 6 commands for the wheelchair control by focusing on the SSVEP stimulation panel. Ten subjects participated in a MI training session and eight of them completed a mobile obstacle-avoidance experiment in a complex environment requesting high control accuracy for successful manipulation. Comparing with the single-modal BCI-controlled wheelchair system, the results demonstrate that the proposed multi-modal method is effective by providing more satisfactory control accuracy, and show the potential of BCI-controlled systems to be applied in complex daily tasks.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/2L3BIYGU/Dong 等 - 2022 - A multi-modal brain–computer interface based on th.pdf}
}

@article{dongStretchableHumanMachine2020,
  title = {Stretchable {{Human Machine Interface Based}} on {{Smart Glove Embedded With PDMS-CB Strain Sensors}}},
  author = {Dong, Wentao and Yang, Lin and Fortino, Giancarlo},
  date = {2020-07},
  journaltitle = {IEEE Sensors Journal},
  volume = {20},
  number = {14},
  pages = {8073--8081},
  issn = {1558-1748},
  doi = {10.1109/JSEN.2020.2982070},
  abstract = {Human machine interface (HMI) has recently received more and more attentions as it would provide a media for human to interact with outside environments to promote people’s lifestyles. Flexible and stretchable electronics have been widely laminated onto the surface of human skin, gloves, or other soft objects for collecting the deformation signal. The paper proposes an HMI based on stretchable smart glove embedded with soft piezoresistive strain sensors for signal classification and controlling the motion of robot fingers. The stretchable polydimethylsiloxane-carbon black (PDMS-CB) strain sensors satisfy larger deformation ({$>$}30\%) which is validated by FEM simulation and experiments. The morphology of the soft and complex objects is detected by the smart glove when fingers touch the objects. Feature signals are extracted with the different finger gestures by the soft strain sensors laminated onto different fingers. Human robot interaction (HRI) algorithm is proposed to analyze and recognize the finger gestures for controlling the motion of the robot fingers. Experiments demonstrate that the motion of robot finger is successfully controlled remotely by the smart glove embedded with PDMS-CB strain sensors. Exploring HRI capabilities into the stretchable smart glove represents promising research directions in the future.},
  eventtitle = {{{IEEE Sensors Journal}}},
  keywords = {Capacitive sensors,human machine interface,Intelligent sensors,PDMS-CB strain sensor,Piezoelectric transducers,Robot sensing systems,sensor arrays,smart glove,Smart sensor systems,Strain,stretchable electronics,引用},
  file = {/Users/liurongkai/Zotero/storage/YI3G84KA/9042856.html}
}

@inproceedings{dossantosIMUbasedTransparencyControl2022,
  title = {{{IMU-based Transparency Control}} of {{Exoskeletons Driven}} by {{Series Elastic Actuator}}},
  booktitle = {2022 {{IEEE}} 61st {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  author = {Dos Santos, Leonardo F. and Escalante, Felix M. and Siqueira, Adriano A. G. and Boaventura, Thiago},
  date = {2022-12-06},
  pages = {2594--2599},
  publisher = {{IEEE}},
  location = {{Cancun, Mexico}},
  doi = {10.1109/CDC51059.2022.9992650},
  url = {https://ieeexplore.ieee.org/document/9992650/},
  urldate = {2024-01-12},
  abstract = {Wearable devices such as rehabilitation robots, power augmentation exoskeletons, and haptic manipulators feature operation modes that need to mirror the user’s action as naturally as possible. By tracking such motions, the human-robot physical interaction is minimized, or, in other words, the device displays effusive mechanical transparency. The present work applies a transparency control framework based on inertial measurement units fixed on the user to a series elastic exoskeleton joint. This approach guarantees the robot’s transparent behavior without explicitly relying on force or human-robot interaction sensors. Instead, we used a state estimator to provide the human-related quantities needed for feedforward and feedback control. The proposed controller considers the dynamics of the series elastic actuator for two motor driver configurations: torque-based and velocity-based low-level control. Using a novel definition of the humanrobot transparency impedance, we designed and experimentally evaluated the performance of both controllers.},
  eventtitle = {2022 {{IEEE}} 61st {{Conference}} on {{Decision}} and {{Control}} ({{CDC}})},
  isbn = {978-1-66546-761-2},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/CQYAM3JN/Dos Santos 等 - 2022 - IMU-based Transparency Control of Exoskeletons Dri.pdf}
}

@article{enayatiSkillbasedHumanRobot2018,
  title = {Skill-Based Human–Robot Cooperation in Tele-Operated Path Tracking},
  author = {Enayati, Nima and Ferrigno, Giancarlo and De~Momi, Elena},
  date = {2018-06},
  journaltitle = {Autonomous Robots},
  shortjournal = {Auton Robot},
  volume = {42},
  number = {5},
  pages = {997--1009},
  issn = {0929-5593, 1573-7527},
  doi = {10.1007/s10514-017-9675-4},
  url = {http://link.springer.com/10.1007/s10514-017-9675-4},
  urldate = {2024-02-02},
  abstract = {This work proposes a shared-control tele-opera tion framework that adapts its cooperative properties to the estimated skill level of the operator. It is hypothesized that different aspects of an operator’s performance in executing a tele-operated path tracking task can be assessed through conventional machine learning methods using motion-based and task-related features. To identify performance measures that capture motor skills linked to the studied task, an experiment is conducted where users new to tele-operation, practice towards motor skill proficiency in 7 training sessions. A set of classifiers are then learned from the acquired data and selected features, which can generate a skill profile that comprises estimations of user’s various competences. Skill profiles are exploited to modify the behavior of the assistive robotic system accordingly with the objective of enhancing user experience by preventing unnecessary restriction for skilled users. A second experiment is implemented in which novice and expert users execute the path tracking on different pathways while being assisted by the robot according to their estimated skill profiles. Results validate the skill estimation method and hint at feasibility of shared-control customization in tele-operated path tracking.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TZJKCDGA/Enayati 等 - 2018 - Skill-based human–robot cooperation in tele-operat.pdf}
}

@article{faisalNoiseNervousSystem2008,
  title = {Noise in the Nervous System},
  author = {Faisal, A. Aldo and Selen, Luc P. J. and Wolpert, Daniel M.},
  date = {2008-04},
  journaltitle = {Nature reviews. Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {9},
  number = {4},
  eprint = {18319728},
  eprinttype = {pmid},
  pages = {292--303},
  issn = {1471-003X},
  doi = {10.1038/nrn2258},
  url = {10.1038/nrn2258},
  urldate = {2021-12-07},
  abstract = {Random disturbances of signals, termed ‘noise’, pose a fundamental problem for information processing and affect all aspects of nervous-system function. However, the nature, amount and impact of noise in the nervous system have only recently been addressed in a quantitative manner. Experimental and computational methods have shown that multiple noise sources contribute to cellular and behavioural trial-to-trial variability. We review the sources of noise in the nervous system, from the molecular to the behavioural level, and show how noise contributes to trial-to-trial variability. We highlight how noise affects neuronal networks and the principles the nervous system applies to counter detrimental effects of noise, and briefly discuss noise's potential benefits.},
  pmcid = {PMC2631351},
  keywords = {引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/DTRES6WW/Faisal et al_2008_Noise in the nervous system.pdf}
}

@unpublished{fallFlexibleModularBodyMachine2020,
  title = {A {{Flexible}} and {{Modular Body-Machine Interface}} for {{Individuals Living}} with {{Severe Disabilities}}},
  author = {Fall, Cheikh Latyr and Côté-Allard, Ulysse and Mascret, Quentin and Campeau-Lecours, Alexandre and Boukadoum, Mounir and Gosselin, Clément and Gosselin, Benoit},
  date = {2020-07-29},
  eprint = {2007.15032},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2007.15032},
  urldate = {2021-10-27},
  abstract = {This paper presents a control interface to translate the residual body motions of individuals living with severe disabilities, into control commands for body-machine interaction. A custom, wireless, wearable multi-sensor network is used to collect motion data from multiple points on the body in real-time. The solution proposed successfully leverage electromyography gesture recognition techniques for the recognition of inertial measurement units-based commands (IMU), without the need for cumbersome and noisy surface electrodes. Motion pattern recognition is performed using a computationally inexpensive classifier (Linear Discriminant Analysis) so that the solution can be deployed onto lightweight embedded platforms. Five participants (three able-bodied and two living with upperbody disabilities) presenting different motion limitations (e.g. spasms, reduced motion range) were recruited. They were asked to perform up to 9 different motion classes, including head, shoulder, finger, and foot motions, with respect to their residual functional capacities. The measured prediction performances show an average accuracy of 99.96\% for able-bodied individuals and 91.66\% for participants with upper-body disabilities. The recorded dataset has also been made available online to the research community. Proof of concept for the real-time use of the system is given through an assembly task replicating activities of daily living using the JACO arm from Kinova Robotics.},
  langid = {english},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Robotics,引用,有价值},
  file = {/Users/liurongkai/Zotero/storage/6T7QBIKD/Fall 等。 - 2020 - A Flexible and Modular Body-Machine Interface for .pdf}
}

@online{fangBehavioralIntentionPrediction2023,
  title = {Behavioral {{Intention Prediction}} in {{Driving Scenes}}: {{A Survey}}},
  shorttitle = {Behavioral {{Intention Prediction}} in {{Driving Scenes}}},
  author = {Fang, Jianwu and Wang, Fan and Xue, Jianru and Chua, Tat-seng},
  date = {2023-12-08},
  eprint = {2211.00385},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2211.00385},
  urldate = {2024-01-07},
  abstract = {In the driving scene, the road agents usually conduct frequent interactions and intention understanding of the surroundings. Ego-agent (each road agent itself) predicts what behavior will be engaged by other road users all the time and expects a shared and consistent understanding for safe movement. Behavioral Intention Prediction (BIP) simulates such a human consideration process and fulfills the early prediction of specific behaviors. Similar to other prediction tasks, such as trajectory prediction, data-driven deep learning methods have taken the primary pipeline in research. The rapid development of BIP inevitably leads to new issues and challenges. To catalyze future research, this work provides a comprehensive review of BIP from the available datasets, key factors and challenges, pedestrian-centric and vehicle-centric BIP approaches, and BIP-aware applications. Based on the investigation, data-driven deep learning approaches have become the primary pipelines. The behavioral intention types are still monotonous in most current datasets and methods (e.g., Crossing (C) and Not Crossing (NC) for pedestrians and Lane Changing (LC) for vehicles) in this field. In addition, for the safe-critical scenarios (e.g., near-crashing situations), current research is limited. Through this investigation, we identify open issues in behavioral intention prediction and suggest possible insights for future research.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/liurongkai/Zotero/storage/NGUDMUAD/Fang et al_2023_Behavioral Intention Prediction in Driving Scenes.pdf;/Users/liurongkai/Zotero/storage/VLFZQIAP/2211.html}
}

@article{flashCoordinationArmMovements1985,
  title = {The Coordination of Arm Movements: An Experimentally Confirmed Mathematical Model},
  shorttitle = {The Coordination of Arm Movements},
  author = {Flash, T and Hogan, N},
  date = {1985-07-01},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {5},
  number = {7},
  pages = {1688--1703},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.05-07-01688.1985},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.05-07-01688.1985},
  urldate = {2023-02-26},
  abstract = {This paper presents studies of the coordination of voluntary human arm movements. A mathematical model is formulated which is shown to predict both the qualitative features and the quantitative details observed experimentally in planar, multijoint arm movements. Coordination is modeled mathematically by defining an objective function, a measure of performance for any possible movement. The unique trajectory which yields the best performance is determined using dynamic optimization theory. In the work presented here, the objective function is the square of the magnitude of jerk (rate of change of acceleration) of the hand integrated over the entire movement. This is equivalent to assuming that a major goal of motor coordination is the production of the smoothest possible movement of the hand. Experimental observations of human subjects performing voluntary unconstrained movements in a horizontal plane are presented. They confirm the following predictions of the mathematical model: unconstrained point-to-point motions are approximately straight with bell-shaped tangential velocity profiles; curved motions (through an intermediate point or around an obstacle) have portions of low curvature joined by portions of high curvature; at points of high curvature, the tangential velocity is reduced; the durations of the lowcurvature portions are approximately equal.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/ZHUKA57C/Flash 和 Hogan - 1985 - The coordination of arm movements an experimental.pdf}
}

@inproceedings{fosterReflectanceFieldMap2023,
  title = {The {{Reflectance Field Map}}: {{Mapping Glass}} and {{Specular Surfaces}} in {{Dynamic Environments}}},
  shorttitle = {The {{Reflectance Field Map}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Foster, Paul and Johnson, Collin and Kuipers, Benjamin},
  date = {2023-05-29},
  pages = {8393--8399},
  publisher = {{IEEE}},
  location = {{London, United Kingdom}},
  doi = {10.1109/ICRA48891.2023.10161520},
  url = {https://ieeexplore.ieee.org/document/10161520/},
  urldate = {2023-12-22},
  abstract = {We present the Reflectance Field Map, a reliable real-time method for detecting shiny surfaces, like glass, metal, and mirrors, with lidar. The Reflectance Field Map combines the theory developed for Light Field Mapping, common in computer graphics, with occupancy grid mapping. Like early methods for sonar-based robot mapping, we show how the addition of angular viewpoint information to a standard 2D grid map enables robust mapping in the presence of specular reflections. However unlike previous approaches, our method works in dynamic environments. Additionally, unlike recent approaches for lidar-based mapping of specular surfaces, our approach is sensor-agnostic and has no reliance on either intensity or multi-return measurements. We demonstrate the ability of the Reflectance Field Map to accurately map a campus environment containing numerous pedestrians and significant plate glass, both straight and curved. The algorithm runs in real-time (75+Hz) on a single core of a standard desktop processor. An open source implementation of the algorithm is available at https://github.com/collinej/ reflectance\_field\_map.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {9798350323658},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/FVEP7FPI/Foster 等 - 2023 - The Reflectance Field Map Mapping Glass and Specu.pdf}
}

@article{galliQuantitativeAnalysisSit2008,
  title = {Quantitative Analysis of Sit to Stand Movement: {{Experimental}} Set-up Definition and Application to Healthy and Hemiplegic Adults},
  shorttitle = {Quantitative Analysis of Sit to Stand Movement},
  author = {Galli, M. and Cimolin, V. and Crivellini, M. and Campanini, I.},
  date = {2008-07},
  journaltitle = {Gait \& Posture},
  shortjournal = {Gait \& Posture},
  volume = {28},
  number = {1},
  pages = {80--85},
  issn = {09666362},
  doi = {10.1016/j.gaitpost.2007.10.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636207002585},
  urldate = {2023-12-29},
  abstract = {Rising from a chair or sit to stand (STS) is a movement with a great clinical interest: it is meaningful in order to evaluate motor control and stability in patients with functional limitations. STS requires some skills, as coordination between trunk and lower limbs movements, correction of muscles strength, control of equilibrium and stability and it is often considered into clinical evaluation scales of different pathologies. In literature, although some studies are focused on STS, the essential functions of standing up are not well standardized and uniformly defined: for this reason its application in clinical centres is difficult. In this study an experimental set-up for acquisition of STS movement which is suitable for clinical applications has been proposed: first, it was studied in healthy subjects, to define a normative database of this specific motor task, then in pathological subjects (adults with hemiplegia), to quantify their functional limitation, using quantitative kinematic and kinetic parameters. The results showed that this experimental set-up is effective both in healthy and in pathological subjects; some significant parameters were identified and calculated in order to characterise and quantify the functional limitation of patients.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/RZGMRAZK/Galli 等 - 2008 - Quantitative analysis of sit to stand movement Ex.pdf}
}

@article{gamsOnlineLearningModulation2009,
  title = {On-Line Learning and Modulation of Periodic Movements with Nonlinear Dynamical Systems},
  author = {Gams, Andrej and Ijspeert, Auke J and Schaal, Stefan and Lenarcˇicˇ, Jadran},
  date = {2009},
  journaltitle = {Auton Robot},
  pages = {21},
  langid = {english},
  keywords = {已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/9Q83SVBM/Gams 等。 - 2009 - On-line learning and modulation of periodic moveme.pdf}
}

@online{gaoPhysicallyGroundedVisionLanguage2023,
  title = {Physically {{Grounded Vision-Language Models}} for {{Robotic Manipulation}}},
  author = {Gao, Jensen and Sarkar, Bidipta and Xia, Fei and Xiao, Ted and Wu, Jiajun and Ichter, Brian and Majumdar, Anirudha and Sadigh, Dorsa},
  date = {2023-09-13},
  eprint = {2309.02561},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.02561},
  urldate = {2024-01-13},
  abstract = {Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 39.6K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, including generalization to held-out concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically-grounded VLM in an interactive framework with a large language model-based robotic planner, and show improved planning performance on tasks that require reasoning about physical object concepts, compared to baselines that do not leverage physically-grounded VLMs. We additionally illustrate the benefits of our physically-grounded VLM on a real robot, where it improves task success rates. We release our dataset and provide further details and visualizations of our results at https://iliad.stanford.edu/pg-vlm/.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics,引用},
  file = {/Users/liurongkai/Zotero/storage/HGWGTG7Q/Gao et al_2023_Physically Grounded Vision-Language Models for Robotic Manipulation.pdf;/Users/liurongkai/Zotero/storage/S374KF6Y/2309.html}
}

@article{geravandHumanSittostandTransfer2017,
  title = {Human Sit-to-Stand Transfer Modeling towards Intuitive and Biologically-Inspired Robot Assistance},
  author = {Geravand, Milad and Korondi, Peter Zeno and Werner, Christian and Hauer, Klaus and Peer, Angelika},
  date = {2017-03},
  journaltitle = {Autonomous Robots},
  shortjournal = {Auton Robot},
  volume = {41},
  number = {3},
  pages = {575--592},
  issn = {0929-5593, 1573-7527},
  doi = {10.1007/s10514-016-9553-5},
  url = {http://link.springer.com/10.1007/s10514-016-9553-5},
  urldate = {2023-11-23},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/EBYXYMYY/s10514-016-9553-5.pdf}
}

@inproceedings{gilliniAssistiveSharedControl2021,
  title = {An {{Assistive Shared Control Architecture}} for a {{Robotic Arm Using EEG-Based BCI}} with {{Motor Imagery}}},
  booktitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Gillini, Giuseppe and Lillo, Paolo Di and Arrichiello, Filippo},
  date = {2021-09},
  pages = {4132--4137},
  issn = {2153-0866},
  doi = {10.1109/IROS51168.2021.9636261},
  abstract = {The paper presents a shared control architecture for robotic systems commanded through a motor imagery based Brain-Computer Interface (BCI). The overall system is aimed at assisting people to perform teleoperated manipulation tasks, and it is structured so as to leave different levels of autonomy to the user depending on the actual stage of the task execution. The low-level part of the shared control architecture is also in charge of taking into account safety and operational tasks, such as to avoid collisions or to manage robot joint limits. The overall architecture has been realized by integrating control and perception software modules developed within the ROS environment, with the OpenVibe framework used to operate the BCI device. The effectiveness of the proposed architecture has been validated through experiments where a healthy user, wearing a Unicorn g.tec BCI, performs an assisted task through motor imagery sessions, with a 7 Degrees of Freedoms Kinova Jaco2 robotic arm.},
  eventtitle = {2021 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  keywords = {Brain-computer interfaces,Computer architecture,Manipulators,Performance evaluation,Safety,Software,Task analysis,引用},
  file = {/Users/liurongkai/Zotero/storage/8LGLQQJ7/Gillini et al_2021_An Assistive Shared Control Architecture for a Robotic Arm Using EEG-Based BCI.pdf;/Users/liurongkai/Zotero/storage/LXP87JBI/9636261.html}
}

@article{golubLearningInternalDynamicsa,
  title = {Learning an {{Internal Dynamics Model}} from {{Control Demonstration}}},
  author = {Golub, Matthew D and Chase, Steven M and Yu, Byron M},
  pages = {9},
  abstract = {Much work in optimal control and inverse control has assumed that the controller has perfect knowledge of plant dynamics. However, if the controller is a human or animal subject, the subject’s internal dynamics model may differ from the true plant dynamics. Here, we consider the problem of learning the subject’s internal model from demonstrations of control and knowledge of task goals. Due to sensory feedback delay, the subject uses an internal model to generate an internal prediction of the current plant state, which may differ from the actual plant state. We develop a probabilistic framework and exact EM algorithm to jointly estimate the internal model, internal state trajectories, and feedback delay. We applied this framework to demonstrations by a nonhuman primate of brain-machine interface (BMI) control. We discovered that the subject’s internal model deviated from the true BMI plant dynamics and provided significantly better explanation of the recorded neural control signals than did the true plant dynamics.},
  langid = {english},
  keywords = {已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/EC7P5AUB/Golub 等。 - Learning an Internal Dynamics Model from Control D.pdf}
}

@article{gongWhatItYou2020,
  title = {What {{Is It You Really Want}} of {{Me}}? {{Generalized Reward Learning}} with {{Biased Beliefs}} about {{Domain Dynamics}}},
  shorttitle = {What {{Is It You Really Want}} of {{Me}}?},
  author = {Gong, Ze and Zhang, Yu},
  date = {2020-04-03},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  shortjournal = {AAAI},
  volume = {34},
  number = {03},
  pages = {2485--2492},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v34i03.5630},
  url = {https://aaai.org/ojs/index.php/AAAI/article/view/5630},
  urldate = {2021-12-16},
  abstract = {Reward learning as a method for inferring human intent and preferences has been studied extensively. Prior approaches make an implicit assumption that the human maintains a correct belief about the robot’s domain dynamics. However, this may not always hold since the human’s belief may be biased, which can ultimately lead to a misguided estimation of the human’s intent and preferences, which is often derived from human feedback on the robot’s behaviors. In this paper, we remove this restrictive assumption by considering that the human may have an inaccurate understanding of the robot. We propose a method called Generalized Reward Learning with biased beliefs about domain dynamics (GeReL) to infer both the reward function and human’s belief about the robot in a Bayesian setting based on human ratings. Due to the complex forms of the posteriors, we formulate it as a variational inference problem to infer the posteriors of the parameters that govern the reward function and human’s belief about the robot simultaneously. We evaluate our method in a simulated domain and with a user study where the user has a bias based on the robot’s appearances. The results show that our method can recover the true human preferences while subject to such biased beliefs, in contrast to prior approaches that could have misinterpreted them completely.},
  langid = {english},
  keywords = {引用,有价值},
  file = {/Users/liurongkai/Zotero/storage/25AXZABT/Gong 和 Zhang - 2020 - What Is It You Really Want of Me Generalized Rewa.pdf}
}

@inproceedings{gopinathCustomizedHandlingUnintended2021,
  title = {Customized {{Handling}} of {{Unintended Interface Operation In Assistive Robots}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Gopinath, Deepak and Javaremi, Mahdieh Nejati and Argall, Brenna},
  date = {2021-05},
  pages = {10406--10412},
  issn = {2577-087X},
  doi = {10.1109/ICRA48506.2021.9561096},
  abstract = {We present an assistance system that reasons about a human’s intended actions during robot teleoperation in order to provide appropriate modifications on unintended behavior. Existing methods typically treat the human and control interface as a black box and assume the measured user input is noise-free, and use this signal to infer task-level human intent. We recognize that the signal measured through the interface is masked by the physical limitations of the user and the interface they are required to use. With this key insight, we model the human’s physical interaction with a control interface during robot teleoperation, and distinguish between interface-level intended and measured physical actions explicitly. By reasoning over the unobserved intentions using model-based inference techniques, our assistive system provides customized modifications on a user’s issued commands. We validate our algorithm both in simulation and with a 10-person human subject study in which we evaluate the performance of the proposed assistance paradigms. Our results show that the assistance paradigms helped to significantly reduce task completion time, number of mode switches, cognitive workload, and user frustration, and improve overall user satisfaction.},
  eventtitle = {2021 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {Automation,Cognition,Conferences,Graphical models,Inference algorithms,Probabilistic logic,Stochastic processes,引用},
  file = {/Users/liurongkai/Zotero/storage/2WTBFJMK/Gopinath et al_2021_Customized Handling of Unintended Interface Operation In Assistive Robots.pdf;/Users/liurongkai/Zotero/storage/WRJX3Z2G/9561096.html}
}

@article{gopinathHumanintheLoopOptimizationShared2017,
  title = {Human-in-the-{{Loop Optimization}} of {{Shared Autonomy}} in {{Assistive Robotics}}},
  author = {Gopinath, Deepak and Jain, Siddarth and Argall, Brenna D.},
  date = {2017-01},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {2},
  number = {1},
  pages = {247--254},
  issn = {2377-3766},
  doi = {10.1109/LRA.2016.2593928},
  url = {10.1109/LRA.2016.2593928},
  abstract = {In this paper, we propose a mathematical framework which formalizes user-driven customization of shared autonomy in assistive robotics as a nonlinear optimization problem. Our insight is to allow the end-user, rather than relying on standard optimization techniques, to perform the optimization procedure, thereby allowing us to leave the exact nature of the cost function indeterminate. We ground our formalism with an interactive optimization procedure that customizes control sharing using an assistive robotic arm. We also present a pilot study that explores interactive optimization with end-users. This study was performed with 17 subjects (4 with spinal cord injury, 13 without injury). Results show all subjects were able to converge to an assistance paradigm, suggesting the existence of optimal solutions. Notably, the amount of assistance was not always optimized for task performance. Instead, some subjects favored retaining more control during the execution over better task performance. The study supports the case for user-driven customization and provides guidance for its continued development and study.},
  eventtitle = {{{IEEE Robotics}} and {{Automation Letters}}},
  keywords = {Cost function,Human factors and human-in-the-loop,Optimal control,Performance evaluation,physically assistive devices,rehabilitation robotics,Robots,在读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/SWAYWGUH/Gopinath et al_2017_Human-in-the-Loop Optimization of Shared Autonomy in Assistive Robotics.pdf;/Users/liurongkai/Zotero/storage/VGHXX4VB/7518989.html}
}

@article{gordonHumanintheLoopOptimizationExoskeleton2022a,
  title = {Human-in-the-{{Loop Optimization}} of {{Exoskeleton Assistance Via Online Simulation}} of {{Metabolic Cost}}},
  author = {Gordon, Daniel F. N. and McGreavy, Christopher and Christou, Andreas and Vijayakumar, Sethu},
  date = {2022-06},
  journaltitle = {IEEE Transactions on Robotics},
  shortjournal = {IEEE Trans. Robot.},
  volume = {38},
  number = {3},
  pages = {1410--1429},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2021.3133137},
  url = {https://ieeexplore.ieee.org/document/9698243/},
  urldate = {2023-12-16},
  abstract = {Many assistive robotic devices have been developed to augment or assist human locomotion. Despite advancements in design and control algorithms, this task remains challenging. Human walking strategies are unique and complex, and assistance strategies based on the dynamics of unassisted locomotion typically offer only modest reductions to the metabolic cost of walking. Recently, human-in-the-loop (HIL) methodologies have been used to identify subject-specific assistive strategies, which offer significant improvements to energy savings. However, current implementations suffer from long measurement times, necessitating the use of low-dimensional control parameterizations, and possibly requiring multiday collection protocols to avoid subject fatigue. We present a HIL methodology, which optimizes the assistive torques provided by a powered hip exoskeleton. Using musculoskeletal modeling, we are able to evaluate simulated metabolic rate online. We applied our methodology to identify assistive torque profiles for seven subjects walking on a treadmill, and found greater reductions to metabolic cost when compared to generic or off-the-shelf controllers. In a secondary investigation, we directly compare simulated and measured metabolic rate for three subjects experiencing a range of assistance levels. The time investment required to identify assistance strategies via our protocol is significantly lower when compared to existing protocols relying on calorimetry. In the future, frameworks such as these could be used to enable shorter HIL protocols or exploit more complex control parameterizations for greater energy savings.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/DRS33NZN/Gordon 等 - 2022 - Human-in-the-Loop Optimization of Exoskeleton Assi.pdf}
}

@inproceedings{gordonLearningPersonalisedHuman2023a,
  title = {Learning {{Personalised Human Sit-to-Stand Motion Strategies}} via {{Inverse Musculoskeletal Optimal Control}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Gordon, Daniel F. N. and Christou, Andreas and Stouraitis, Theodoros and Gienger, Michael and Vijayakumar, Sethu},
  date = {2023-05-29},
  pages = {10497--10503},
  publisher = {{IEEE}},
  location = {{London, United Kingdom}},
  doi = {10.1109/ICRA48891.2023.10160411},
  url = {https://ieeexplore.ieee.org/document/10160411/},
  urldate = {2023-12-01},
  abstract = {Physically assistive robots and exoskeletons have great potential to help humans with a wide variety of collaborative tasks. However, a challenging aspect of the control of such devices is to accurately model or predict human behaviour, which can be highly individual and personalised. In this work, we implement a framework for learning subject-specific models of underlying human motion strategies using inverse musculoskeletal optimal control. We apply this framework to a specific motion task: the sit-to-stand transition. By collecting sitto-stand data from 4 subjects with and without perturbations, we show that humans modulate their sit-to-stand strategy in the presence of instability, and learn the corresponding models of these strategies. In the future, the personalised motion strategies resulting from this framework could be used to inform the design of real-time assistance strategies for humanrobot collaboration problems.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {9798350323658},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/AX7LAXUC/Gordon 等 - 2023 - Learning Personalised Human Sit-to-Stand Motion St.pdf}
}

@article{gouwandaIdentifyingGaitAsymmetry2011,
  title = {Identifying Gait Asymmetry Using Gyroscopes—{{A}} Cross-Correlation and {{Normalized Symmetry Index}} Approach},
  author = {Gouwanda, Darwin and Arosha Senanayake, S.M.N.},
  date = {2011-03},
  journaltitle = {Journal of Biomechanics},
  shortjournal = {Journal of Biomechanics},
  volume = {44},
  number = {5},
  pages = {972--978},
  issn = {00219290},
  doi = {10.1016/j.jbiomech.2010.12.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021929011000121},
  urldate = {2022-07-18},
  abstract = {Injury to a lower limb may disrupt natural walking and cause asymmetrical gait, therefore assessing the gait asymmetry has become one of the important procedures in gait analysis. This paper proposes the use of wireless gyroscopes as a new instrument to determine gait asymmetry. It also introduces two novel approaches: normalized cross-correlations (Ccnorm) and Normalized Symmetry Index (SInorm). Ccnorm evaluates the waveform patterns generated by the lower limb in each gait cycle. SInorm provides indications on the timing and magnitude of the bilateral differences between the limbs while addressing the drawbacks of the conventional methods. One-way ANOVA test reveals that Ccnorm can be considered as single value indicator that determines the gait asymmetry (po0.01). The experiment results showed that SInorm in asymmetrical gait were different from normal gait. SInorm in asymmetrical gait were found to be approximately 20\% greater than SInorm in normal gait during pre-swing and initial swing.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/G645NIQA/Gouwanda 和 Arosha Senanayake - 2011 - Identifying gait asymmetry using gyroscopes—A cros.pdf}
}

@inproceedings{haddadinNewInsightsConcerning2010,
  title = {New Insights Concerning Intrinsic Joint Elasticity for Safety},
  booktitle = {2010 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Haddadin, S and Albu-Schaffer, A and Eiberger, O and Hirzinger, G},
  date = {2010-10},
  pages = {2181--2187},
  publisher = {{IEEE}},
  location = {{Taipei}},
  doi = {10.1109/IROS.2010.5652037},
  url = {http://ieeexplore.ieee.org/document/5652037/},
  urldate = {2024-01-14},
  abstract = {In this paper we present various new insights on the effect intrinsic joint elasticity has on safety in pHRI. We address the fact that the intrinsic safety of elastic mechanisms has been discussed rather one sided in favor of this new designs and intend to give a more differentiated view on the problem. An important result is that intrinsic joint elasticity does not reduce the Head Injury Criterion or impact forces compared to conventional actuation with some considerable elastic behavior in the joint, if considering full scale robots. We also elaborate conditions under which intrinsically compliant actuation is potentially more dangerous than rigid one. Furthermore, we present collision detection and reaction schemes for such mechanisms and verify their effectiveness experimentally.},
  eventtitle = {2010 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}} 2010)},
  isbn = {978-1-4244-6674-0},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/37BY9A7I/Haddadin 等 - 2010 - New insights concerning intrinsic joint elasticity.pdf}
}

@article{hagenowCorrectiveSharedAutonomy2021,
  title = {Corrective {{Shared Autonomy}} for {{Addressing Task Variability}}},
  author = {Hagenow, Michael and Senft, Emmanuel and Radwin, Robert and Gleicher, Michael and Mutlu, Bilge and Zinn, Michael},
  date = {2021-04},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {2},
  pages = {3720--3727},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3064500},
  abstract = {Many tasks, particularly those involving interaction with the environment, are characterized by high variability, making robotic autonomy difficult. One flexible solution is to introduce the input of a human with superior experience and cognitive abilities as part of a shared autonomy policy. However, current methods for shared autonomy are not designed to address the wide range of necessary corrections (e.g., positions, forces, execution rate, etc.) that the user may need to provide to address task variability. In this letter, we present corrective shared autonomy, where users provide corrections to key robot state variables on top of an otherwise autonomous task model. We provide an instantiation of this shared autonomy paradigm and demonstrate its viability and benefits such as low user effort and physical demand via a system-level user study on three tasks involving variability situated in aircraft manufacturing.},
  eventtitle = {{{IEEE Robotics}} and {{Automation Letters}}},
  keywords = {Fasteners,Force,Human-robot collaboration,Kinematics,Real-time systems,Robot kinematics,Robots,Task analysis,telerobotics and teleoperation,在读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/KVFIEAME/Hagenow et al_2021_Corrective Shared Autonomy for Addressing Task Variability.pdf;/Users/liurongkai/Zotero/storage/P2Y64KSH/9372859.html}
}

@article{hartmanHumanMachineInterfaceSmart2019,
  title = {Human-{{Machine Interface}} for a {{Smart Wheelchair}}},
  author = {Hartman, Amiel and Nandikolla, Vidya K.},
  date = {2019-01-02},
  journaltitle = {Journal of Robotics},
  shortjournal = {Journal of Robotics},
  volume = {2019},
  pages = {1--11},
  issn = {1687-9600, 1687-9619},
  doi = {10.1155/2019/4837058},
  url = {https://www.hindawi.com/journals/jr/2019/4837058/},
  urldate = {2023-12-20},
  abstract = {The paper describes the integration of hardware and software with sensor technology and computer processing to develop the next generation intelligent wheelchair. The focus is a computer cluster design to test high performance computing for smart wheelchair operation and human interaction. The LabVIEW cluster is developed for real-time autonomous path planning and sensor data processing. Four small form factor computers are connected over a Gigabit Ethernet local area network to form the computer cluster. Autonomous programs are distributed across the cluster for increased task parallelism to improve processing time performance               .               The distributed programs operating frequency for path planning and motion control is 50Hz and 12.3Hz for 0.3 megapixel robot vision system. To monitor the operation and control of the distributed LabVIEW code, network automation is integrated into the cluster software along with a performance monitor. A link between the computer motion control program and the wheelchair joystick control of the drive train is developed for the computer control interface. A perception sensor array and control circuitry is integrated with the computer system to detect and respond to the wheelchair environment. Multiple cameras are used for image processing and scanning laser rangefinder sensors for obstacle avoidance in the cluster program. A centralized power system is integrated to power the smart wheelchair along with the cluster and sensor feedback system. The on board computer system is evaluated for cluster processing performance for the smart wheelchair, incorporating camera machine vision and LiDAR perception for terrain obstacle detection, operating in urban scenarios.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/ZRD8FMFI/Hartman 和 Nandikolla - 2019 - Human-Machine Interface for a Smart Wheelchair.pdf}
}

@article{heidariKneeOsteoarthritisPrevalence2011,
  title = {Knee Osteoarthritis Prevalence, Risk Factors, Pathogenesis and Features: {{Part I}}},
  shorttitle = {Knee Osteoarthritis Prevalence, Risk Factors, Pathogenesis and Features},
  author = {Heidari, Behzad},
  date = {2011},
  journaltitle = {Caspian Journal of Internal Medicine},
  shortjournal = {Caspian J Intern Med},
  volume = {2},
  number = {2},
  eprint = {24024017},
  eprinttype = {pmid},
  pages = {205--212},
  issn = {2008-6164},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3766936/},
  urldate = {2024-02-19},
  abstract = {Osteoarthritis (OA) a common disease of aged population and one of the leading causes of disability. Incidence of knee OA is rising by increasing average age of general population. Age, weight, trauma to joint due to repetiting movements in particular squatting and kneeling are common risk factors of knee OA. Several factors including cytokines, leptin, and mechanical forces are pathogenic factors of knee OA. In patients with knee pain attribution of pain to knee OA should be considered with caution. Since a proportion of knee OA are asymptomatic and in a number of patients identification of knee OA is not possible due to low sensitivity of radiographic examination. In this review data presented in regard to prevalence, pathogenesis, risk factors.},
  pmcid = {PMC3766936},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/JXZLC5WK/Heidari - 2011 - Knee osteoarthritis prevalence, risk factors, path.pdf}
}

@article{heSurveyHumancenteredIntelligent2017b,
  title = {A Survey of Human-Centered Intelligent Robots: Issues and Challenges},
  shorttitle = {A Survey of Human-Centered Intelligent Robots},
  author = {He, Wei and Li, Zhijun and Chen, C. L. Philip},
  date = {2017},
  journaltitle = {IEEE/CAA Journal of Automatica Sinica},
  shortjournal = {IEEE/CAA J. Autom. Sinica},
  volume = {4},
  number = {4},
  pages = {602--609},
  issn = {2329-9266, 2329-9274},
  doi = {10.1109/JAS.2017.7510604},
  url = {https://ieeexplore.ieee.org/document/8039018/},
  urldate = {2024-01-08},
  abstract = {Intelligent techniques foster the dissemination of new discoveries and novel technologies that advance the ability of robots to assist and support humans. The human-centered intelligent robot has become an important research field that spans all of the robot capabilities including navigation, intelligent control, pattern recognition and human-robot interaction. This paper focuses on the recent achievements and presents a survey of existing works on human-centered robots. Furthermore, we provide a comprehensive survey of the recent development of the human-centered intelligent robot and discuss the issues and challenges in the field.},
  langid = {english},
  keywords = {在读,引用,有价值},
  file = {/Users/liurongkai/Zotero/storage/5VUCLLE9/He 等 - 2017 - A survey of human-centered intelligent robots iss.pdf}
}

@article{hidayahGaitAdaptationUsing2020,
  title = {Gait {{Adaptation Using}} a {{Cable-Driven Active Leg Exoskeleton}} ({{C-ALEX}}) {{With Post-Stroke Participants}}},
  author = {Hidayah, Rand and Bishop, Lauri and Jin, Xin and Chamarthy, Siddharth and Stein, Joel and Agrawal, Sunil K.},
  date = {2020-09},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  shortjournal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
  volume = {28},
  number = {9},
  pages = {1984--1993},
  issn = {1534-4320, 1558-0210},
  doi = {10.1109/TNSRE.2020.3009317},
  url = {https://ieeexplore.ieee.org/document/9140030/},
  urldate = {2023-12-16},
  abstract = {Individuals with chronic hemiparesis poststroke exhibit gait impairments that require functional rehabilitation through training. Exoskeletal robotic assistive devices can provide a user with continuous assistance but impose movement restrictions. There are currently devices that allow unrestricted movement but provide assistance only intermittently at specific points of the gait cycle. Our design, a cable-driven active leg exoskeleton (C-ALEX), allows the user both unrestricted movement and continuous force assistance throughout the gait cycle to assist the user in new walking patterns. In this study, we assessed the ability of C-ALEX to induce a change in the walking patterns of ten post-stroke participants using a single-session training protocol. The ability of C-ALEX to accurately provide forces and torques in the desired directions was also evaluated to compare its design performance to traditional rigid-link designs. Participants were able to reach 91\% ± 12\% of their target step length and 89\% ± 13 \% of their target step height. The achieved step parameters differed significantly from participant baselines (p {$<$} 0.05). To quantify the performance, the forces in each cable’s out of the plane movements were evaluated relative to the in-plane desired cable tension magnitudes. This corresponded to an error of under 2Nm in the desired controlled joint torques. This error magnitude is low compared to the system command torques and typical adult biological torques during walking (2-4\%).},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/VLH7VLGY/Hidayah 等 - 2020 - Gait Adaptation Using a Cable-Driven Active Leg Ex.pdf}
}

@inproceedings{hong-guljunWalkingSittostandSupport2011,
  title = {Walking and Sit-to-Stand Support System for Elderly and Disabled},
  booktitle = {2011 {{IEEE International Conference}} on {{Rehabilitation Robotics}}},
  author = {{Hong-Gul Jun} and {Yoon-Young Chang} and {Byung-Ju Dan} and {Byeong-Rim Jo} and {Byung-Hoon Min} and {Hyunseok Yang} and {Won-Kyung Song} and {Jongbae Kim}},
  date = {2011-06},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Zurich}},
  doi = {10.1109/ICORR.2011.5975365},
  url = {http://ieeexplore.ieee.org/document/5975365/},
  urldate = {2023-12-27},
  eventtitle = {2011 {{IEEE}} 12th {{International Conference}} on {{Rehabilitation Robotics}}: {{Reaching Users}} \& the {{Community}} ({{ICORR}} 2011)},
  isbn = {978-1-4244-9862-8 978-1-4244-9863-5 978-1-4244-9861-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/5EZRPS88/Hong-Gul Jun 等 - 2011 - Walking and sit-to-stand support system for elderl.pdf}
}

@article{HuangJiQiRenYunDongGuiJiDeMoFangXueXiZongShu,
  title = {机器人运动轨迹的模仿学习综述},
  author = {黄, 艳龙 and 徐, 德 and 谭, 民},
  journaltitle = {自动化学报},
  pages = {1--20},
  issn = {0254-4156},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CAPJ&dbname=CAPJLAST&filename=MOTO20210507002&v=},
  abstract = {作为机器人技能学习中的一个重要分支,模仿学习近年来在机器人系统中得到了广泛的应用.模仿学习能够将人类的技能以一种相对直接的方式迁移到机器人系统中,其思路是先从少量示教样本中提取相应的运动特征,然后将该特征泛化到新的情形.本文针对机器人运动轨迹的模仿学习进行综述.首先详细解释模仿学习中的技能泛化、收敛性和外插等基本问题;其次从原理上对动态运动基元、概率运动基元和核化运动基元等主要的模仿学习算法进行介绍;然后深入地讨论模仿学习中姿态和刚度矩阵的学习问题、协同和不确定性预测的问题以及人机交互中的模仿学习等若干关键问题;最后本文探讨了结合因果推理的模仿学习等几个未来的发展方向.},
  langid = {chinese},
  keywords = {imitation learning,movement primitive,trajectory learning,已读,引用,有价值,机器人技能学习,模仿学习,综述,轨迹学习 Robot learning,运动基元,重要文章},
  annotation = {{$<$}北大核心, EI, CSCD{$>$}},
  file = {/Users/liurongkai/Zotero/storage/XDFIU7LD/机器人运动轨迹的模仿学习综述_黄艳龙.pdf}
}

@article{huangKernelizedMovementPrimitives2019,
  title = {Kernelized Movement Primitives},
  author = {Huang, Yanlong and Rozo, Leonel and Silvério, João and Caldwell, Darwin G},
  date = {2019-06},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {38},
  number = {7},
  pages = {833--852},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364919846363},
  url = {http://journals.sagepub.com/doi/10.1177/0278364919846363},
  urldate = {2024-02-03},
  abstract = {Imitation learning has been studied widely as a convenient way to transfer human skills to robots. This learning approach is aimed at extracting relevant motion patterns from human demonstrations and subsequently applying these patterns to different situations. Despite the many advancements that have been achieved, solutions for coping with unpredicted situations (e.g., obstacles and external perturbations) and high-dimensional inputs are still largely absent. In this paper, we propose a novel kernelized movement primitive (KMP), which allows the robot to adapt the learned motor skills and fulfill a variety of additional constraints arising over the course of a task. Specifically, KMP is capable of learning trajectories associated with high-dimensional inputs owing to the kernel treatment, which in turn renders a model with fewer open parameters in contrast to methods that rely on basis functions. Moreover, we extend our approach by exploiting local trajectory representations in different coordinate systems that describe the task at hand, endowing KMP with reliable extrapolation capabilities in broader domains. We apply KMP to the learning of time-driven trajectories as a special case, where a compact parametric representation describing a trajectory and its first-order derivative is utilized. In order to verify the effectiveness of our method, several examples of trajectory modulations and extrapolations associated with time inputs, as well as trajectory adaptations with high-dimensional inputs are provided.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/PCSZX3DP/Huang et al_2019_Kernelized movement primitives.pdf}
}

@inproceedings{huangLearningbasedWalkingAssistance2018,
  title = {Learning-Based {{Walking Assistance Control Strategy}} for a {{Lower Limb Exoskeleton}} with {{Hemiplegia Patients}}},
  booktitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Huang, Rui and Peng, Zhinan and Cheng, Hong and Hu, Jiangping and Qiu, Jing and Zou, Chaobin and Chen, Qiming},
  date = {2018-10},
  pages = {2280--2285},
  issn = {2153-0866},
  doi = {10.1109/IROS.2018.8594464},
  url = {10.1109/IROS.2018.8594464},
  abstract = {Lower exoskeleton has gained considerable interests in walking assistance applications for both paraplegia and hemiplegia patients. In walking assistance of hemiplegia patients, the exoskeleton should have the ability to control the affected leg to follow the unaffected leg's motion naturally. One critical issue of walking assistance for hemiplegia patients is how to adapt the controller of both lower limbs with different patients. This paper presents a novel learning-based walking assistance control strategy for lower exoskeleton with hemiplegia patients. In the proposed control strategy, we modeled the control system of lower exoskeleton with hemiplegia patient as a Leader-Follower Multi-Agent System (LF-MAS). In order to adapt different patients with different conditions, reinforcement learning framework is utilized to adapt controllers online. In reinforcement learning framework with LF-MAS, we employed a Policy Iteration Adaptive Dynamic Programming (PI-ADP) algorithm, which aims to achieve better tracking control performance for lower exoskeleton with hemiplegia patient. We demonstrate the efficiency of proposed learning-based walking assistance control strategy in an exoskeleton system with healthy subjects who simulate hemiplegia patients. Experimental results indicate that the proposed control strategy can adapt different pilots with good tracking performance.},
  eventtitle = {2018 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  keywords = {Control systems,Cost function,Exoskeletons,Hemiplegia,Heuristic algorithms,Leader-Follower Multi-Agent System,Legged locomotion,Lower Exoskeleton,Multi-agent systems,Reinforcement learning,Reinforcement Learning,Walking Assistance Strategy,引用},
  file = {/Users/liurongkai/Zotero/storage/W3398TJM/Huang et al_2018_Learning-based Walking Assistance Control Strategy for a Lower Limb Exoskeleton.pdf;/Users/liurongkai/Zotero/storage/7E7FGE22/8594464.html}
}

@online{huangVoxPoserComposable3D2023,
  title = {{{VoxPoser}}: {{Composable 3D Value Maps}} for {{Robotic Manipulation}} with {{Language Models}}},
  shorttitle = {{{VoxPoser}}},
  author = {Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  date = {2023-11-02},
  eprint = {2307.05973},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.05973},
  urldate = {2024-01-13},
  abstract = {Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck. In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects. We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction. More importantly, by leveraging their code-writing capabilities, they can interact with a vision-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent. The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop robot trajectories with robustness to dynamic perturbations. We further demonstrate how the proposed framework can benefit from online experiences by efficiently learning a dynamics model for scenes that involve contact-rich interactions. We present a large-scale study of the proposed method in both simulated and real-robot environments, showcasing the ability to perform a large variety of everyday manipulation tasks specified in free-form natural language. Videos and code at https://voxposer.github.io},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics,引用}
}

@article{ijspeertDynamicalMovementPrimitives2013a,
  title = {Dynamical {{Movement Primitives}}: {{Learning Attractor Models}} for {{Motor Behaviors}}},
  shorttitle = {Dynamical {{Movement Primitives}}},
  author = {Ijspeert, Auke Jan and Nakanishi, Jun and Hoffmann, Heiko and Pastor, Peter and Schaal, Stefan},
  date = {2013-02},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {25},
  number = {2},
  pages = {328--373},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/NECO_a_00393},
  url = {https://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00393},
  urldate = {2020-11-04},
  abstract = {Nonlinear dynamical systems have been used in many disciplines to model complex behaviors, including biological motor control, robotics, perception, economics, traffic prediction, and neuroscience. While often the unexpected emergent behavior of nonlinear systems is the focus of investigations, it is of equal importance to create goal-directed behavior (e.g., stable locomotion from a system of coupled oscillators under perceptual guidance). Modeling goal-directed behavior with nonlinear systems is, however, rather difficult due to the parameter sensitivity of these systems, their complex phase transitions in response to subtle parameter changes, and the difficulty of analyzing and predicting their long-term behavior; intuition and time-consuming parameter tuning play a major role. This letter presents and reviews dynamical movement primitives, a line of research for modeling attractor behaviors of autonomous nonlinear dynamical systems with the help of statistical learning techniques. The essence of our approach is to start with a simple dynamical system, such as a set of linear differential equations, and transform those into a weakly nonlinear system with prescribed attractor dynamics by means of a learnable autonomous forcing term. Both point attractors and limit cycle attractors of almost arbitrary complexity can be generated. We explain the design principle of our approach and evaluate its properties in several example applications in motor control and robotics.},
  langid = {english},
  keywords = {在读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/ULXQI4DW/Ijspeert 等。 - 2013 - Dynamical Movement Primitives Learning Attractor .pdf}
}

@inproceedings{inhokimKinematicAnalysisSittostand2011,
  title = {Kinematic Analysis of Sit-to-Stand Assistive Device for the Elderly and Disabled},
  booktitle = {2011 {{IEEE International Conference}} on {{Rehabilitation Robotics}}},
  author = {{Inho Kim} and {Woonghee Cho} and {Gyunghwan Yuk} and {Hyunseok Yang} and {Byeong-Rim Jo} and {Byung-Hoon Min}},
  date = {2011-06},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Zurich}},
  doi = {10.1109/ICORR.2011.5975438},
  url = {http://ieeexplore.ieee.org/document/5975438/},
  urldate = {2023-12-27},
  abstract = {This paper introduces a robotic walking and sit-tostand support system, Smart Mobile Walker(SMW), and presents kinematic analysis of the system. For supporting person’s sit-tostand movement, the motion of SMW is modeled by the analysis of kinematics. The results of analysis are used for simulations and its feasibility is investigated by simulations. The feasibility shows our analysis of kinematics can be applied as a base of making optimal motion trajectory for helping sit-to-stand.},
  eventtitle = {2011 {{IEEE}} 12th {{International Conference}} on {{Rehabilitation Robotics}}: {{Reaching Users}} \& the {{Community}} ({{ICORR}} 2011)},
  isbn = {978-1-4244-9862-8 978-1-4244-9863-5 978-1-4244-9861-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/U3PF36ZN/Inho Kim 等 - 2011 - Kinematic analysis of sit-to-stand assistive devic.pdf}
}

@article{jainProbabilisticHumanIntent2020,
  title = {Probabilistic {{Human Intent Recognition}} for {{Shared Autonomy}} in {{Assistive Robotics}}},
  author = {Jain, Siddarth and Argall, Brenna},
  date = {2020-01-31},
  journaltitle = {ACM Transactions on Human-Robot Interaction},
  shortjournal = {J. Hum.-Robot Interact.},
  volume = {9},
  number = {1},
  pages = {1--23},
  issn = {2573-9522},
  doi = {10.1145/3359614},
  url = {https://dl.acm.org/doi/10.1145/3359614},
  urldate = {2022-01-13},
  abstract = {Effective human-robot collaboration in shared autonomy requires reasoning about the intentions of the human partner. To provide meaningful assistance, the autonomy has to first correctly predict, or infer, the intended goal of the human collaborator. In this work, we present a mathematical formulation for intent inference during assistive teleoperation under shared autonomy. Our recursive Bayesian filtering approach models and fuses multiple non-verbal observations to probabilistically reason about the intended goal of the user without explicit communication. In addition to contextual observations, we model and incorporate the human agent’s behavior as goal-directed actions with adjustable rationality to inform intent recognition. Furthermore, we introduce a user-customized optimization of this adjustable rationality to achieve user personalization. We validate our approach with a human subjects study that evaluates intent inference performance under a variety of goal scenarios and tasks. Importantly, the studies are performed using multiple control interfaces that are typically available to users in the assistive domain, which differ in the continuity and dimensionality of the issued control signals. The implications of the control interface limitations on intent inference are analyzed. The study results show that our approach in many scenarios outperforms existing solutions for intent inference in assistive teleoperation and otherwise performs comparably. Our findings demonstrate the benefit of probabilistic modeling and the incorporation of human agent behavior as goal-directed actions where the adjustable rationality model is user customized. Results further show that the underlying intent inference approach directly affects shared autonomy performance, as do control interface limitations.},
  langid = {english},
  keywords = {已读,感兴趣的,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/ZAIC9THU/Jain 和 Argall - 2020 - Probabilistic Human Intent Recognition for Shared .pdf}
}

@article{javdaniSharedAutonomyHindsight2018,
  title = {Shared Autonomy via Hindsight Optimization for Teleoperation and Teaming},
  author = {Javdani, Shervin and Admoni, Henny and Pellegrinelli, Stefania and Srinivasa, Siddhartha S. and Bagnell, J. Andrew},
  date = {2018-06},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {37},
  number = {7},
  pages = {717--742},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364918776060},
  url = {http://journals.sagepub.com/doi/10.1177/0278364918776060},
  urldate = {2022-11-23},
  abstract = {In shared autonomy, a user and autonomous system work together to achieve shared goals. To collaborate effectively, the autonomous system must know the user’s goal. As such, most prior works follow a predict-then-act model, first predicting the user’s goal with high confidence, then assisting given that goal. Unfortunately, confidently predicting the user’s goal may not be possible until they have nearly achieved it, causing predict-then-act methods to provide little assistance. However, the system can often provide useful assistance even when confidence for any single goal is low (e.g. move towards multiple goals). In this work, we formalize this insight by modeling shared autonomy as a partially observable Markov decision process (POMDP), providing assistance that minimizes the expected cost-to-go with an unknown goal. As solving this POMDP optimally is intractable, we use hindsight optimization to approximate. We apply our framework to both shared-control teleoperation and human–robot teaming. Compared with predict-then-act methods, our method achieves goals faster, requires less user input, decreases user idling time, and results in fewer user–robot collisions.},
  langid = {english},
  keywords = {在读,感兴趣的,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/PHC83R9Q/Javdani 等 - 2018 - Shared autonomy via hindsight optimization for tel.pdf}
}

@inproceedings{jinSoftSensingShirt2020,
  title = {Soft {{Sensing Shirt}} for {{Shoulder Kinematics Estimation}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Jin, Y. and Glover, C. M. and Cho, H. and Araromi, O. A. and Graule, M. A. and Li, N. and Wood, R. J. and Walsh, C. J.},
  date = {2020-05},
  pages = {4863--4869},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9196586},
  url = {10.1109/ICRA40945.2020.9196586},
  abstract = {Soft strain sensors have been explored as an unobtrusive approach for wearable motion tracking. However, accurate tracking of multi degree-of-freedom (DOF) noncyclic joint movements remains a challenge. This paper presents a soft sensing shirt for tracking shoulder kinematics of both cyclic and random arm movements in 3 DOFs: adduction/abduction, horizontal flexion/extension, and internal/external rotation. The sensing shirt consists of 8 textile-based capacitive strain sensors sewn around the shoulder joint that communicate to a customized readout electronics board through sewn micro-coaxial cables. An optimized sensor design includes passive shielding and demonstrates high linearity and low hysteresis, making it suitable for wearable motion tracking. In a study with a single human subject, we evaluated the tracking capability of the integrated shirt in comparison with a ground truth optical motion capture system. An ensemble-based regression algorithm was implemented in post-processing to estimate joint angles and angular velocities from the strain sensor data. Results demonstrated root mean square errors (RMSEs) less than 4.5° for joint angle estimation and normalized root mean square errors (NRMSEs) less than 4\% for joint velocity estimation. Furthermore, we applied a recursive feature elimination (RFE)-based sensor selection analysis to down select the number of sensors for future shirt designs. This sensor selection analysis found that 5 sensors out of 8 were sufficient to generate comparable accuracies.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {biomechanics,biomedical measurement,capacitive sensors,Capacitive sensors,coaxial cables,customized readout electronics board,cyclic arm movements,Electrodes,ground truth optical motion capture system,inertial systems,joint angle estimation,joint velocity estimation,kinematics,mean square error methods,motion measurement,multidegree-of-freedom noncyclic joint movements,noncyclic joint movements,normalized root mean square errors,patient monitoring,patient rehabilitation,random arm movements,readout electronics,recursive feature elimination-based sensor selection analysis,regression analysis,Robot sensing systems,sewn microcoaxial cables,Shoulder,shoulder joint,shoulder kinematics estimation,soft strain sensors,Strain,strain sensor data,strain sensors,textile-based capacitive strain sensors,Tracking,unobtrusive approach,wearable motion tracking,已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/LGYGJNCF/Jin et al_2020_Soft Sensing Shirt for Shoulder Kinematics Estimation.pdf;/Users/liurongkai/Zotero/storage/D239D48T/9196586.html}
}

@article{jorgensenRecoveryWalkingFunction1995,
  title = {Recovery of Walking Function in Stroke Patients: {{The}} Copenhagen Stroke Study},
  shorttitle = {Recovery of Walking Function in Stroke Patients},
  author = {Jørgensen, Henrik S. and Nakayama, Hirofumi and Raaschou, Hans O. and Olsen, Tom S.},
  date = {1995-01},
  journaltitle = {Archives of Physical Medicine and Rehabilitation},
  shortjournal = {Archives of Physical Medicine and Rehabilitation},
  volume = {76},
  number = {1},
  pages = {27--32},
  issn = {00039993},
  doi = {10.1016/S0003-9993(95)80038-7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0003999395800387},
  urldate = {2022-06-16},
  langid = {english},
  keywords = {引用}
}

@article{kalitaDevelopmentActiveLower2021,
  title = {Development of {{Active Lower Limb Robotic-Based Orthosis}} and {{Exoskeleton Devices}}: {{A Systematic Review}}},
  shorttitle = {Development of {{Active Lower Limb Robotic-Based Orthosis}} and {{Exoskeleton Devices}}},
  author = {Kalita, Bhaben and Narayan, Jyotindra and Dwivedy, Santosha Kumar},
  date = {2021-07},
  journaltitle = {International Journal of Social Robotics},
  shortjournal = {Int J of Soc Robotics},
  volume = {13},
  number = {4},
  pages = {775--793},
  issn = {1875-4791, 1875-4805},
  doi = {10.1007/s12369-020-00662-9},
  url = {https://link.springer.com/10.1007/s12369-020-00662-9},
  urldate = {2023-12-16},
  abstract = {The basic routine movements for elderly people are not easily accessible due to the weak muscles and impaired nerves in their lower extremity. In the last few years, many robotic-based rehabilitation devices, like orthosis and exoskeletons, have been designed and developed by researchers to provide locomotion assistance to support gait behavior and to perform daily activities for elderly people. However, there is still a need for improvement in the design, actuation and control of these devices for making them cost-effective in the worldwide market. In this work, a systematic review is presented on available lower limb orthosis and exoskeleton devices, to date. The devices are broadly reviewed according to joint types, actuation modes and control strategies. Furthermore, tabular comparisons have also been presented with the types and applications of these devices. Finally, the needful improvements for realizing the efficacy of lower limb rehabilitation devices are discussed along with the development stage. This review will help the designers and researchers to develop an efficient robotic device for the rehabilitation of the lower limb.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/P4TK5RDU/Kalita 等 - 2021 - Development of Active Lower Limb Robotic-Based Ort.pdf}
}

@inproceedings{kawamotoDevelopmentAssistController2014a,
  title = {Development of an Assist Controller with Robot Suit {{HAL}} for Hemiplegic Patients Using Motion Data on the Unaffected Side},
  booktitle = {2014 36th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  author = {Kawamoto, Hiroaki and Kandone, Hideki and Sakurai, Takeru and Ariyasu, Ryohei and Ueno, Yukiko and Eguchi, Kiyoshi and Sankai, Yoshiyuki},
  date = {2014},
  pages = {3077--3080},
  issn = {1558-4615},
  doi = {10.1109/EMBC.2014.6944273},
  abstract = {Among several characteristics seen in gait of hemiplegic patients after stroke, symmetry is known to be an indicator of the degree of impairment of walking ability. This paper proposes a control method for a wearable type lower limb motion assist robot to realize spontaneous symmetric gait for these individuals. This control method stores the motion of the unaffected limb during swing and then provides motion support on the affected limb during the subsequent swing using the stored pattern to realize symmetric gait based on spontaneous limb swing. This method is implemented on the robot suit HAL (Hybrid Assistive Limbs). Clinical tests were conducted in order to assess the feasibility of the control method. Our case study involved participation of one chronic stroke patient who was not able to flex his right knee. As a result, the walking support for hemiplegic leg provided by the HAL improved the subject's gait symmetry. The feasibility study showed promising basis for the future clinical study.},
  eventtitle = {2014 36th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  keywords = {Foot,Hip,Joints,Knee,Legged locomotion,Robot sensing systems,引用,有价值},
  file = {/Users/liurongkai/Zotero/storage/H6K7HEY2/Kawamoto et al_2014_Development of an assist controller with robot suit HAL for hemiplegic patients.pdf;/Users/liurongkai/Zotero/storage/M54NLF2X/6944273.html}
}

@inproceedings{kawamotoModificationHemiplegicCompensatory2015,
  title = {Modification of Hemiplegic Compensatory Gait Pattern by Symmetry-Based Motion Controller of {{HAL}}},
  booktitle = {2015 37th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Kawamoto, Hiroaki and Kadone, Hideki and Sakurai, Takeru and Sankai, Yoshiyuki},
  date = {2015-08},
  pages = {4803--4807},
  issn = {1558-4615},
  doi = {10.1109/EMBC.2015.7319468},
  url = {10.1109/EMBC.2015.7319468},
  abstract = {As one of several characteristics of hemiplegic patients after stroke, compensatory gait caused by affected limb is often seen. The purpose of this research is to apply a symmetry-based controller of a wearable type lower limb robot, Hybrid Assistive Limb (HAL) to hemiplegic patients with compensatory gait, and to investigate improvement of gait symmetry. The controller is designed respectively for swing phase and support phase according to characteristics of hemiplegic gait pattern. The controller during swing phase stores the motion of the unaffected limb and then provides motion support on the affected limb during the subsequent swing using the stored pattern to realize symmetric gait based on spontaneous limb swing. Moreover, the controller during support phase provides motion to extend hip and knee joints to support wearer's body. Clinical tests were conducted in order to assess the modification of gait symmetry. Our case study involved participation of one chronic stroke patient who performs abnormally-compensatory gait for both of the affected and unaffected limbs. As a result, the patient's gait symmetry was improved by providing motion support during the swing phase on the affected side and motion constraint during the support phase on the unaffected side. The study showed promising basis for the effectiveness of the controller for the future clinical study.},
  eventtitle = {2015 37th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  keywords = {Foot,Hip,Joints,Kinematics,Knee,Legged locomotion,Trajectory,引用},
  file = {/Users/liurongkai/Zotero/storage/S36HQK4Z/Kawamoto 等。 - 2015 - Modification of hemiplegic compensatory gait patte.pdf;/Users/liurongkai/Zotero/storage/I2CV4UJ7/7319468.html}
}

@article{kimDeepFullBodyMotion2019,
  title = {Deep {{Full-Body Motion Network}} for a {{Soft Wearable Motion Sensing Suit}}},
  author = {Kim, D. and Kwon, J. and Han, S. and Park, Y. and Jo, S.},
  date = {2019-02},
  journaltitle = {IEEE/ASME Transactions on Mechatronics},
  volume = {24},
  number = {1},
  pages = {56--66},
  issn = {1941-014X},
  doi = {10.1109/TMECH.2018.2874647},
  url = {10.1109/TMECH.2018.2874647},
  abstract = {Soft sensors are becoming more popular in wearables as a means of tracking human body motions due to their high stretchability and easy wearability. However, previous research not only was limited to only certain body parts, but also showed problems in both calibration and processing of the sensor signals, which are caused by the high nonlinearity and hysteresis of the soft materials and also by the misplacement and displacement of the sensors during motion. Although this problem can be alleviated through redundancy by employing an increased number of sensors, it will lay another burden of heavy processing and power consumption. Moreover, complete full-body motion tracking has not been achieved yet. Therefore, we propose use of deep learning for full-body motion sensing, which significantly increases efficiency in calibration of the soft sensor and estimation of the body motions. The sensing suit is made of stretchable fabric and contains 20 soft strain sensors distributed on both the upper and the lower extremities. Three athletic motions were tested with a human subject, and the proposed learning-based calibration and mapping method showed a higher accuracy than traditional methods that are mainly based on mathematical estimation, such as linear regression.},
  eventtitle = {{{IEEE}}/{{ASME Transactions}} on {{Mechatronics}}},
  keywords = {athletic motions,biomechanics,Body motion tracking,body sensor networks,calibration,Calibration,Capacitive sensors,deep full-body motion network,deep learning,full-body motion network,full-body motion sensing,full-body motion tracking,human body motions,hysteresis,learning (artificial intelligence),learning-based calibration,medical computing,motion measurement,regression analysis,Sensor phenomena and characterization,sensor signals,Shoulder,soft sensors,soft strain sensors,soft wearable motion sensing suit,soft wearables,sport,strain sensors,stretchable fabric,Tracking,Wearable sensors,引用,重要文章},
  file = {/Users/liurongkai/Zotero/storage/WDCEJFQE/Kim et al_2019_Deep Full-Body Motion Network for a Soft Wearable Motion Sensing Suit.pdf;/Users/liurongkai/Zotero/storage/3FWTL8TC/8485722.html}
}

@online{kimLiteratureReviewSmart2023,
  title = {A {{Literature Review}} on the {{Smart Wheelchair Systems}}},
  author = {Kim, Yane and Velamala, Bharath and Choi, Youngseo and Kim, Yujin and Kim, Hyunkin and Kulkarni, Nishad and Lee, Eung-Joo},
  date = {2023-12-03},
  eprint = {2312.01285},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2312.01285},
  urldate = {2023-12-19},
  abstract = {This study offers an in-depth analysis of smart wheelchair (SW) systems, charting their progression from early developments to future innovations. It delves into various Brain-Computer Interface (BCI) systems, including mu rhythm, event-related potential, and steady-state visual evoked potential. The paper addresses challenges in signal categorization, proposing the sparse Bayesian extreme learning machine as an innovative solution. Additionally, it explores the integration of emotional states in BCI systems, the application of alternative control methods such as EMG-based systems, and the deployment of intelligent adaptive interfaces utilizing recurrent quantum neural networks. The study also covers advancements in autonomous navigation, assistance, and mapping, emphasizing their importance in SW systems. The human aspect of SW interaction receives considerable attention, specifically in terms of privacy, physiological factors, and the refinement of control mechanisms. The paper acknowledges the commercial challenges faced, like the limitations of indoor usage and the necessity for user training. For future applications, the research explores the potential of autonomous systems adept at adapting to changing environments and user needs. This exploration includes reinforcement learning and various control methods, such as eye and voice control, to improve adaptability and interaction. The potential integration with smart home technologies, including advanced features such as robotic arms, is also considered, aiming to further enhance user accessibility and independence. Ultimately, this study seeks to provide a thorough overview of SW systems, presenting extensive research to detail their historical evolution, current state, and future prospects.},
  pubstate = {preprint},
  keywords = {Electrical Engineering and Systems Science - Systems and Control,引用},
  file = {/Users/liurongkai/Zotero/storage/VREJS9PS/Kim et al_2023_A Literature Review on the Smart Wheelchair Systems.pdf;/Users/liurongkai/Zotero/storage/WPBFSJ77/2312.html}
}

@article{kimPointandClickCursorControl2011a,
  title = {Point-and-{{Click Cursor Control With}} an {{Intracortical Neural Interface System}} by {{Humans With Tetraplegia}}},
  author = {Kim, Sung-Phil and Simeral, John D. and Hochberg, Leigh R. and Donoghue, John P. and Friehs, Gerhard M. and Black, Michael J.},
  date = {2011-04},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {19},
  number = {2},
  pages = {193--203},
  issn = {1558-0210},
  doi = {10.1109/TNSRE.2011.2107750},
  abstract = {We present a point-and-click intracortical neural interface system (NIS) that enables humans with tetraplegia to volitionally move a 2-D computer cursor in any desired direction on a computer screen, hold it still, and click on the area of interest. This direct brain-computer interface extracts both discrete (click) and continuous (cursor velocity) signals from a single small population of neurons in human motor cortex. A key component of this system is a multi-state probabilistic decoding algorithm that simultaneously decodes neural spiking activity of a small population of neurons and outputs either a click signal or the velocity of the cursor. The algorithm combines a linear classifier, which determines whether the user is intending to click or move the cursor, with a Kalman filter that translates the neural population activity into cursor velocity. We present a paradigm for training the multi-state decoding algorithm using neural activity observed during imagined actions. Two human participants with tetraplegia (paralysis of the four limbs) performed a closed-loop radial target acquisition task using the point-and-click NIS over multiple sessions. We quantified point-and-click performance using various human-computer interaction measurements for pointing devices. We found that participants could control the cursor motion and click on specified targets with a small error rate ({$<$}; 3\% in one participant). This study suggests that signals from a small ensemble of motor cortical neurons ( 40) can be used for natural point-and-click 2-D cursor control of a personal computer.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Systems}} and {{Rehabilitation Engineering}}},
  keywords = {Amyotrophic lateral sclerosis,Computers,Decoding,Firing,human motor cortex,Humans,intracortical neural interface system,Kalman filters,multi-state decoding,point-and-click control,quadriplegia,stroke,Training,Tuning,引用},
  file = {/Users/liurongkai/Zotero/storage/P4BEXMSL/Kim et al_2011_Point-and-Click Cursor Control With an Intracortical Neural Interface System by.pdf;/Users/liurongkai/Zotero/storage/TCSJQTVW/5703131.html}
}

@article{kimTongueEnablesComputer2013a,
  title = {The {{Tongue Enables Computer}} and {{Wheelchair Control}} for {{People}} with {{Spinal Cord Injury}}},
  author = {Kim, Jeonghee and Park, Hangue and Bruce, Joy and Sutton, Erica and Rowles, Diane and Pucci, Deborah and Holbrook, Jaimee and Minocha, Julia and Nardone, Beatrice and West, Dennis and Laumann, Anne and Roth, Eliot and Jones, Mike and Veledar, Emir and Ghovanloo, Maysam},
  date = {2013-11-27},
  journaltitle = {Science translational medicine},
  shortjournal = {Sci Transl Med},
  volume = {5},
  number = {213},
  eprint = {24285485},
  eprinttype = {pmid},
  pages = {213ra166},
  issn = {1946-6234},
  doi = {10.1126/scitranslmed.3006296},
  url = {10.1126/scitranslmed.3006296},
  urldate = {2021-10-26},
  abstract = {The Tongue Drive System (TDS) is a wireless and wearable assistive technology, designed to allow individuals with severe motor impairments such as tetraplegia to access their environment using voluntary tongue motion. Previous TDS trials used a magnetic tracer temporarily attached to the top surface of the tongue with tissue adhesive. We investigated TDS efficacy for controlling a computer and driving a powered wheelchair in two groups of able-bodied subjects and a group of volunteers with spinal cord injury (SCI) at C6 or above. All participants received a magnetic tongue barbell and used the TDS for five to six consecutive sessions. The performance of the group was compared for TDS versus keypad and TDS versus a sip-and-puff device (SnP) using accepted measures of speed and accuracy. All performance measures improved over the course of the trial. The gap between keypad and TDS performance narrowed for able-bodied subjects. Despite participants with SCI already having familiarity with the SnP, their performance measures were up to three times better with the TDS than with the SnP and continued to improve. TDS flexibility and the inherent characteristics of the human tongue enabled individuals with high-level motor impairments to access computers and drive wheelchairs at speeds that were faster than traditional assistive technologies but with comparable accuracy.},
  pmcid = {PMC4454612},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/BUTFPQZA/Kim et al_2013_The Tongue Enables Computer and Wheelchair Control for People with Spinal Cord.pdf}
}

@article{kortierAssessmentHandKinematics2014,
  title = {Assessment of Hand Kinematics Using Inertial and Magnetic Sensors},
  author = {Kortier, Henk G and Sluiter, Victor I and Roetenberg, Daniel and Veltink, Peter H},
  date = {2014},
  journaltitle = {Journal of NeuroEngineering and Rehabilitation},
  shortjournal = {J NeuroEngineering Rehabil},
  volume = {11},
  number = {1},
  pages = {70},
  issn = {1743-0003},
  doi = {10.1186/1743-0003-11-70},
  url = {http://jneuroengrehab.biomedcentral.com/articles/10.1186/1743-0003-11-70},
  urldate = {2024-01-13},
  abstract = {Background: Assessment of hand kinematics is important when evaluating hand functioning. Major drawbacks of current sensing glove systems are lack of rotational observability in particular directions, labour intensive calibration methods which are sensitive to wear and lack of an absolute hand orientation estimate. Methods: We propose an ambulatory system using inertial sensors that can be placed on the hand, fingers and thumb. It allows a full 3D reconstruction of all finger and thumb joints as well as the absolute orientation of the hand. The system was experimentally evaluated for the static accuracy, dynamic range and repeatability. Results: The RMS position norm difference of the fingertip compared to an optical system was 5 ± 0.5 mm (mean ± standard deviation) for flexion-extension and 12.4 ± 3.0 mm for combined flexion-extension abduction-adduction movements of the index finger. The difference between index and thumb tips during a pinching movement was 6.5 ± 2.1 mm. The dynamic range of the sensing system and filter was adequate to reconstruct full 80 degrees movements of the index finger performed at 116 times per minute, which was limited by the range of the gyroscope. Finally, the reliability study showed a mean range difference over five subjects of 1.1 ± 0.4 degrees for a flat hand test and 1.8 ± 0.6 degrees for a plastic mold clenching test, which is smaller than other reported data gloves. Conclusion: Compared to existing data gloves, this research showed that inertial and magnetic sensors are of interest for ambulatory analysis of the human hand and finger kinematics in terms of static accuracy, dynamic range and repeatability. It allows for estimation of multi-degree of freedom joint movements using low-cost sensors.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/4G9FTT2B/Kortier 等 - 2014 - Assessment of hand kinematics using inertial and m.pdf}
}

@online{kronhardtUnderstandingSharedControl2023,
  title = {Understanding {{Shared Control}} for {{Assistive Robotic Arms}}},
  author = {Kronhardt, Kirill and Pascher, Max and Gerken, Jens},
  date = {2023-03-03},
  eprint = {2303.01993},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.01993},
  urldate = {2023-07-08},
  abstract = {Living a self-determined life independent of human caregivers or fully autonomous robots is a crucial factor for human dignity and the preservation of self-worth for people with motor impairments. Assistive robotic solutions - particularly robotic arms - are frequently deployed in domestic care, empowering people with motor impairments in performing ADLs independently. However, while assistive robotic arms can help them perform ADLs, currently available controls are highly complex and time-consuming due to the need to control multiple DoFs at once and necessary mode-switches. This work provides an overview of shared control approaches for assistive robotic arms, which aim to improve their ease of use for people with motor impairments. We identify three main takeaways for future research: Less is More, Pick-and-Place Matters, and Communicating Intent.},
  pubstate = {preprint},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Robotics,引用,有价值,综述,重要文章},
  file = {/Users/liurongkai/Zotero/storage/QW3U2FWP/Kronhardt et al_2023_Understanding Shared Control for Assistive Robotic Arms.pdf;/Users/liurongkai/Zotero/storage/VX7C9AHK/2303.html}
}

@article{krygerFlightSimulationUsing2017,
  title = {Flight Simulation Using a {{Brain-Computer Interface}}: {{A}} Pilot, Pilot Study},
  shorttitle = {Flight Simulation Using a {{Brain-Computer Interface}}},
  author = {Kryger, Michael and Wester, Brock and Pohlmeyer, Eric A. and Rich, Matthew and John, Brendan and Beaty, James and McLoughlin, Michael and Boninger, Michael and Tyler-Kabara, Elizabeth C.},
  date = {2017-01},
  journaltitle = {Experimental Neurology},
  shortjournal = {Experimental Neurology},
  volume = {287},
  pages = {473--478},
  issn = {00144886},
  doi = {10.1016/j.expneurol.2016.05.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0014488616301248},
  urldate = {2022-12-17},
  abstract = {As Brain-Computer Interface (BCI) systems advance for uses such as robotic arm control it is postulated that the control paradigms could apply to other scenarios, such as control of video games, wheelchair movement or even flight. The purpose of this pilot study was to determine whether our BCI system, which involves decoding the signals of two 96-microelectrode arrays implanted into the motor cortex of a subject, could also be used to control an aircraft in a flight simulator environment.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/6YJIT9VY/Kryger 等 - 2017 - Flight simulation using a Brain-Computer Interface.pdf}
}

@article{kumarPredictingSittoStandAdaptations2022,
  title = {Predicting {{Sit-to-Stand Adaptations}} Due to {{Muscle Strength Deficits}} and {{Assistance Trajectories}} to {{Complement Them}}},
  author = {Kumar, Vinay and Yoshiike, Takahide and Shibata, Tomohiro},
  date = {2022-03-18},
  journaltitle = {Frontiers in Bioengineering and Biotechnology},
  shortjournal = {Front. Bioeng. Biotechnol.},
  volume = {10},
  pages = {799836},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2022.799836},
  url = {https://www.frontiersin.org/articles/10.3389/fbioe.2022.799836/full},
  urldate = {2023-11-23},
  abstract = {Sit-to-stand (STS) transition is one of the most bio-mechanically challenging task necessary for performing activities of daily life. With muscle strength being the most dominant, many co-occurring factors influence how individuals perform STS. This study investigates the STS changes and STS failure caused by strength deficits using the trajectories generated employing an open-loop single shooting optimization framework and musculoskeletal models. The strength deficits were introduced by simultaneously scaling the maximum isometric strength of muscles in steps of 20\%. The optimization framework could generate successful STS transitions for models with up to 60\% strength deficits. The joint angle kinematics, muscle activation patterns, and the ground reaction forces from the 0\% strength deficit model’s STS transition match those observed experimentally for a healthy adult in literature. Comparison of different strength deficit STS trajectories shows that the vasti muscle saturation leads to reduced activation of the antagonistic hamstring muscle, and consequently, the gluteus maximus muscle saturation. Subsequently, the observation of reduced hamstring activation and the motion tracking results are used to suggest the vasti muscle weakness to be responsible for STS failure. Finally, the successful STS trajectory of the externally assisted 80\% strength deficit model is presented to demonstrate the optimization framework’s capability to synthesize assisted STS transition. The trajectory features utilization of external assistance as and when needed to complement strength deficits for successful STS transition. Our results will help plan intervention and design novel STS assistance devices.},
  langid = {english},
  keywords = {有价值},
  file = {/Users/liurongkai/Zotero/storage/2UAJMWVU/Kumar 等 - 2022 - Predicting Sit-to-Stand Adaptations due to Muscle .pdf}
}

@article{lancioniPersonsMultipleDisabilities2013,
  title = {Persons with Multiple Disabilities Use Forehead and Smile Responses to Access or Choose among Technology-Aided Stimulation Events},
  author = {Lancioni, Giulio E. and Singh, Nirbhay N. and O’Reilly, Mark F. and Sigafoos, Jeff and Alberti, Gloria and Bellini, Domenico and Oliva, Doretta and Boccasini, Adele and La Martire, Maria L. and Signorino, Mario},
  date = {2013-05},
  journaltitle = {Research in Developmental Disabilities},
  shortjournal = {Research in Developmental Disabilities},
  volume = {34},
  number = {5},
  pages = {1749--1757},
  issn = {08914222},
  doi = {10.1016/j.ridd.2013.02.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0891422213000838},
  urldate = {2024-01-09},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/MZMP3PZ8/Lancioni 等 - 2013 - Persons with multiple disabilities use forehead an.pdf}
}

@online{leamanComprehensiveReviewSmart2017,
  title = {A {{Comprehensive Review}} of {{Smart Wheelchairs}}: {{Past}}, {{Present}} and {{Future}}},
  shorttitle = {A {{Comprehensive Review}} of {{Smart Wheelchairs}}},
  author = {Leaman, Jesse and La, Hung M.},
  date = {2017-05-18},
  eprint = {1704.04697},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1704.04697},
  urldate = {2023-12-19},
  abstract = {A smart wheelchair (SW) is a power wheelchair (PW) to which computers, sensors, and assistive technology are attached. In the past decade, there has been little effort to provide a systematic review of SW research. This paper aims to provide a complete state-of-the-art overview of SW research trends. We expect that the information gathered in this study will enhance awareness of the status of contemporary PW as well as SW technology, and increase the functional mobility of people who use PWs. We systematically present the international SW research effort, starting with an introduction to power wheelchairs and the communities they serve. Then we discuss in detail the SW and associated technological innovations with an emphasis on the most researched areas, generating the most interest for future research and development. We conclude with our vision for the future of SW research and how to best serve people with all types of disabilities.},
  pubstate = {preprint},
  keywords = {Computer Science - Robotics,引用},
  file = {/Users/liurongkai/Zotero/storage/F25UCY6J/Leaman 和 La - 2017 - A Comprehensive Review of Smart Wheelchairs Past,.pdf;/Users/liurongkai/Zotero/storage/MJWQPISL/Leaman_La_2017_A Comprehensive Review of Smart Wheelchairs.pdf;/Users/liurongkai/Zotero/storage/MCTZM33E/1704.html}
}

@inproceedings{leePrintableSkinAdhesive2016,
  title = {Printable Skin Adhesive Stretch Sensor for Measuring Multi-Axis Human Joint Angles},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Lee, H. and Cho, J. and Kim, J.},
  date = {2016-05},
  pages = {4975--4980},
  doi = {10.1109/ICRA.2016.7487705},
  url = {10.1109/ICRA.2016.7487705},
  abstract = {This paper presents a printable skin adhesive stretch sensor to estimate rotation angles of multi-axis joint for biomedical engineering applications, such as gait analysis, gesture recognition, and motion monitoring. Silicone rubber mixed with multiwall carbon nanotube composites were fabricated to make a highly stretchable (up to 120\%) strain sensors. Embedding liquid state composites to the fabric leaded to enhance the adhesive force between the composites and fabric. The skin adhesive sensor system could be used to estimate rotation angles of the multi-axis joints while providing comfortable physical interfaces. To reduce misalignment to the axis of rotation, a calibration method was formulated based on geometrical relationship between the sensor axes and the joint angle. In order to validate the estimation performance of the sensor in multi-axis joint, shoulder flexion/extension and abduction/adduction angles were estimated. The results showed the system could estimate the rotation angles of the shoulder enough to identify motion intentions of the user. In the future, the proposed system can be applied to the motion monitoring system by direct attachment to skin without discomfort to the user in daily life.},
  eventtitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {biomedical engineering application,biomedical measurement,Calibration,calibration method,composite materials,Fabrics,gait analysis,gesture recognition,motion monitoring,multi-wall carbon nanotubes,multiaxis human joint angle measurement,multiwall carbon nanotube composite,nanofabrication,patient monitoring,Polymers,printable skin adhesive stretch sensor,Resistance,Robot sensing systems,sensors,silicone rubber,skin,Skin,Strain,strain sensor,引用,重要文章},
  file = {/Users/liurongkai/Zotero/storage/E5I82US3/Lee et al_2016_Printable skin adhesive stretch sensor for measuring multi-axis human joint.pdf;/Users/liurongkai/Zotero/storage/2J3K8TQG/7487705.html}
}

@article{liangGestureBasedNaturalHuman2022,
  title = {A {{Gesture-Based Natural Human}}–{{Robot Interaction Interface With Unrestricted Force Feedback}}},
  author = {Liang, Yinhao and Du, Guanglong and Li, Chunquan and Chen, Chuxin and Wang, Xueqian and Liu, Peter X.},
  date = {2022},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {71},
  pages = {1--11},
  issn = {1557-9662},
  doi = {10.1109/TIM.2022.3149109},
  abstract = {This article presents a novel gesture-based natural human–robot interaction interface, which integrates a markerless gesture tracking system and an unrestricted electromagnetic force feedback mechanism. In this proposed interface, a markerless gesture tracking system is developed to relate the motion of the operator’s hand to the robot manipulator so that the operator can naturally and friendly control the robot without any markers. More importantly, this interface uses a new unrestricted electromagnetic force feedback mechanism to avoid the friction, hysteresis, and other nonlinear influence in the conventional actuation dynamics. The interface makes the operator obtain the effective force immersion of the robot. Therefore, the proposed interface can provide the promising operation accuracy for the operator. To effectively regulate the electric currents of coils and provide accurate force feedback, the broad learning system (BLS) is introduced in this unrestricted electromagnetic force feedback mechanism. In addition, two interval Kalman filters (IKFs) are applied to estimate the position and orientation of the operator’s hand, respectively, improving the measurement accuracy of the proposed interface. Experimental results show that the proposed interface is suitable for high-precision human–robot interactive tasks and enables the operator to focus on the tasks and operate dual robot manipulator, which provides natural and efficient human–robot interaction.},
  eventtitle = {{{IEEE Transactions}} on {{Instrumentation}} and {{Measurement}}},
  keywords = {Coils,Electromagnetic force,Force,force feedback,Force feedback,Human-robot interaction,human–robot interaction,Kalman filters,multi-sensors,Robots,Task analysis,Tracking,引用},
  file = {/Users/liurongkai/Zotero/storage/CNESD5DX/Liang 等 - 2022 - A Gesture-Based Natural Human–Robot Interaction In.pdf;/Users/liurongkai/Zotero/storage/WNY45IGU/9703290.html}
}

@article{liContinuousRoleAdaptation2015,
  title = {Continuous {{Role Adaptation}} for {{Human}}–{{Robot Shared Control}}},
  author = {Li, Yanan and Tee, Keng Peng and Chan, Wei Liang and Yan, Rui and Chua, Yuanwei and Limbu, Dilip Kumar},
  date = {2015-06},
  journaltitle = {IEEE Transactions on Robotics},
  shortjournal = {IEEE Trans. Robot.},
  volume = {31},
  number = {3},
  pages = {672--681},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2015.2419873},
  url = {http://ieeexplore.ieee.org/document/7097058/},
  urldate = {2024-02-02},
  abstract = {In this paper, we propose a role adaptation method for human–robot shared control. Game theory is employed for fundamental analysis of this two-agent system. An adaptation law is developed such that the robot is able to adjust its own role according to the human’s intention to lead or follow, which is inferred through the measured interaction force. In the absence of human interaction forces, the adaptive scheme allows the robot to take the lead and complete the task by itself. On the other hand, when the human persistently exerts strong forces that signal an unambiguous intent to lead, the robot yields and becomes the follower. Additionally, the full spectrum of mixed roles between these extreme scenarios is afforded by continuous online update of the control that is shared between both agents. Theoretical analysis shows that the resulting shared control is optimal with respect to a two-agent coordination game. Experimental results illustrate better overall performance, in terms of both error and effort, compared with fixed-role interactions.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/BIJA2MIL/Li 等 - 2015 - Continuous Role Adaptation for Human–Robot Shared .pdf}
}

@article{liFrameworkHumanRobot2016,
  title = {A {{Framework}} of {{Human}}–{{Robot Coordination Based}} on {{Game Theory}} and {{Policy Iteration}}},
  author = {Li, Yanan and Tee, Keng Peng and Yan, Rui and Chan, Wei Liang and Wu, Yan},
  date = {2016-12},
  journaltitle = {IEEE Transactions on Robotics},
  shortjournal = {IEEE Trans. Robot.},
  volume = {32},
  number = {6},
  pages = {1408--1418},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2016.2597322},
  url = {http://ieeexplore.ieee.org/document/7548305/},
  urldate = {2024-02-02},
  abstract = {In this paper, we propose a framework to analyze the interactive behaviors of humans and robots in physical interactions. Game theory is employed to describe the system under study, and policy iteration is adopted to provide a solution of Nash equilibrium. The human’s control objective is estimated based on the measured interaction force, and it is used to adapt the robot’s objective such that human–robot coordination can be achieved. The validity of the proposed method is verified through a rigorous proof and experimental studies.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/HBHDWQTT/Li 等 - 2016 - A Framework of Human–Robot Coordination Based on G.pdf}
}

@inproceedings{liHumanCenteredControlFramework2018,
  title = {A {{Human-Centered Control Framework}} for {{Robotic Sit-to-Stand Assistance}}},
  booktitle = {2018 {{IEEE}}/{{ASME International Conference}} on {{Advanced Intelligent Mechatronics}} ({{AIM}})},
  author = {Li, Jiawei and Lu, Lu and Zhao, Leidi and Wang, Cong and Huo, Xiaoye},
  date = {2018-07},
  pages = {845--850},
  publisher = {{IEEE}},
  location = {{Auckland}},
  doi = {10.1109/AIM.2018.8452684},
  url = {https://ieeexplore.ieee.org/document/8452684/},
  urldate = {2023-10-30},
  abstract = {In this research, we propose a human-centered control framework for the Sit-To-Stand (STS) assistance by using a robot manipulator. The framework is designed to assist those with weak knees and feeble muscles to get out of a seated position. Compared to previous work on STS assistance, we develop a novel human-centered strategy that explicitly optimizes the human joint loads under the human body dynamics while taking care of the constantly-changing intention of the human during the actual STS assistance. Simulations and experiments are conducted to validate the proposed control framework.},
  eventtitle = {2018 {{IEEE}}/{{ASME International Conference}} on {{Advanced Intelligent Mechatronics}} ({{AIM}})},
  isbn = {978-1-5386-1854-7},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/C8DAUXPK/Li 等 - 2018 - A Human-Centered Control Framework for Robotic Sit.pdf}
}

@article{liIntegratedApproachRobotic2021,
  title = {An Integrated Approach for Robotic {{Sit-To-Stand}} Assistance: {{Control}} Framework Design and Human Intention Recognition},
  shorttitle = {An Integrated Approach for Robotic {{Sit-To-Stand}} Assistance},
  author = {Li, Jiawei and Lu, Lu and Zhao, Leidi and Wang, Cong and Li, Junhui},
  date = {2021-02},
  journaltitle = {Control Engineering Practice},
  shortjournal = {Control Engineering Practice},
  volume = {107},
  pages = {104680},
  issn = {09670661},
  doi = {10.1016/j.conengprac.2020.104680},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0967066120302501},
  urldate = {2023-10-26},
  abstract = {In this paper, the problem of robotic Sit-To-Stand (STS) assistance is studied. The objective is to effectively assist individuals in need to stand up from a seated position using a robot manipulator. To achieve the goal, we propose an integrated method which encompasses traditional model-based control and optimization, as well as AI-based human intention recognition. Specifically, a number of demonstrations of human-to-human STS assistance are first performed and recorded using motion capture system. On the account of the observation and recorded data, the average intended motion trajectories for the joints of lower limbs are obtained. Based on these intended motion trajectories as well as the constructed human body dynamics and control in different STS phases, an optimal nominal trajectory of the robot end-effector is generated off-line that minimizes the human joint loads while satisfying additional physical constraints. In actual STS assistance, the human who is being assisted is likely to move faster or slower from the nominal trajectories, or even sit back down. Therefore, we develop a Long Short-Term Memory (LSTM) network to estimate the ever-changing human’s intention in STS assistance, and then adjust the velocity of the robot end-effector on the basis of the predicted human intention on the nominal trajectory. Simulations and experiments are conducted, demonstrating that the proposed algorithm is indeed capable of minimizing joint load of human while following his/her intention during the course of STS motion. The algorithm can potentially be applied to future home robots that assist elderly and disabled people with daily activities.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/YEP8FZCJ/Li 等 - 2021 - An integrated approach for robotic Sit-To-Stand as.pdf}
}

@book{liPhysicalTherapySpinal2019,
  title = {Physical {{Therapy}} for {{Spinal Cord Injury}}},
  author = {Li, Jianan},
  date = {2019},
  edition = {1-st ed},
  location = {{Beijing, China}},
  keywords = {引用}
}

@article{liReviewInteractionControl2022,
  title = {A Review on Interaction Control for Contact Robots through Intent Detection},
  author = {Li, Yanan and Sena, Aran and Wang, Ziwei and Xing, Xueyan and Babič, Jan and Van Asseldonk, Edwin and Burdet, Etienne},
  date = {2022-07-01},
  journaltitle = {Progress in Biomedical Engineering},
  shortjournal = {Prog. Biomed. Eng.},
  volume = {4},
  number = {3},
  pages = {032004},
  issn = {2516-1091},
  doi = {10.1088/2516-1091/ac8193},
  url = {https://iopscience.iop.org/article/10.1088/2516-1091/ac8193},
  urldate = {2024-01-10},
  abstract = {Interaction control presents opportunities for contact robots physically interacting with their human user, such as assistance targeted to each human user, communication of goals to enable effective teamwork, and task-directed motion resistance in physical training and rehabilitation contexts. Here we review the burgeoning field of interaction control in the control theory and machine learning communities, by analysing the exchange of haptic information between the robot and its human user, and how they share the task effort. We first review the estimation and learning methods to predict the human user intent with the large uncertainty, variability and noise and limited observation of human motion. Based on this motion intent core, typical interaction control strategies are described using a homotopy of shared control parameters. Recent methods of haptic communication and game theory are then presented to consider the co-adaptation of human and robot control and yield versatile interactive control as observed between humans. Finally, the limitations of the presented state of the art are discussed and directions for future research are outlined.},
  langid = {english},
  file = {/Users/liurongkai/Zotero/storage/KJJC6WQN/Li 等 - 2022 - A review on interaction control for contact robots.pdf}
}

@article{liuDesigningRobotBehavior,
  title = {Designing {{Robot Behavior}} in {{Human-Robot Interactions}}},
  author = {Liu, Changliu},
  langid = {english},
  keywords = {引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/366KNQ35/Liu - Designing Robot Behavior in Human-Robot Interactio.pdf}
}

@inproceedings{liuDesignWearableWireless2018,
  title = {The {{Design}} of {{Wearable Wireless Inertial Measurement Unit}} for {{Body}} Motion {{Capture System}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Intelligence}} and {{Safety}} for {{Robotics}} ({{ISR}})},
  author = {Liu, Rongkai and Peng, Liang and Tong, Lina and Yang, Kaizhi and Liu, Bingyang},
  date = {2018-08},
  pages = {557--562},
  publisher = {{IEEE}},
  location = {{Shenyang}},
  doi = {10.1109/IISR.2018.8535742},
  url = {https://ieeexplore.ieee.org/document/8535742/},
  urldate = {2020-10-27},
  abstract = {Motion capture system serves as a critical technology in a wide range of applications. Nowadays, motion capture system based on inter components has become a new research hotspot. This paper provides a new design of low cost wearable wireless inertia measurement unit based on a 9-DOF micro inertia sensor MPU9250 and STM32F103C8T6 MCU. Furthermore, an ultra-low power (ULP) 2Mbps RF transceiver IC NRF24L01 was used as RF transceiver, which operates in 2.4GHz ISM (Industrial, Scientific and Medical) band, with peak RX/TX currents lower than 14mA. Finally, a program was built by Unity3D 5.6 on PC to display sensors real-time attitude and the experiment shows it has good performance in static and dynamic state.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Intelligence}} and {{Safety}} for {{Robotics}} ({{ISR}})},
  isbn = {978-1-5386-5547-4},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/86SL9ZFF/Liu 等。 - 2018 - The Design of Wearable Wireless Inertial Measureme.pdf}
}

@inproceedings{liuNovelMethodParkinson2019,
  title = {A {{Novel Method}} for {{Parkinson}}'s {{Disease Classification}} and {{Dyskinesia Quantification Using Wearable Inertial Sensors}}},
  booktitle = {2019 {{IEEE}} 9th {{Annual International Conference}} on {{CYBER Technology}} in {{Automation}}, {{Control}}, and {{Intelligent Systems}} ({{CYBER}})},
  author = {Liu, Rongkai and Peng, Liang and Tong, Lina and Wu, Yingjie},
  date = {2019-07},
  pages = {1022--1026},
  publisher = {{IEEE}},
  location = {{Suzhou, China}},
  doi = {10.1109/CYBER46603.2019.9066660},
  url = {https://ieeexplore.ieee.org/document/9066660/},
  urldate = {2020-10-27},
  abstract = {This work introduces a novel method for classification and the dyskinesia quantification of Parkinson’s disease patients. We merely utilized the data from two 9-axis inertial sensors (only use 3D gyroscope and 3D accelerometer) located at wrist and ankle. And an SVM classifier with RBF kernel was applied for classifying the data frame of PD subjects and controls and finally got an accuracy of 87.1\%. Additionally, a pr value was proposed for quantification the dyskinesia into three levels in a fixed sample time period. Combining with the quadratic weighted Kappa coefficient, we evaluated the interrater reliability of artificial quantification and our proposed method in the end (k=0.961). The outcome indicates that our method is effective for identifying the PD patients and healthy individuals and quantitative evaluating the dyskinesia severity levels of PD patients, which has the application prospect of continual illness monitoring and levodopa dosing assessment for PD patients in the future.},
  eventtitle = {2019 {{IEEE}} 9th {{Annual International Conference}} on {{CYBER Technology}} in {{Automation}}, {{Control}}, and {{Intelligent Systems}} ({{CYBER}})},
  isbn = {978-1-72810-770-7},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/MRNDX7IF/Liu 等。 - 2019 - A Novel Method for Parkinson's Disease Classificat.pdf}
}

@online{LiuYangJianKangZhongGuo2030GuiHuaGangYao,
  title = {“健康中国2030”规划纲要},
  author = {刘杨},
  url = {https://www.gov.cn/zhengce/2016-10/25/content_5124174.htm},
  urldate = {2023-12-16},
  abstract = {近日，中共中央、国务院印发了《“健康中国2030”规划纲要》，并发出通知，要求各地区各部门结合实际认真贯彻落实。},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/K2AIRY3K/content_5124174.html}
}

@article{lucareliALTERATIONLOADRESPONSEMECHANISM2006,
  title = {{{ALTERATION OF THE LOAD-RESPONSE MECHANISM OF THE KNEE JOINT DURING HEMIPARETIC GAIT FOLLOWING STROKE ANALYZED BY}} 3-{{DIMENSIONAL KINEMATIC}}},
  author = {Lucareli, Paulo Roberto Garcia and Greve, Julia Maria D’Andrea},
  date = {2006},
  journaltitle = {Clinics},
  shortjournal = {Clinics},
  volume = {61},
  number = {4},
  pages = {295--300},
  issn = {18075932},
  doi = {10.1590/S1807-59322006000400004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1807593222032422},
  urldate = {2022-06-17},
  abstract = {PURPOSE: The aims of this study were to evaluate the variables found in the alteration of the load-response mechanism on 3dimensional kinematic analysis of the knee joint during hemiparetic gait following stroke. METHODS: We evaluated 66 adult patients (33 men and 33 women), aged 45.4 ± 8.5 years (mean ± SD), with a diagnosis of ischemic cerebrovascular accident either right or left hemiparesis and brachial prevalence. All the participants underwent 3dimensional gait evaluation with a Vicon 370, and the values of the angular kinematics of the knee joint were selected for analysis. RESULTS: There were no statistically significant differences (by the Kruskal-Wallis test) between the subjects regarding the following variables: angular knee position at initial contact and time of peak knee flexion in the stance. The clinically relevant characteristics found were: an increase in knee joint flexion during the initial contact and a movement amplitude below that anticipated in this phase of the walking cycle. These should be taken into account when choosing the best treatment, because they are the ones which exhibit the most important alteration in the load-response mechanism in all patients. CONCLUSION: There is still no consensus among the different specialists regarding the variations in kinematics during the hemiparetic gait. One of the most frequently discussed joints is the knee—the way the main changes take place during the gait cycle and whether the gait velocity changes the patterns of joint mobility.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/FTM8V49Y/Lucareli 和 Greve - 2006 - ALTERATION OF THE LOAD-RESPONSE MECHANISM OF THE K.pdf}
}

@article{malcolmExperimentalStudyRole2009,
  title = {Experimental Study on the Role of the Ankle Push off in the Walk-to-Run Transition by Means of a Powered Ankle-Foot-Exoskeleton},
  author = {Malcolm, P. and Fiers, P. and Segers, V. and Van Caekenberghe, I. and Lenoir, M. and De Clercq, D.},
  date = {2009-10},
  journaltitle = {Gait \& Posture},
  shortjournal = {Gait \& Posture},
  volume = {30},
  number = {3},
  pages = {322--327},
  issn = {09666362},
  doi = {10.1016/j.gaitpost.2009.06.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636209001593},
  urldate = {2023-12-16},
  abstract = {The goal of this study was to analyse the role of the plantarflexor muscles in the walk-to-run transition (WRT) by means of a powered ankle-foot-exoskeleton. 11 female subjects performed several WRT’s on an accelerating treadmill while their plantarflexors were assisted or resisted during push off. The WRT speed was lower in the resist condition than in the control condition which reinforces hypotheses from previous simulations, descriptive and experimental studies. There was no increase in WRT speed in the assist condition which is in contrast to another study where the plantarflexor push off was assisted indirectly by a horizontal traction at waist level. The lack of effect from the assist condition in the present study is possibly due to the narrowly focused nature of the experimental manipulation.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/AECMH6AY/Malcolm 等 - 2009 - Experimental study on the role of the ankle push o.pdf}
}

@article{malikEfficientDecodingSteadyState2011,
  title = {Efficient {{Decoding With Steady-State Kalman Filter}} in {{Neural Interface Systems}}},
  author = {Malik, Wasim Q. and Truccolo, Wilson and Brown, Emery N. and Hochberg, Leigh R.},
  date = {2011-02},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {19},
  number = {1},
  pages = {25--34},
  issn = {1558-0210},
  doi = {10.1109/TNSRE.2010.2092443},
  abstract = {The Kalman filter is commonly used in neural interface systems to decode neural activity and estimate the desired movement kinematics. We analyze a low-complexity Kalman filter implementation in which the filter gain is approximated by its steady-state form, computed offline before real-time decoding commences. We evaluate its performance using human motor cortical spike train data obtained from an intracortical recording array as part of an ongoing pilot clinical trial. We demonstrate that the standard Kalman filter gain converges to within 95\% of the steady-state filter gain in 1.5 ± 0.5 s (mean ±s.d.). The difference in the intended movement velocity decoded by the two filters vanishes within 5 s, with a correlation coefficient of 0.99 between the two decoded velocities over the session length. We also find that the steady-state Kalman filter reduces the computational load (algorithm execution time) for decoding the firing rates of 25±3 single units by a factor of 7.0±0.9. We expect that the gain in computational efficiency will be much higher in systems with larger neural ensembles. The steady-state filter can thus provide substantial runtime efficiency at little cost in terms of estimation accuracy. This far more efficient neural decoding approach will facilitate the practical implementation of future large-dimensional, multisignal neural interface systems.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Systems}} and {{Rehabilitation Engineering}}},
  keywords = {Arrays,Brain–computer interfaces (BCI),brain–machine interfaces (BMI),Clinical trials,Decoding,Hospitals,Kalman filter,Kalman filters,motor cortex,neural decoding,paralysis,spinal cord injury,state-space models,Steady-state,tetraplegia,Training,引用},
  file = {/Users/liurongkai/Zotero/storage/JBMDTQ8R/Malik et al_2011_Efficient Decoding With Steady-State Kalman Filter in Neural Interface Systems.pdf;/Users/liurongkai/Zotero/storage/D93N49SA/5638150.html}
}

@inproceedings{mallesonRealTimeFullBodyMotion2017,
  title = {Real-{{Time Full-Body Motion Capture}} from {{Video}} and {{IMUs}}},
  booktitle = {2017 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Malleson, Charles and Gilbert, Andrew and Trumble, Matthew and Collomosse, John and Hilton, Adrian and Volino, Marco},
  date = {2017-10},
  pages = {449--457},
  publisher = {{IEEE}},
  location = {{Qingdao}},
  doi = {10.1109/3DV.2017.00058},
  url = {https://ieeexplore.ieee.org/document/8374599/},
  urldate = {2024-01-13},
  abstract = {A real-time full-body motion capture system is presented which uses input from a sparse set of inertial measurement units (IMUs) along with images from two or more standard video cameras and requires no optical markers or specialized infra-red cameras. A real-time optimization-based framework is proposed which incorporates constraints from the IMUs, cameras and a prior pose model. The combination of video and IMU data allows the full 6-DOF motion to be recovered including axial rotation of limbs and drift-free global position. The approach was tested using both indoor and outdoor captured data. The results demonstrate the effectiveness of the approach for tracking a wide range of human motion in real time in unconstrained indoor/outdoor scenes.},
  eventtitle = {2017 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  isbn = {978-1-5386-2610-8},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/ZQCVFMHX/Malleson 等 - 2017 - Real-Time Full-Body Motion Capture from Video and .pdf}
}

@incollection{medericElderlyPeopleSit2006,
  title = {Elderly {{People Sit}} to {{Stand Transfer Experimental Analysis}}},
  booktitle = {Climbing and {{Walking Robots}}},
  author = {Médéric, P. and Pasqui, V. and Plumet, F. and Bidaud, P.},
  editor = {Tokhi, M. O. and Virk, G. S. and Hossain, M. A.},
  date = {2006},
  pages = {953--960},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-26415-9_114},
  url = {http://link.springer.com/10.1007/3-540-26415-9_114},
  urldate = {2023-12-27},
  abstract = {This paper describe an assistive device for the elderly providing support during the sit to stand transfer. A postural stabilization criteria and an assisting force in case of instability are presented.},
  isbn = {978-3-540-26413-2 978-3-540-26415-6},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/27VE6UPC/Médéric 等 - 2006 - Elderly People Sit to Stand Transfer Experimental .pdf}
}

@article{miehlbradtDatadrivenBodyMachine2018a,
  title = {Data-Driven Body–Machine Interface for the Accurate Control of Drones},
  author = {Miehlbradt, Jenifer and Cherpillod, Alexandre and Mintchev, Stefano and Coscia, Martina and Artoni, Fiorenzo and Floreano, Dario and Micera, Silvestro},
  date = {2018-07-31},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {115},
  number = {31},
  pages = {7913--7918},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1718648115},
  url = {https://pnas.org/doi/full/10.1073/pnas.1718648115},
  urldate = {2022-12-19},
  abstract = {Significance             The teleoperation of nonhumanoid robots is often a demanding task, as most current control interfaces rely on mappings between the operator’s and the robot’s actions, which are determined by the design and characteristics of the interface, and may therefore be challenging to master. Here, we describe a structured methodology to identify common patterns in spontaneous interaction behaviors, to implement embodied user interfaces, and to select the appropriate sensor type and positioning. Using this method, we developed an intuitive, gesture-based control interface for real and simulated drones, which outperformed a standard joystick in terms of learning time and steering abilities. Implementing this procedure to identify body-machine patterns for specific applications could support the development of more intuitive and effective interfaces.           ,              The accurate teleoperation of robotic devices requires simple, yet intuitive and reliable control interfaces. However, current human–machine interfaces (HMIs) often fail to fulfill these characteristics, leading to systems requiring an intensive practice to reach a sufficient operation expertise. Here, we present a systematic methodology to identify the spontaneous gesture-based interaction strategies of naive individuals with a distant device, and to exploit this information to develop a data-driven body–machine interface (BoMI) to efficiently control this device. We applied this approach to the specific case of drone steering and derived a simple control method relying on upper-body motion. The identified BoMI allowed participants with no prior experience to rapidly master the control of both simulated and real drones, outperforming joystick users, and comparing with the control ability reached by participants using the bird-like flight simulator Birdly.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/GSR5AU9D/Miehlbradt 等 - 2018 - Data-driven body–machine interface for the accurat.pdf}
}

@inproceedings{millikenModelingUserExpertise2017,
  title = {Modeling User Expertise for Choosing Levels of Shared Autonomy},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Milliken, Lauren and Hollinger, Geoffrey A.},
  date = {2017-05},
  pages = {2285--2291},
  publisher = {{IEEE}},
  location = {{Singapore, Singapore}},
  doi = {10.1109/ICRA.2017.7989263},
  url = {http://ieeexplore.ieee.org/document/7989263/},
  urldate = {2024-02-02},
  abstract = {In shared autonomy, a robot and human user both have some level of control in order to achieve a shared goal. Choosing the balance of control given to the user and the robot can be a challenging problem since different users have different preferences and vary in skill levels when operating a robot. We propose using a novel formulation of Partially Observable Markov Decision Process (POMDP) to represent a model of the user’s expertise in controlling the robot. The POMDP uses observations from the user’s actions and from the environment to update the belief of the user’s skill and chooses a level of control between the robot and the user. The level of control given between the user and the robot is encapsulated in macro-action controllers. A user study was run to test the performance of our formulation. Users drive a simulated robot through an obstacle-filled map while the POMDP model chooses appropriate macro-action controllers based on the belief state of the user’s skill level. The results of the user study show that our model can encapsulate user skill. The results also show that using the controller with greater robot autonomy helped users of low skill avoid obstacles more than it helped users of high skill.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5090-4633-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/3B3PT4D5/Milliken 和 Hollinger - 2017 - Modeling user expertise for choosing levels of sha.pdf}
}

@inproceedings{mistrySSVEPBasedBrain2018,
  title = {An {{SSVEP}} Based Brain Computer Interface System to Control Electric Wheelchairs},
  booktitle = {2018 {{IEEE International Instrumentation}} and {{Measurement Technology Conference}} ({{I2MTC}})},
  author = {Mistry, Krupal Sureshbai and Pelayo, Pablo and Anil, Divya Geethakumari and George, Kiran},
  date = {2018-05},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Houston, TX, USA}},
  doi = {10.1109/I2MTC.2018.8409632},
  url = {https://ieeexplore.ieee.org/document/8409632/},
  urldate = {2023-12-22},
  abstract = {Brain-computer interface (BCI) based systems can be used to control external devices by translating a certain set of patterns in the brain signals into actions. An example of this is a BCI controlled wheelchair, with the actions being navigating the wheelchair. In this paper, a Steady State Visual Evoked Potential (SSVEP) based BCI system that controls the operations (forward, reverse, left, and right) of an electrical wheelchair is presented. This system utilizes four LEDs with different flickering frequencies as a visual stimulation source. By providing concentration to these visual stimulation sources, the SSVEP signals are entrained in the occipital and posterior region of the brain. The acquired SSVEP signals are classified into four different frequency ranges representing each of the directions using suitable signal processing algorithms. Based on this classification, a specific control signal is derived to navigate the wheelchair in the desired direction. This system can assist individuals who suffer from neuromuscular degenerative diseases such as Amyotrophic Lateral Sclerosis (ALS), Locked-in Syndrome (LIS), etc., with the navigation of an electric wheelchair using their brain waves. Five peripheral safety sensors are mounted on the wheelchair to avoid the risk of collisions while operating the wheelchair. Once an obstacle is detected by these sensors, a control signal is sent from the Arduino microcontroller to stop the wheelchair. Three experiments were conducted on four subjects to measure the accuracy and reliability of the system. Our results show that the presented system allows the user to navigate to their intended direction with an average accuracy of 79.4\%. Also, the safety mechanism incorporated results in an accuracy of 100\% obstacle avoidance. Our results show that on average a user can navigate 50 feet set path in approximately five minutes.},
  eventtitle = {2018 {{IEEE International Instrumentation}} and {{Measurement Technology Conference}} ({{I2MTC}} )},
  isbn = {978-1-5386-2222-3},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/ZCBF9QDR/Mistry 等 - 2018 - An SSVEP based brain computer interface system to .pdf}
}

@online{MobiusMobilityNext,
  title = {Mobius {{Mobility}} | {{The}} next Generation {{iBOT}} Is Here.},
  url = {https://mobiusmobility.com/},
  urldate = {2023-12-21},
  abstract = {The iBOT® Personal Mobility Device (“iBOT® PMD”) combines balance and motion to provide a unique eye-level experience in mobility.},
  langid = {american},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/NR8LD4PD/mobiusmobility.com.html}
}

@article{mohebbiHumanRobotInteractionRehabilitation2020a,
  title = {Human-{{Robot Interaction}} in {{Rehabilitation}} and {{Assistance}}: A {{Review}}},
  shorttitle = {Human-{{Robot Interaction}} in {{Rehabilitation}} and {{Assistance}}},
  author = {Mohebbi, Abolfazl},
  date = {2020-09},
  journaltitle = {Current Robotics Reports},
  shortjournal = {Curr Robot Rep},
  volume = {1},
  number = {3},
  pages = {131--144},
  issn = {2662-4087},
  doi = {10.1007/s43154-020-00015-4},
  url = {https://link.springer.com/10.1007/s43154-020-00015-4},
  urldate = {2023-12-20},
  abstract = {Purpose of Review Research in assistive and rehabilitation robotics is a growing, promising, and challenging field emerged due to various social and medical needs such as aging populations, neuromuscular, and musculoskeletal disorders. Such robots can be used in various day-to-day scenarios or to support motor functionality, training, and rehabilitation. This paper reflects on the human-robot interaction perspective in rehabilitation and assistive robotics and reports on current issues and developments in the field.},
  langid = {english},
  file = {/Users/liurongkai/Zotero/storage/XM5SRK2K/Mohebbi - 2020 - Human-Robot Interaction in Rehabilitation and Assi.pdf}
}

@article{moniruzzamanWearableMotionCapture2023,
  title = {Wearable {{Motion Capture}}: {{Reconstructing}} and {{Predicting 3D Human Poses From Wearable Sensors}}},
  shorttitle = {Wearable {{Motion Capture}}},
  author = {Moniruzzaman, Md and Yin, Zhaozheng and Hossain, Md Sanzid Bin and Choi, Hwan and Guo, Zhishan},
  date = {2023-11},
  journaltitle = {IEEE Journal of Biomedical and Health Informatics},
  shortjournal = {IEEE J. Biomed. Health Inform.},
  volume = {27},
  number = {11},
  pages = {5345--5356},
  issn = {2168-2194, 2168-2208},
  doi = {10.1109/JBHI.2023.3311448},
  url = {https://ieeexplore.ieee.org/document/10238692/},
  urldate = {2024-01-13},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/47ZTZNND/Moniruzzaman 等 - 2023 - Wearable Motion Capture Reconstructing and Predic.pdf}
}

@article{montazerinTransformerbasedHandGesture2023,
  title = {Transformer-Based Hand Gesture Recognition from Instantaneous to Fused Neural Decomposition of High-Density {{EMG}} Signals},
  author = {Montazerin, Mansooreh and Rahimian, Elahe and Naderkhani, Farnoosh and Atashzar, S. Farokh and Yanushkevich, Svetlana and Mohammadi, Arash},
  date = {2023-07-07},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {13},
  number = {1},
  pages = {11000},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-36490-w},
  url = {https://www.nature.com/articles/s41598-023-36490-w},
  urldate = {2024-01-07},
  abstract = {Abstract                            Designing efficient and labor-saving prosthetic hands requires powerful hand gesture recognition algorithms that can achieve high accuracy with limited complexity and latency. In this context, the paper proposes a Compact Transformer-based Hand Gesture Recognition framework referred to as                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  , which employs a vision transformer network to conduct hand gesture recognition using high-density surface EMG (HD-sEMG) signals. Taking advantage of the attention mechanism, which is incorporated into the transformer architectures, our proposed                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  framework overcomes major constraints associated with most of the existing deep learning models such as model complexity; requiring feature engineering; inability to consider both temporal and spatial information of HD-sEMG signals, and requiring a large number of training samples. The attention mechanism in the proposed model identifies similarities among different data segments with a greater capacity for parallel computations and addresses the memory limitation problems while dealing with inputs of large sequence lengths.                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  can be trained from scratch without any need for transfer learning and can simultaneously extract both temporal and spatial features of HD-sEMG data. Additionally, the                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  framework can perform instantaneous recognition using sEMG image spatially composed from HD-sEMG signals. A variant of the                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  is also designed to incorporate microscopic neural drive information in the form of Motor Unit Spike Trains (MUSTs) extracted from HD-sEMG signals using Blind Source Separation (BSS). This variant is combined with its baseline version via a hybrid architecture to evaluate potentials of fusing macroscopic and microscopic neural drive information. The utilized HD-sEMG dataset involves 128 electrodes that collect the signals related to 65 isometric hand gestures of 20 subjects. The proposed                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  framework is applied to 31.25, 62.5, 125, 250 ms window sizes of the above-mentioned dataset utilizing 32, 64, 128 electrode channels. Our results are obtained via 5-fold cross-validation by first applying the proposed framework on the dataset of each subject separately and then, averaging the accuracies among all the subjects. The average accuracy over all the participants using 32 electrodes and a window size of 31.25 ms is 86.23\%, which gradually increases till reaching 91.98\% for 128 electrodes and a window size of 250 ms. The                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  achieves accuracy of 89.13\% for instantaneous recognition based on a single frame of HD-sEMG image. The proposed model is statistically compared with a 3D Convolutional Neural Network (CNN) and two different variants of Support Vector Machine (SVM) and Linear Discriminant Analysis (LDA) models. The accuracy results for each of the above-mentioned models are paired with their precision, recall, F1 score, required memory, and train/test times. The results corroborate effectiveness of the proposed                                                   \$\$\textbackslash text \{CT-HGR\}\$\$                                        CT-HGR                                                                  framework compared to its counterparts.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/HCS5MPXT/Montazerin 等 - 2023 - Transformer-based hand gesture recognition from in.pdf}
}

@online{MotionCaptureSystems,
  title = {Motion {{Capture Systems}}},
  url = {http://optitrack.com/index.html},
  urldate = {2024-01-11},
  abstract = {Industry leading precision motion capture and 3D tracking systems for video game design, animation, virtual reality, robotics, and movement sciences.},
  langid = {english},
  organization = {{OptiTrack}},
  keywords = {引用}
}

@article{naserPracticalBCIDrivenWheelchairs2023,
  title = {Towards {{Practical BCI-Driven Wheelchairs}}: {{A Systematic Review Study}}},
  shorttitle = {Towards {{Practical BCI-Driven Wheelchairs}}},
  author = {Naser, Mohammad Y. M. and Bhattacharya, Sylvia},
  date = {2023},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  shortjournal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
  volume = {31},
  pages = {1030--1044},
  issn = {1534-4320, 1558-0210},
  doi = {10.1109/TNSRE.2023.3236251},
  url = {https://ieeexplore.ieee.org/document/10015149/},
  urldate = {2023-12-22},
  abstract = {The use of brain signals in controlling wheelchairs is a promising solution for many disabled individuals, specifically those who are suffering from motor neuron disease affecting the proper functioning of their motor units. Almost two decades since the first work, the applicability of EEG-driven wheelchairs is still limited to laboratory environments. In this work, a systematic review study has been conducted to identify the state-of-the-art and the different models adopted in the literature. Furthermore, a strong emphasis is devoted to introducing the challenges impeding a broad use of the technology as well as the latest research trends in each of those areas.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/GN8IKPNQ/Naser 和 Bhattacharya - 2023 - Towards Practical BCI-Driven Wheelchairs A System.pdf}
}

@article{ngIndirectControlAutonomous2020,
  title = {Indirect {{Control}} of an {{Autonomous Wheelchair Using SSVEP BCI}}},
  author = {Ng, Danny Wee-Kiat and Goh, Sing Yau and {Lee Kong Chian Faculty of Engineering and Science, Universiti Tunku Abdul Rahman Jalan Sungai Long, Bandar Sungai Long, Kajang, Selangor 43000, Malaysia}},
  date = {2020-08-20},
  journaltitle = {Journal of Robotics and Mechatronics},
  shortjournal = {JRM},
  volume = {32},
  number = {4},
  pages = {761--767},
  issn = {1883-8049, 0915-3942},
  doi = {10.20965/jrm.2020.p0761},
  url = {https://www.fujipress.jp/jrm/rb/robot003200040761},
  urldate = {2023-12-25},
  abstract = {Having the capability to control a wheelchair using brain signals would be a major benefit to patients suffering from motor disabling diseases. However, one major challenge such systems are facing is the amount of input needed over time by the patient for control. Such a navigation control system results in a significant mental burden for the patient. The objective of this study is to develop a BCI system that requires a low number of inputs from a subject to operate. We propose an autonomous wheelchair that uses steadystate visual evoked potential based brain computer interfaces to achieve the objective. A dual mode system was implemented in this study to allow the autonomous wheelchair to work in both unknown and known environments. Robot operating system is used as the middleware in this study for the development of the algorithm to operate the wheelchair. The mental task for the subject using this wheelchair is reduced by relegating the responsibility of navigation control from the subject to the navigation software.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/JSPTQZSZ/Ng 等 - 2020 - Indirect Control of an Autonomous Wheelchair Using.pdf}
}

@online{NoitomNuoYiTengGuanWang,
  title = {Noitom诺亦腾官网},
  url = {https://www.noitom.com.cn/perception-neuron-3.html},
  urldate = {2024-01-12},
  keywords = {引用}
}

@inproceedings{ogataEstimatingMovementsHuman2019,
  title = {Estimating {{Movements}} of {{Human Body}} for the {{Shirt-Type Wearable Device Mounted}} on the {{Strain Sensors Based}} on {{Convolutional Neural Networks}}},
  booktitle = {2019 41st {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Ogata, K. and Matsumoto, Y.},
  date = {2019-07},
  pages = {5871--5876},
  issn = {1558-4615},
  doi = {10.1109/EMBC.2019.8856722},
  url = {10.1109/EMBC.2019.8856722},
  abstract = {To measure the life log of humans and enjoy virtual or augmented reality video games, several wearable devices have been developed that allow users to intuitively input commands. However, monitoring and estimating three-dimensional human motions for extended periods using the wearable devices is difficult. Therefore, this study aims to develop a method that estimates the joint angles of the upper human body using a wearable suit implanted with strain sensors with a nonlinear characteristic. We used a convolutional neural network (CNN) to estimate the joint angles. We established a CNN estimator based on the training data of two adult males and confirmed that this estimator could estimate the joint angles of other adult males. To monitor the caretakers in a care facility, we measure the care-working motion, such as motions that care workers transform the elder persons, estimate each joint angle, and visualize the motions on Unity.},
  eventtitle = {2019 41st {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  keywords = {Acceleration,acceleration sensor,Adult,angular sensor,biology computing,Biomedical monitoring,Capacitive sensors,CNN estimator,Convolution,convolutional neural nets,convolutional neural network,data visualisation,E-skin,Elbow,human activity monitoring,human body movements,human computer interaction,Humans,inertia motion capture system,joint angle estimation,magnetic sensor,Male,Middle Aged,mobile computing,motion estimation,Motion measurement,motion visualization,Movement,Neural Networks Computer,sensor fusion,shirt-type wearable device,strain sensors,three-dimensional human motion estimation,Training data,Unity,wearable computers,Wearable Electronic Devices,wearable sensor suit,已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/A8W4LGKR/Ogata_Matsumoto_2019_Estimating Movements of Human Body for the Shirt-Type Wearable Device Mounted.pdf;/Users/liurongkai/Zotero/storage/RBB67IL9/8856722.html}
}

@article{okerekeManagementCervicalSpine2021,
  title = {The {{Management}} of {{Cervical Spine Injuries}} – {{A Literature Review}}},
  author = {Okereke, Isaac and Mmerem, Kingsley and Balasubramanian, Dhanasekaraprabu},
  date = {2021-09-28},
  journaltitle = {Orthopedic Research and Reviews},
  shortjournal = {Orthop Res Rev},
  volume = {13},
  eprint = {34611449},
  eprinttype = {pmid},
  pages = {151--162},
  issn = {1179-1462},
  doi = {10.2147/ORR.S324622},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8487293/},
  urldate = {2023-05-04},
  abstract = {Due to the inherent bony instability of the cervical spine, there is an over-reliance on ligamentous structures for stability, making this segment of the vertebral column most prone to traumatic injuries. The frequently occurring mechanisms of injury include axial compression, hyper-flexion, hyper-extension, and rotational type injuries. Good pre-hospital care and a thorough assessment in the emergency department of patients suspected to have a cervical spine injury (CSI) leads to improved clinical outcomes. The objective of the initial evaluation of a patient with a suspected CSI is to identify the presence of injuries through thorough clinical and radiologic assessments as missed injuries are potentially catastrophic. The treatment of cervical spine injuries can be conservative, pharmacological, or surgical, and aims to halt SCI progression, stabilize the spine, and to allow rehabilitation of the patient.},
  pmcid = {PMC8487293},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/8QW2IYVG/Okereke et al_2021_The Management of Cervical Spine Injuries – A Literature Review.pdf}
}

@article{orejuela-zapataSelfHelpDevicesQuadriplegic2019,
  title = {Self-{{Help Devices}} for {{Quadriplegic Population}}: {{A Systematic Literature Review}}},
  shorttitle = {Self-{{Help Devices}} for {{Quadriplegic Population}}},
  author = {Orejuela-Zapata, Juan F. and Rodríguez, Sarita and Ramírez, Gonzalo Llano},
  date = {2019-04},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {27},
  number = {4},
  pages = {692--701},
  issn = {1558-0210},
  doi = {10.1109/TNSRE.2019.2901399},
  url = {10.1109/TNSRE.2019.2901399},
  abstract = {This systematic literature review collects and discusses the main needs, expectations, and barriers of people with quadriplegia and caregivers in relation to the self-help devices that are currently used for daily tasks. The major advantages, disadvantages, and challenges of the existing assistive technology are exposed and discussed in order to evaluate whether an existing technology could be combined with others to expand its scope, enhance its performance, or solve its limitations improving the adherence of quadriplegic population to these technologies and enhancing their quality of life.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Systems}} and {{Rehabilitation Engineering}}},
  keywords = {assistive technology,Bibliographies,biomedical measurement,Brain-computer interfaces,Electrodes,Electroencephalography,human-robot interaction,Performance evaluation,Sociology,Statistics,Task analysis,在读,引用,感兴趣的,综述,重要文章},
  file = {/Users/liurongkai/Zotero/storage/CBI4IT4Z/Orejuela-Zapata et al_2019_Self-Help Devices for Quadriplegic Population.pdf;/Users/liurongkai/Zotero/storage/7T46Z8ZH/8651427.html}
}

@inproceedings{paraschosProbabilisticMovementPrimitives2013,
  title = {Probabilistic {{Movement Primitives}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Paraschos, Alexandros and Daniel, Christian and Peters, Jan R and Neumann, Gerhard},
  date = {2013},
  volume = {26},
  publisher = {{Curran Associates, Inc.}},
  url = {https://papers.nips.cc/paper_files/paper/2013/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html},
  urldate = {2024-02-03},
  abstract = {Movement Primitives (MP) are a well-established approach for representing modular and re-usable robot movement generators. Many state-of-the-art robot learning successes are based MPs, due to their compact representation of the inherently continuous and high dimensional robot movements. A major goal in robot learning is to combine multiple MPs as building blocks in a modular control architecture to solve complex tasks. To this effect, a MP representation has to allow for blending between motions, adapting to altered task variables, and co-activating multiple MPs in parallel. We present a probabilistic formulation of the MP concept that maintains a distribution over trajectories. Our probabilistic approach allows for the derivation of new operations which are essential for implementing all aforementioned properties in one framework. In order to use such a trajectory distribution for robot movement control, we analytically derive a stochastic feedback controller which reproduces the given trajectory distribution. We evaluate and compare our approach to existing methods on several simulated as well as real robot scenarios.},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/R6CLIMU4/Paraschos et al_2013_Probabilistic Movement Primitives.pdf}
}

@inproceedings{parkDiscretetimeDynamicModeling2017,
  title = {Discrete-Time Dynamic Modeling and Calibration of Differential-Drive Mobile Robots with Friction},
  booktitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Park, Jong Jin and Lee, Seungwon and Kuipers, Benjamin},
  date = {2017-05},
  pages = {6510--6517},
  publisher = {{IEEE}},
  location = {{Singapore, Singapore}},
  doi = {10.1109/ICRA.2017.7989769},
  url = {http://ieeexplore.ieee.org/document/7989769/},
  urldate = {2023-12-22},
  abstract = {Fast and high-fidelity dynamic model is very useful for planning, control, and estimation. Here, we present a fixed-time-step, discrete-time dynamic model of differentialdrive vehicle with friction for reliable velocity prediction, which is fast, stable, and easy to calibrate.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5090-4633-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/U2T6R8F6/Park 等 - 2017 - Discrete-time dynamic modeling and calibration of .pdf}
}

@inproceedings{pengDataDrivenReinforcementLearning2020,
  title = {Data-{{Driven Reinforcement Learning}} for {{Walking Assistance Control}} of a {{Lower Limb Exoskeleton}} with {{Hemiplegic Patients}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Peng, Zhinan and Luo, Rui and Huang, Rui and Hu, Jiangping and Shi, Kecheng and Cheng, Hong and Ghosh, Bijoy Kumar},
  date = {2020-05},
  pages = {9065--9071},
  issn = {2577-087X},
  doi = {10.1109/ICRA40945.2020.9197229},
  url = {10.1109/ICRA40945.2020.9197229},
  abstract = {Lower limb exoskeleton (LLE) has received considerable interests in strength augmentation, rehabilitation and walking assistance scenarios. For walking assistance, the LLE is expected to have the capability of controlling the affected leg to track the unaffected leg's motion naturally. An important issue in this scenario is that the exoskeleton system needs to deal with unpredictable disturbance from the patient, which requires the controller of exoskeleton system to have the ability to adapt to different wearers. This paper proposes a novel Data-Driven Reinforcement Learning (DDRL) control strategy to adapt different hemiplegic patients with unpredictable disturbances. In the proposed DDRL strategy, the interaction between two lower limbs of LLE and the legs of hemiplegic patient are modeled in the context of leader-follower framework. The walking assistance control problem is transformed into a optimal control problem. Then, a policy iteration (PI) algorithm is introduced to learn optimal controller. To achieve online adaptation control for different patients, based on PI algorithm, an Actor-Critic Neural Network (ACNN) technology of the reinforcement learning (RL) is employed in the proposed DDRL. We conduct experiments both on a simulation environment and a real LLE system. Experimental results demonstrate that the proposed control strategy has strong robustness against disturbances and adaptability to different pilots.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {Actor-Critic Neural Network,Adaptation models,Data-driven Control,Exoskeletons,Extremities,Hemiplegic Patients,Leader-Follower Multi-Agent System,Learning (artificial intelligence),Legged locomotion,Lower Limb Exoskeleton,Optimal control,Reinforcement Learning,Trajectory,引用},
  file = {/Users/liurongkai/Zotero/storage/AMI5GKG6/Peng et al_2020_Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower.pdf;/Users/liurongkai/Zotero/storage/KLK6N8RC/9197229.html}
}

@inproceedings{perez-del-pulgarUsingLearningDemonstration2016,
  title = {Using Learning from Demonstration to Generate Real-Time Guidance for Haptic Shared Control},
  booktitle = {2016 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  author = {Perez-del-Pulgar, C. J. and Smisek, Jan and Munoz, V. F. and Schiele, Andre},
  date = {2016-10},
  pages = {003205--003210},
  publisher = {{IEEE}},
  location = {{Budapest, Hungary}},
  doi = {10.1109/SMC.2016.7844727},
  url = {http://ieeexplore.ieee.org/document/7844727/},
  urldate = {2024-02-02},
  abstract = {This paper introduces a new Learning from Demonstration (LfD)-based method that makes usage of robot effector forces and torques recorded during expert demonstrations, to generate force-based haptic guidance reference trajectories online, that are intended to be used during haptic shared control for additional operator ‘guidance’. Derived haptic guidance trajectories are superimposed to master-device inputs and feedback forces within a bilateral control experiment, to assist an operator by the guidance during peg-in-hole insertion. We show that 96 peg-in-hole expert demonstrations were sufficient to obtain a good model of the task, which was used on-line to generate haptic guidance trajectories in real-time with a 1kHz sampling rate.},
  eventtitle = {2016 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{SMC}})},
  isbn = {978-1-5090-1897-0},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/9X3XEXUW/Perez-del-Pulgar 等 - 2016 - Using learning from demonstration to generate real.pdf}
}

@inproceedings{peternelAdaptationRobotPhysical2016,
  title = {Adaptation of Robot Physical Behaviour to Human Fatigue in Human-Robot Co-Manipulation},
  booktitle = {2016 {{IEEE-RAS}} 16th {{International Conference}} on {{Humanoid Robots}} ({{Humanoids}})},
  author = {Peternel, Luka and Tsagarakis, Nikos and Caldwell, Darwin and Ajoudani, Arash},
  date = {2016-11},
  pages = {489--494},
  publisher = {{IEEE}},
  location = {{Cancun, Mexico}},
  doi = {10.1109/HUMANOIDS.2016.7803320},
  url = {http://ieeexplore.ieee.org/document/7803320/},
  urldate = {2024-02-02},
  abstract = {In this paper, we propose a method that allows the robot to adapt its physical behaviour to the human fatigue in human-robot co-manipulation tasks. The robot initially imitates the human to perform the collaborative task in a leader-follower setting, using a feedback about the human motor behaviour. Simultaneously, the robot obtains the skill in online manner. When a predetermined level of human fatigue is detected, the robot uses the learnt skill to take over the physically demanding aspect of the task and contributes to a significant reduction of the human effort. The human, on the other hand, controls and supervises the high-level interaction behaviour and performs the aspects that require the contribution of both agents in such a dynamic co-manipulation setup. The robot adaptation system is based on the Dynamical Movement Primitives, Locally Weighted Regression and Adaptive Frequency Oscillators. The estimation of the human motor fatigue is carried out using a proposed online model, which is based on the human muscle activity measured by the electromyography. We demonstrate the proposed method with experiments on a real-world comanipulation task with environmental constraints and dynamic uncertainties.},
  eventtitle = {2016 {{IEEE-RAS}} 16th {{International Conference}} on {{Humanoid Robots}} ({{Humanoids}})},
  isbn = {978-1-5090-4718-5},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/3MQ87GH5/Peternel 等 - 2016 - Adaptation of robot physical behaviour to human fa.pdf}
}

@article{phinyomarkFeatureExtractionSelection2018,
  title = {Feature {{Extraction}} and {{Selection}} for {{Myoelectric Control Based}} on {{Wearable EMG Sensors}}},
  author = {Phinyomark, Angkoon and N. Khushaba, Rami and Scheme, Erik},
  date = {2018-05-18},
  journaltitle = {Sensors (Basel, Switzerland)},
  shortjournal = {Sensors (Basel)},
  volume = {18},
  number = {5},
  eprint = {29783659},
  eprinttype = {pmid},
  pages = {1615},
  issn = {1424-8220},
  doi = {10.3390/s18051615},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5982518/},
  urldate = {2024-01-07},
  abstract = {Specialized myoelectric sensors have been used in prosthetics for decades, but, with recent advancements in wearable sensors, wireless communication and embedded technologies, wearable electromyographic (EMG) armbands are now commercially available for the general public. Due to physical, processing, and cost constraints, however, these armbands typically sample EMG signals at a lower frequency (e.g., 200 Hz for the Myo armband) than their clinical counterparts. It remains unclear whether existing EMG feature extraction methods, which largely evolved based on EMG signals sampled at 1000 Hz or above, are still effective for use with these emerging lower-bandwidth systems. In this study, the effects of sampling rate (low: 200 Hz vs. high: 1000 Hz) on the classification of hand and finger movements were evaluated for twenty-six different individual features and eight sets of multiple features using a variety of datasets comprised of both able-bodied and amputee subjects. The results show that, on average, classification accuracies drop significantly (p{$<$} 0.05) from 2\% to 56\% depending on the evaluated features when using the lower sampling rate, and especially for transradial amputee subjects. Importantly, for these subjects, no number of existing features can be combined to compensate for this loss in higher-frequency content. From these results, we identify two new sets of recommended EMG features (along with a novel feature, L-scale) that provide better performance for these emerging low-sampling rate systems.},
  pmcid = {PMC5982518},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/K57HN9AK/Phinyomark et al_2018_Feature Extraction and Selection for Myoelectric Control Based on Wearable EMG.pdf}
}

@article{pineauSmartWheelerRoboticWheelchair,
  title = {{{SmartWheeler}}: {{A Robotic Wheelchair Test-Bed}} for {{Investigating New Models}} of {{Human-Robot Interaction}}},
  author = {Pineau, Joelle},
  abstract = {The goal of the SmartWheeler project is to increase the autonomy and safety of individuals with severe mobility impairments by developing a robotic wheelchair that is adapted to their needs. The project tackles a range of challenging issues, focusing in particular on tasks pertaining to human-robot interaction, and on robust control of the intelligent wheelchair. The platform we have built also serves as a test-bed for validating novel concepts and algorithms for automated decisionmaking onboard socially assistive robots. This paper introduces the wheelchair platform, and outlines technique contributions in four ongoing research areas: adaptive planning in large-scale environments, learning and control under model uncertainty, large-scale dialogue management, and communication protocols for the tactile interface.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/PTWGD7RA/Pineau - SmartWheeler A Robotic Wheelchair Test-Bed for In.pdf}
}

@article{plochlCombiningEEGEye2012,
  title = {Combining {{EEG}} and Eye Tracking: Identification, Characterization, and Correction of Eye Movement Artifacts in Electroencephalographic Data},
  shorttitle = {Combining {{EEG}} and Eye Tracking},
  author = {Plöchl, Michael and Ossandón, José P. and König, Peter},
  date = {2012},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front. Hum. Neurosci.},
  volume = {6},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2012.00278},
  url = {http://journal.frontiersin.org/article/10.3389/fnhum.2012.00278/abstract},
  urldate = {2024-01-13},
  abstract = {Eye movements introduce large artifacts to electroencephalographic recordings (EEG) and thus render data analysis difficult or even impossible. Trials contaminated by eye movement and blink artifacts have to be discarded, hence in standard EEG-paradigms subjects are required to fixate on the screen. To overcome this restriction, several correction methods including regression and blind source separation have been proposed. Yet, there is no automated standard procedure established. By simultaneously recording eye movements and 64-channel-EEG during a guided eye movement paradigm, we investigate and review the properties of eye movement artifacts, including corneo-retinal dipole changes, saccadic spike potentials and eyelid artifacts, and study their interrelations during different types of eye- and eyelid movements. In concordance with earlier studies our results confirm that these artifacts arise from different independent sources and that depending on electrode site, gaze direction, and choice of reference these sources contribute differently to the measured signal. We assess the respective implications for artifact correction methods and therefore compare the performance of two prominent approaches, namely linear regression and independent component analysis (ICA). We show and discuss that due to the independence of eye artifact sources, regression-based correction methods inevitably over- or under-correct individual artifact components, while ICA is in principle suited to address such mixtures of different types of artifacts. Finally, we propose an algorithm, which uses eye tracker information to objectively identify eye-artifact related ICA-components (ICs) in an automated manner. In the data presented here, the algorithm performed very similar to human experts when those were given both, the topographies of the ICs and their respective activations in a large amount of trials. Moreover it performed more reliable and almost twice as effective than human experts when those had to base their decision on IC topographies only. Furthermore, a receiver operating characteristic (ROC) analysis demonstrated an optimal balance of false positive and false negative at an area under curve (AUC) of more than 0.99. Removing the automatically detected ICs from the data resulted in removal or substantial suppression of ocular artifacts including microsaccadic spike potentials, while the relevant neural signal remained unaffected. In conclusion the present work aims at a better understanding of individual eye movement artifacts, their interrelations and the respective implications for eye artifact correction. Additionally, the proposed ICA-procedure provides a tool for optimized detection and correction of eye movement-related artifact components.},
  langid = {english},
  file = {/Users/liurongkai/Zotero/storage/N7XSYAUQ/Plöchl 等 - 2012 - Combining EEG and eye tracking identification, ch.pdf}
}

@article{ptShoulderProprioceptionHow2017,
  title = {Shoulder Proprioception: {{How}} Is It Measured and Is It Reliable? {{A}} Systematic Review},
  author = {Pt, Amanda L Ager},
  date = {2017},
  journaltitle = {Journal of Hand Therapy},
  abstract = {Introduction: Constituents of proprioception include our awareness of the position (joint position sense [JPS]) and motion (kinesthesia) of our limbs in space. Proprioceptive deficits are associated with musculoskeletal disorders but remain a challenge to quantify, particularly at the shoulder. Purpose of the Study: To report the psychometric values of validity, reliability, and responsiveness for shoulder JPS and/or kinesthesia protocols. Methods: A review of 5 databases was conducted from inception to July 2016 for studies reporting a psychometric property of a shoulder proprioception protocol. The included studies were evaluated using the QualSyst checklist and COSMIN 4-point scale. Results: Twenty-one studies were included, yielding 407 participants and 553 evaluated shoulders (n). The included studies support excellent methodological scores using the QualSyst checklist (88.1 Æ 9.9\%) and good psychometric scores with the COSMIN for reliability (71.1\%) and moderate-to-low quality score (50\%) for criterion validity. Weighted average intraclass correlation coefficients (ICCs) for intrarater reliability were highest for passive JPS and kinesthesia, ICC ¼ 0.92 Æ 0.07 (n ¼ 214) and ICC ¼ 0.92 Æ 0.04 (n ¼ 74), respectively. The most reliable movement and tool are internal rotation at 90  of abduction, ICC ¼ 0.88 Æ 0.01 (n ¼ 53), and the dynamometer, ICC ¼ 0.92 Æ 0.88 (n ¼ 225). Only 2 studies quantify an aspect of validity and no responsiveness indices were reported among the included studies. Conclusion: Based on the results of the included studies, the evaluation of shoulder proprioception is most reliable when using a passive protocol with an isokinetic dynamometer for internal rotation at 90  of shoulder abduction. Standardized protocols addressing the psychometric properties of shoulder proprioception measures are needed.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/NM5R6YD4/Pt - 2017 - Shoulder proprioception How is it measured and is.pdf}
}

@inproceedings{qinanliDynamicSharedControl2011,
  title = {Dynamic Shared Control for Human-Wheelchair Cooperation},
  booktitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {{Qinan Li} and {Weidong Chen} and {Jingchuan Wang}},
  date = {2011-05},
  pages = {4278--4283},
  publisher = {{IEEE}},
  location = {{Shanghai, China}},
  doi = {10.1109/ICRA.2011.5980055},
  url = {http://ieeexplore.ieee.org/document/5980055/},
  urldate = {2024-02-01},
  abstract = {Shared control is a common used method for human and wheelchair cooperation. However, most of the previous shared control methods didn’t think much of the effect caused by the difference in the user’s control ability. The control weight of a user in these methods is irrelevant to the user’s capability or the driving conditions. In this paper, a dynamic shared control method is proposed to adapt wheelchair’s assistance to the variations of user performance and the environmental changes. Three evaluation indices including safety, comfort and obedience are designed to evaluate wheelchair performance in real time. A minimax multi-objective optimization algorithm is adopted to calculate the user’s control weight. The results of lab experiments and elderly home field tests show that this method can adapt the degree of wheelchair’s autonomy to the user’s control ability and it makes driving wheelchair much easier for elder people.},
  eventtitle = {2011 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-61284-386-5},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/M2H9SXLS/Qinan Li 等 - 2011 - Dynamic shared control for human-wheelchair cooper.pdf}
}

@article{rabinerIntroductionHiddenMarkov1986,
  title = {An Introduction to Hidden {{Markov}} Models},
  author = {Rabiner, L. and Juang, B.},
  date = {1986},
  journaltitle = {IEEE ASSP Magazine},
  shortjournal = {IEEE ASSP Mag.},
  volume = {3},
  number = {1},
  pages = {4--16},
  issn = {0740-7467},
  doi = {10.1109/MASSP.1986.1165342},
  url = {http://ieeexplore.ieee.org/document/1165342/},
  urldate = {2024-02-03},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/MF6AW7PD/Rabiner 和 Juang - 1986 - An introduction to hidden Markov models.pdf}
}

@article{raffertyInferringLearnersKnowledge,
  title = {Inferring Learners’ Knowledge from Observed Actions},
  author = {Rafferty, Anna N and LaMar, Michelle M and Griffiths, Thomas L},
  pages = {2},
  abstract = {Teachers gain significant information about their students through close observation of classroom activities. By noting which actions a student takes to achieve particular goals, a teacher can often infer the knowledge possessed by the student and diagnose misconceptions. In this work, we develop a framework for automatically inferring a student’s underlying beliefs from a set of observed actions. This framework relies on modeling how student actions follow from beliefs about the effects of those actions. We demonstrate the practicality of this approach by modeling empirical student data from an educational game and validate its performance via a controlled lab experiment. In the educational game, inferences were consistent with conventional assessment measures; in the lab experiment, the model’s inferences reflect participants’ stated beliefs.},
  langid = {english},
  keywords = {已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/MEXT2AHY/Rafferty 等。 - Inferring learners’ knowledge from observed action.pdf}
}

@article{rebsamenBrainControlledWheelchair2010,
  title = {A {{Brain Controlled Wheelchair}} to {{Navigate}} in {{Familiar Environments}}},
  author = {Rebsamen, Brice and Guan, Cuntai and Zhang, Haihong and Wang, Chuanchu and Teo, Cheeleong and Ang, Marcelo H. and Burdet, Etienne},
  date = {2010-12},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  shortjournal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
  volume = {18},
  number = {6},
  pages = {590--598},
  issn = {1534-4320, 1558-0210},
  doi = {10.1109/TNSRE.2010.2049862},
  url = {https://ieeexplore.ieee.org/document/5462915/},
  urldate = {2023-12-25},
  abstract = {While brain–computer interfaces (BCIs) can provide communication to people who are locked-in, they suffer from a very low information transfer rate. Further, using a BCI requires a concentration effort and using it continuously can be tiring. The brain controlled wheelchair (BCW) described in this paper aims at providing mobility to BCI users despite these limitations, in a safe and efficient way. Using a slow but reliable P300 based BCI, the user selects a destination amongst a list of predefined locations. While the wheelchair moves on virtual guiding paths ensuring smooth, safe, and predictable trajectories, the user can stop the wheelchair by using a faster BCI. Experiments with nondisabled subjects demonstrated the efficiency of this strategy. Brain control was not affected when the wheelchair was in motion, and the BCW enabled the users to move to various locations in less time and with significantly less control effort than other control strategies proposed in the literature.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/ZKEHQ99N/Rebsamen 等 - 2010 - A Brain Controlled Wheelchair to Navigate in Famil.pdf}
}

@inproceedings{reddyWhereYouThink2018,
  title = {Where {{Do You Think You}}' Re {{Going}}?: {{Inferring Beliefs}} about {{Dynamics}} from {{Behavior}}},
  shorttitle = {Where {{Do You Think You}}' Re {{Going}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Reddy, Sid and Dragan, Anca and Levine, Sergey},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/6f2268bd1d3d3ebaabb04d6b5d099425-Abstract.html},
  urldate = {2021-12-02},
  keywords = {已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/2YWMPYHA/Reddy et al_2018_Where Do You Think You' re Going.pdf}
}

@article{richhariyaEEGSignalClassification2018,
  title = {{{EEG}} Signal Classification Using Universum Support Vector Machine},
  author = {Richhariya, B. and Tanveer, M.},
  date = {2018-09},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {106},
  pages = {169--182},
  issn = {09574174},
  doi = {10.1016/j.eswa.2018.03.053},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417418302100},
  urldate = {2024-01-07},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/MNE2Y4IJ/Richhariya 和 Tanveer - 2018 - EEG signal classification using universum support .pdf}
}

@article{righettiDynamicHebbianLearning2006a,
  title = {Dynamic {{Hebbian}} Learning in Adaptive Frequency Oscillators},
  author = {Righetti, Ludovic and Buchli, Jonas and Ijspeert, Auke Jan},
  date = {2006-04},
  journaltitle = {Physica D: Nonlinear Phenomena},
  shortjournal = {Physica D: Nonlinear Phenomena},
  volume = {216},
  number = {2},
  pages = {269--281},
  issn = {01672789},
  doi = {10.1016/j.physd.2006.02.009},
  url = {10.1016/j.physd.2006.02.009},
  urldate = {2020-11-01},
  abstract = {Nonlinear oscillators are widely used in biology, physics and engineering for modeling and control. They are interesting because of their synchronization properties when coupled to other dynamical systems. In this paper, we propose a learning rule for oscillators which adapts their frequency to the frequency of any periodic or pseudo-periodic input signal. Learning is done in a dynamic way: it is part of the dynamical system and not an offline process. An interesting property of our model is that it is easily generalizable to a large class of oscillators, from phase oscillators to relaxation oscillators and strange attractors with a generic learning rule. One major feature of our learning rule is that the oscillators constructed can adapt their frequency without any signal processing or the need to specify a time window or similar free parameters. All the processing is embedded in the dynamics of the adaptive oscillator. The convergence of the learning is proved for the Hopf oscillator, then numerical experiments are carried out to explore the learning capabilities of the system. Finally, we generalize the learning rule to non-harmonic oscillators like relaxation oscillators and strange attractors.},
  langid = {english},
  keywords = {已读,引用,感兴趣的,有价值},
  file = {/Users/liurongkai/Zotero/storage/SP6VJGT6/Righetti 等。 - 2006 - Dynamic Hebbian learning in adaptive frequency osc.pdf}
}

@article{rivera-florCCABasedCompressiveSensing2022,
  title = {{{CCA-Based Compressive Sensing}} for {{SSVEP-Based Brain-Computer Interfaces}} to {{Command}} a {{Robotic Wheelchair}}},
  author = {Rivera-Flor, Hamilton and Gurve, Dharmendra and Floriano, Alan and Delisle-Rodriguez, Denis and Mello, Ricardo and Bastos-Filho, Teodiano},
  date = {2022},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {71},
  pages = {1--10},
  issn = {1557-9662},
  doi = {10.1109/TIM.2022.3218102},
  abstract = {People with severe physical disabilities are not able of using standard robotic wheelchairs, which generally demand some motor skills, and therefore total usage of associate muscles. Robotic wheelchairs commanded by brain-computer interfaces (BCIs) based on electroencephalography have demonstrated to be an alternative for these end-users. In general, existing robotic wheelchairs commanded by BCIs require special platforms adapted to the EEG-BCI, and end-users need to attend a long training process to safely drive these devices. But many times these potential users do not have access to training sessions; due to mobility problems or technology access restrictions. This study proposes an EEG-based BCI with a customizable configuration to be used in cloud architectures for the remote control of robotic wheelchairs. This research explores two types of steady-state visual evoked potential (SSVEP)-based BCI by applying canonical correlation analysis (CCA) and compressive sensing (CS) as a novelty, adopting one free calibration, and the other including a calibration stage. The free-calibrated SSVEP recognition approach (CS-ncCCA) using compression ratio (CR) at 60\% obtained accuracy (ACC) of 85\% and information transfer rate (ITR) of 102 bits per minute (b/min), whereas the calibrated BCI (CS-wcCCA) applying also CR at 62\% achieved ACC of 85\% and ITR of 195 b/min. As a highlight, the proposed BCI allows a significant reduction of the transmitted file size (TFS) and improves the communication latency that may be useful in remote and cloud robotics applications, such as for users with severe motor disabilities, to train driving safely robotic wheelchairs via Internet of Things (IoT).},
  eventtitle = {{{IEEE Transactions}} on {{Instrumentation}} and {{Measurement}}},
  keywords = {Brain computer interfaces (BCIs),Cloud computing,compressive sensing (CS),Electroencephalography,Mobile robots,Robot sensing systems,robotic wheelchairs,steady-state visual evoked potentials (SSVEPs),Training,Visualization,Wheelchairs,引用},
  file = {/Users/liurongkai/Zotero/storage/8XWZTNMZ/Rivera-Flor 等 - 2022 - CCA-Based Compressive Sensing for SSVEP-Based Brai.pdf;/Users/liurongkai/Zotero/storage/I4V9A7CH/9933046.html}
}

@article{rizzoglioHybridBodyMachineInterface2020,
  title = {A Hybrid {{Body-Machine Interface}} Integrating Signals from Muscles and Motions},
  author = {Rizzoglio, Fabio and Pierella, Camilla and De Santis, Dalia and Mussa-Ivaldi, Ferdinando and Casadio, Maura},
  date = {2020-08-01},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {17},
  number = {4},
  pages = {046004},
  issn = {1741-2560, 1741-2552},
  doi = {10.1088/1741-2552/ab9b6c},
  url = {https://iopscience.iop.org/article/10.1088/1741-2552/ab9b6c},
  urldate = {2022-10-08},
  abstract = {Objective. Body-Machine Interfaces (BoMIs) establish a way to operate a variety of devices, allowing their users to extend the limits of their motor abilities by exploiting the redundancy of muscles and motions that remain available after spinal cord injury or stroke. Here, we considered the integration of two types of signals, motion signals derived from inertial measurement units (IMUs) and muscle activities recorded with electromyography (EMG), both contributing to the operation of the BoMI. Approach. A direct combination of IMU and EMG signals might result in inefficient control due to the differences in their nature. Accordingly, we used a nonlinearregression-based approach to predict IMU from EMG signals, after which the predicted and actual IMU signals were combined into a hybrid control signal. The goal of this approach was to provide users with the possibility to switch seamlessly between movement and EMG control, using the BoMI as a tool for promoting the engagement of selected muscles. We tested the interface in three control modalities, EMG-only, IMU-only and hybrid, in a cohort of 15 unimpaired participants. Participants practiced reaching movements by guiding a computer cursor over a set of targets. Main results. We found that the proposed hybrid control led to comparable performance to IMU-based control and significantly outperformed the EMG-only control. Results also indicated that hybrid cursor control was predominantly influenced by EMG signals. Significance. We concluded that combining EMG with IMU signals could be an efficient way to target muscle activations while overcoming the limitations of an EMG-only control.},
  langid = {english},
  keywords = {在读,引用,有价值,过往文章},
  file = {/Users/liurongkai/Zotero/storage/M2WFRF4L/Rizzoglio 等。 - 2020 - A hybrid Body-Machine Interface integrating signal.pdf}
}

@online{RoleCollaborativeRobotics,
  title = {The Role of Collaborative Robotics in Assistive and Rehabilitation Applications},
  doi = {10.1126/scirobotics.adk6743},
  url = {https://www.science.org/doi/10.1126/scirobotics.adk6743},
  urldate = {2024-01-03},
  langid = {english},
  file = {/Users/liurongkai/Zotero/storage/VXR4S3S6/scirobotics.html}
}

@article{romanoCoDyCoProjectAchievements2018,
  title = {The {{CoDyCo Project Achievements}} and {{Beyond}}: {{Toward Human Aware Whole-Body Controllers}} for {{Physical Human Robot Interaction}}},
  shorttitle = {The {{CoDyCo Project Achievements}} and {{Beyond}}},
  author = {Romano, Francesco and Nava, Gabriele and Azad, Morteza and Camernik, Jernej and Dafarra, Stefano and Dermy, Oriane and Latella, Claudia and Lazzaroni, Maria and Lober, Ryan and Lorenzini, Marta and Pucci, Daniele and Sigaud, Olivier and Traversaro, Silvio and Babic, Jan and Ivaldi, Serena and Mistry, Michael and Padois, Vincent and Nori, Francesco},
  date = {2018-01},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {3},
  number = {1},
  pages = {516--523},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2017.2768126},
  url = {https://ieeexplore.ieee.org/document/8093992/},
  urldate = {2024-02-19},
  abstract = {The success of robots in real-world environments is largely dependent on their ability to interact with both humans and said environment.The FP7 EU project CoDyCo focused on the latter of these two challenges by exploiting both rigid and compliant contacts dynamics in the robot control problem. Regarding the former, to properly manage interaction dynamics on the robot control side, an estimation of the human behaviors and intentions is necessary. In this letter, we present the building blocks of such a human-in-the-loop controller, and validate them in both simulation and on the iCub humanoid robot using a human–robot interaction scenario. In this scenario, a human assists the robot in standing up from being seated on a bench.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/C5BU2V7B/Romano 等 - 2018 - The CoDyCo Project Achievements and Beyond Toward.pdf}
}

@article{ronsseOscillatorbasedAssistanceCyclical2011,
  title = {Oscillator-Based Assistance of Cyclical Movements: Model-Based and Model-Free Approaches},
  shorttitle = {Oscillator-Based Assistance of Cyclical Movements},
  author = {Ronsse, Renaud and Lenzi, Tommaso and Vitiello, Nicola and Koopman, Bram and Van Asseldonk, Edwin and De Rossi, Stefano Marco Maria and Van Den Kieboom, Jesse and Van Der Kooij, Herman and Carrozza, Maria Chiara and Ijspeert, Auke Jan},
  date = {2011-10},
  journaltitle = {Medical \& Biological Engineering \& Computing},
  shortjournal = {Med Biol Eng Comput},
  volume = {49},
  number = {10},
  pages = {1173--1185},
  issn = {0140-0118, 1741-0444},
  doi = {10.1007/s11517-011-0816-1},
  url = {http://link.springer.com/10.1007/s11517-011-0816-1},
  urldate = {2023-12-16},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/SWMLVCHM/Ronsse 等 - 2011 - Oscillator-based assistance of cyclical movements.pdf}
}

@article{rulikControlWheelchairMounted6DOF2022,
  title = {Control of a {{Wheelchair-Mounted 6DOF Assistive Robot With Chin}} and {{Finger Joysticks}}},
  author = {Rulik, Ivan and Sunny, Md Samiul Haque and Sanjuan De Caro, Javier Dario and Zarif, Md Ishrak Islam and Brahmi, Brahim and Ahamed, Sheikh Iqbal and Schultz, Katie and Wang, Inga and Leheng, Tony and Longxiang, Jason Peng and Rahman, Mohammad H.},
  date = {2022-07-22},
  journaltitle = {Frontiers in Robotics and AI},
  shortjournal = {Front. Robot. AI},
  volume = {9},
  pages = {885610},
  issn = {2296-9144},
  doi = {10.3389/frobt.2022.885610},
  url = {https://www.frontiersin.org/articles/10.3389/frobt.2022.885610/full},
  urldate = {2023-12-23},
  abstract = {Throughout the last decade, many assistive robots for people with disabilities have been developed; however, researchers have not fully utilized these robotic technologies to entirely create independent living conditions for people with disabilities, particularly in relation to activities of daily living (ADLs). An assistive system can help satisfy the demands of regular ADLs for people with disabilities. With an increasing shortage of caregivers and a growing number of individuals with impairments and the elderly, assistive robots can help meet future healthcare demands. One of the critical aspects of designing these assistive devices is to improve functional independence while providing an excellent human–machine interface. People with limited upper limb function due to stroke, spinal cord injury, cerebral palsy, amyotrophic lateral sclerosis, and other conditions find the controls of assistive devices such as power wheelchairs difficult to use. Thus, the objective of this research was to design a multimodal control method for robotic self-assistance that could assist individuals with disabilities in performing self-care tasks on a daily basis. In this research, a control framework for two interchangeable operating modes with a finger joystick and a chin joystick is developed where joysticks seamlessly control a wheelchair and a wheelchair-mounted robotic arm. Custom circuitry was developed to complete the control architecture. A user study was conducted to test the robotic system. Ten healthy individuals agreed to perform three tasks using both (chin and finger) joysticks for a total of six tasks with 10 repetitions each. The control method has been tested rigorously, maneuvering the robot at different velocities and under varying payload (1–3.5 lb) conditions. The absolute position accuracy was experimentally found to be approximately 5 mm. The round-trip delay we observed between the commands while controlling the xArm was 4 ms. Tests performed showed that the proposed control system allowed individuals to perform some ADLs such as picking up and placing items with a completion time of less than 1 min for each task and 100\% success.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/KV6CFHMN/Rulik 等 - 2022 - Control of a Wheelchair-Mounted 6DOF Assistive Rob.pdf}
}

@article{samper-escuderoEfficientMultiaxialShoulderMotion2020,
  title = {Efficient {{Multiaxial Shoulder-Motion Tracking Based}} on {{Flexible Resistive Sensors Applied}} to {{Exosuits}}},
  author = {Samper-Escudero, J. Luis and Contreras-González, Aldo F. and Ferre, Manuel and Sánchez-Urán, Miguel A. and Pont-Esteban, David},
  date = {2020-06-01},
  journaltitle = {Soft Robotics},
  shortjournal = {Soft Robotics},
  volume = {7},
  number = {3},
  pages = {370--385},
  issn = {2169-5172, 2169-5180},
  doi = {10.1089/soro.2019.0040},
  url = {https://www.liebertpub.com/doi/10.1089/soro.2019.0040},
  urldate = {2020-12-03},
  abstract = {This article describes the performance of a flexible resistive sensor network to track shoulder motion. This system monitors every gesture of the human shoulder in its range of motion except rotations around the longitudinal axis of the arm. In this regard, the design considers the movement of the glenohumeral, acromioclavicular, sternoclavicular, and scapulothoracic joints. The solution presented in this work considers several sensor configurations and compares its performance with a set of inertial measurement units (IMUs). These devices have been put together in a shoulder suit with Optitrack visual markers in order to be used as pose ground truth. Optimal configurations of flexible resistive sensors, in terms of accuracy requirements and number of sensors, have been obtained by applying principal component analysis techniques. The data provided by each configuration are then mapped onto the shoulder pose by using neural network algorithms. According to the results shown in this article, a set of flexible resistive sensors can be an adequate alternative to IMUs for multiaxial shoulder pose tracking in open spaces. Furthermore, the system presented can be easily embedded in fabric or wearable devices without obstructing the user’s motion.},
  langid = {english},
  keywords = {已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/RY2AV4V3/Samper-Escudero 等。 - 2020 - Efficient Multiaxial Shoulder-Motion Tracking Base.pdf}
}

@article{saverianoDynamicMovementPrimitives2023,
  title = {Dynamic Movement Primitives in Robotics: {{A}} Tutorial Survey},
  shorttitle = {Dynamic Movement Primitives in Robotics},
  author = {Saveriano, Matteo and Abu-Dakka, Fares J and Kramberger, Aljaž and Peternel, Luka},
  date = {2023-11},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {42},
  number = {13},
  pages = {1133--1184},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/02783649231201196},
  url = {http://journals.sagepub.com/doi/10.1177/02783649231201196},
  urldate = {2024-02-03},
  abstract = {Biological systems, including human beings, have the innate ability to perform complex tasks in a versatile and agile manner. Researchers in sensorimotor control have aimed to comprehend and formally define this innate characteristic. The idea, supported by several experimental findings, that biological systems are able to combine and adapt basic units of motion into complex tasks finally leads to the formulation of the motor primitives’theory. In this respect, Dynamic Movement Primitives (DMPs) represent an elegant mathematical formulation of the motor primitives as stable dynamical systems and are well suited to generate motor commands for artificial systems like robots. In the last decades, DMPs have inspired researchers in different robotic fields including imitation and reinforcement learning, optimal control, physical interaction, and human–robot co-working, resulting in a considerable amount of published papers. The goal of this tutorial survey is two-fold. On one side, we present the existing DMP formulations in rigorous mathematical terms and discuss the advantages and limitations of each approach as well as practical implementation details. In the tutorial vein, we also search for existing implementations of presented approaches and release several others. On the other side, we provide a systematic and comprehensive review of existing literature and categorize state-of-the-art work on DMP. The paper concludes with a discussion on the limitations of DMPs and an outline of possible research directions.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/7K6IIKZ5/Saveriano 等 - 2023 - Dynamic movement primitives in robotics A tutoria.pdf}
}

@article{scardovelliDesignEvaluationPeripheral2015,
  title = {The Design and Evaluation of a Peripheral Device for Use with a Computer Game Intended for Children with Motor Disabilities},
  author = {Scardovelli, Terigi Augusto and Frère, Annie France},
  date = {2015-01},
  journaltitle = {Computer Methods and Programs in Biomedicine},
  shortjournal = {Computer Methods and Programs in Biomedicine},
  volume = {118},
  number = {1},
  pages = {44--58},
  issn = {01692607},
  doi = {10.1016/j.cmpb.2014.10.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260714003472},
  urldate = {2024-01-09},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/ZELR8JMX/Scardovelli 和 Frère - 2015 - The design and evaluation of a peripheral device f.pdf}
}

@article{schaalConstructiveIncrementalLearning1998,
  title = {Constructive {{Incremental Learning}} from {{Only Local Information}}},
  author = {Schaal, Stefan and Atkeson, Christopher G.},
  date = {1998-11-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {10},
  number = {8},
  pages = {2047--2084},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976698300016963},
  url = {https://direct.mit.edu/neco/article/10/8/2047-2084/6201},
  urldate = {2021-03-26},
  abstract = {We introduce a constructive, incremental learning system for regression problems that models data by means of spatially localized linear models. In contrast to other approaches, the size and shape of the receptive field of each locally linear model, as well as the parameters of the locally linear model itself, are learned independently, that is, without the need for competition or any other kind of communication. Independent learning is accomplished by incrementally minimizing a weighted local cross-validation error. As a result, we obtain a learning system that can allocate resources as needed while dealing with the bias-variance dilemma in a principled way. The spatial localization of the linear models increases robustness toward negative interference. Our learning system can be interpreted as a nonparametric adaptive bandwidth smoother, as a mixture of experts where the experts are trained in isolation, and as a learning system that profits from combining independent expert knowledge on the same problem. This article illustrates the potential learning capabilities of purely local learning and offers an interesting and powerful approach to learning with receptive fields.},
  langid = {english},
  keywords = {引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/L6DRCWPB/Schaal 和 Atkeson - 1998 - Constructive Incremental Learning from Only Local .pdf}
}

@article{schaalImitationLearningRoute1999,
  title = {Is Imitation Learning the Route to Humanoid Robots?},
  author = {Schaal, Stefan},
  date = {1999-06},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {3},
  number = {6},
  pages = {233--242},
  issn = {13646613},
  doi = {10.1016/S1364-6613(99)01327-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661399013273},
  urldate = {2022-06-29},
  abstract = {This review investigates two recent developments in artificial intelligence and neural computation: learning from imitation and the development of humanoid robots. It will be postulated that the study of imitation learning offers a promising route to gain new insights into mechanisms of perceptual motor control that could ultimately lead to the creation of autonomous humanoid robots. Imitation learning focuses on three important issues: efficient motor learning, the connection between action and perception, and modular motor control in form of movement primitives. It will be reviewed how research on representations of, and functional connections between action and perception have contributed to our understanding of motor acts of other beings. The recent discovery that some areas in the primate brain are active during both movement perception and execution has provided a hypothetical neural basis of imitation. Computational approaches to imitation learning will also be described, initially from the perspective of traditional AI and robotics, but also from the perspective of neural network models and statistical learning research. Parallels and differences between biological and computational approaches to imitation will be highlighted and an overview of current projects that actually employ imitation learning for humanoid robots will be given.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/B8CPTBZW/Schaal - 1999 - Is imitation learning the route to humanoid robots.pdf}
}

@article{schaalScalableTechniquesNonparametric2002,
  title = {Scalable {{Techniques}} from {{Nonparametric Statistics}} for {{Real Time Robot Learning}}},
  author = {Schaal, Stefan and Atkeson, Christopher G and Vijayakumar, Sethu},
  date = {2002},
  journaltitle = {Applied Intelligence},
  volume = {17},
  pages = {49--60},
  abstract = {Locally weighted learning (LWL) is a class of techniques from nonparametric statistics that provides useful representations and training algorithms for learning about complex phenomena during autonomous adaptive control of robotic systems. This paper introduces several LWL algorithms that have been tested successfully in real-time learning of complex robot tasks. We discuss two major classes of LWL, memory-based LWL and purely incremental LWL that does not need to remember any data explicitly. In contrast to the traditional belief that LWL methods cannot work well in high-dimensional spaces, we provide new algorithms that have been tested on up to 90 dimensional learning problems. The applicability of our LWL algorithms is demonstrated in various robot learning examples, including the learning of devil-sticking, pole-balancing by a humanoid robot arm, and inverse-dynamics learning for a seven and a 30 degree-of-freedom robot. In all these examples, the application of our statistical neural networks techniques allowed either faster or more accurate acquisition of motor control than classical control engineering.},
  langid = {english},
  keywords = {引用},
  annotation = {titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation:},
  file = {/Users/liurongkai/Zotero/storage/XA63MGGQ/Schaal 等 - Scalable Techniques from Nonparametric Statistics .pdf}
}

@inproceedings{schettinoImprovingGeneralisationLearning2020,
  title = {Improving {{Generalisation}} in {{Learning Assistance}} by {{Demonstration}} for {{Smart Wheelchairs}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Schettino, Vinicius and Demiris, Yiannis},
  date = {2020-05},
  pages = {5474--5480},
  publisher = {{IEEE}},
  location = {{Paris, France}},
  doi = {10.1109/ICRA40945.2020.9197490},
  url = {https://ieeexplore.ieee.org/document/9197490/},
  urldate = {2023-12-22},
  abstract = {Learning Assistance by Demonstration (LAD) is concerned with using demonstrations of a human agent to teach a robot how to assist another human. The concept has previously been used with smart wheelchairs to provide customised assistance to individuals with driving difficulties. A basic premise of this technique is that the learned assistive policy should be able to generalise to environments different than the ones used for training; but this has not been tested before. In this work we evaluate the assistive power and the generalisation capability of LAD using our custom teleoperation and learning system for smart wheelchairs, while seeking to improve it by experimenting with different combinations of dimensionality reduction techniques and machine learning models. Using Autoencoders to reduce the dimension of laserscan data and a Gaussian Process as the learning model, we achieved a 23\% improvement in prediction performance against the combination used by the latest work on the field. Using this model to assist a driver exposed to a simulated disability, we observed a 9.8\% reduction in track completion times when compared to driving without assistance.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-72817-395-5},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/5RNDFSE9/Schettino 和 Demiris - 2020 - Improving Generalisation in Learning Assistance by.pdf}
}

@article{seanez-gonzalezCursorControlKalman2014a,
  title = {Cursor Control by {{Kalman}} Filter with a Non-Invasive Body–Machine Interface},
  author = {Seáñez-González, Ismael and Mussa-Ivaldi, Ferdinando A},
  date = {2014-10-01},
  journaltitle = {Journal of Neural Engineering},
  shortjournal = {J. Neural Eng.},
  volume = {11},
  number = {5},
  pages = {056026},
  issn = {1741-2560, 1741-2552},
  doi = {10.1088/1741-2560/11/5/056026},
  url = {https://iopscience.iop.org/article/10.1088/1741-2560/11/5/056026},
  urldate = {2022-09-30},
  abstract = {Objective. We describe a novel human–machine interface for the control of a two-dimensional (2D) computer cursor using four inertial measurement units (IMUs) placed on the user’s upperbody. Approach. A calibration paradigm where human subjects follow a cursor with their body as if they were controlling it with their shoulders generates a map between shoulder motions and cursor kinematics. This map is used in a Kalman filter to estimate the desired cursor coordinates from upper-body motions. We compared cursor control performance in a centre-out reaching task performed by subjects using different amounts of information from the IMUs to control the 2D cursor. Main results. Our results indicate that taking advantage of the redundancy of the signals from the IMUs improved overall performance. Our work also demonstrates the potential of non-invasive IMU-based body–machine interface systems as an alternative or complement to brain–machine interfaces for accomplishing cursor control in 2D space. Significance. The present study may serve as a platform for people with high-tetraplegia to control assistive devices such as powered wheelchairs using a joystick.},
  langid = {english},
  keywords = {已读,引用,感兴趣的,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/TSYQH23Z/Seáñez-González 和 Mussa-Ivaldi - 2014 - Cursor control by Kalman filter with a non-invasiv.pdf}
}

@article{seanez-gonzalezStaticDynamicDecoding2017,
  title = {Static {{Versus Dynamic Decoding Algorithms}} in a {{Non-Invasive Body}}–{{Machine Interface}}},
  author = {Seáñez-González, I. and Pierella, C. and Farshchiansadegh, A. and Thorp, E. B. and Abdollahi, F. and Pedersen, J. P. and Mussa-Ivaldi, F. A.},
  date = {2017-07},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {25},
  number = {7},
  pages = {893--905},
  issn = {1558-0210},
  doi = {10.1109/TNSRE.2016.2640360},
  url = {10.1109/TNSRE.2016.2640360},
  abstract = {In this study, we consider a non-invasive body-machine interface that captures body motions still available to people with spinal cord injury (SCI) and maps them into a set of signals for controlling a computer user interface while engaging in a sustained level of mobility and exercise. We compare the effectiveness of two decoding algorithms that transform a high-dimensional body-signal vector into a lower dimensional control vector on six subjects with high-level SCI and eight controls. One algorithm is based on a static map from current body signals to the current value of the control vector set through principal component analysis (PCA), the other on dynamic mapping a segment of body signals to the value and the temporal derivatives of the control vector set through a Kalman filter. SCI and control participants performed straighter and smoother cursor movements with the Kalman algorithm during center-out reaching, but their movements were faster and more precise when using PCA. All participants were able to use the BMI's continuous, two-dimensional control to type on a virtual keyboard and play pong, and performance with both algorithms was comparable. However, seven of eight control participants preferred PCA as their method of virtual wheelchair control. The unsupervised PCA algorithm was easier to train and seemed sufficient to achieve a higher degree of learnability and perceived ease of use.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Systems}} and {{Rehabilitation Engineering}}},
  keywords = {Actigraphy,Adult,Algorithms,Assistive devices,body motions,body-signal vector,Body–machine interface (BMI),brain-computer interfaces,cervical spinal cord injury,computer user interface,Computers,control vector,decoding,dynamic decoding algorithms,dynamic mapping,Female,handicapped aids,Heuristic algorithms,Humans,injuries,Kalman algorithm,Kalman filter,Kalman filters,Kinematics,Male,Man-Machine Systems,medical signal processing,Middle Aged,Movement,neurophysiology,noninvasive body-machine interface,Pattern Recognition Automated,principal component analysis,Principal component analysis,Principal Component Analysis,Reproducibility of Results,SCI,Sensitivity and Specificity,Signal Processing Computer-Assisted,Spinal Cord Injuries,spinal cord injury,static decoding algorithms,static map,tetraplegia,two-dimensional control,Unsupervised Machine Learning,unsupervised PCA algorithm,virtual wheelchair control,wheelchair control,wheelchairs,Wheelchairs,已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/MIRD6XBD/Seáñez-González et al_2017_Static Versus Dynamic Decoding Algorithms in a Non-Invasive Body–Machine.pdf;/Users/liurongkai/Zotero/storage/S2GWT6S5/7784844.html}
}

@online{SelfdrivingScooterUnveiled,
  title = {Self-Driving Scooter Unveiled},
  url = {https://news.nus.edu.sg/self-driving-scooter-unveiled/},
  urldate = {2023-12-23},
  abstract = {The vision of a car-lite society and efficient door to door mobility led NUS and the Singapore-MIT Alliance for Research and Technology to embark on a collaborative research project on autonomous, self-driving vehicles. The latest in the series is a self-driving scooter that is meant for use in pedestrian environments, to navigate smaller and n...},
  langid = {english},
  organization = {{Self-driving scooter unveiled}},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/8NCD7YTR/self-driving-scooter-unveiled.html}
}

@article{selvaggioAutonomyPhysicalHumanRobot2021a,
  title = {Autonomy in {{Physical Human-Robot Interaction}}: {{A Brief Survey}}},
  shorttitle = {Autonomy in {{Physical Human-Robot Interaction}}},
  author = {Selvaggio, Mario and Cognetti, Marco and Nikolaidis, Stefanos and Ivaldi, Serena and Siciliano, Bruno},
  date = {2021},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {6},
  number = {4},
  pages = {7989--7996},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3100603},
  abstract = {Sharing the control of a robotic system with an autonomous controller allows a human to reduce his/her cognitive and physical workload during the execution of a task. In recent years, the development of inference and learning techniques has widened the spectrum of applications of shared control (SC) approaches, leading to robotic systems that are capable of seamless adaptation of their autonomy level. In this perspective, shared autonomy (SA) can be defined as the design paradigm that enables this adapting behavior of the robotic system. This letter collects the latest results achieved by the research community in the field of SC and SA with special emphasis on physical human-robot interaction (pHRI). Architectures and methods developed for SC and SA are discussed throughout the letter, highlighting the key aspects of each methodology. A discussion about open issues concludes this letter.},
  eventtitle = {{{IEEE Robotics}} and {{Automation Letters}}},
  keywords = {Collaboration,human-centered robotics,human-robot collaboration,Human-robot interaction,Mobile robots,Physical human-robot interaction,Robot kinematics,Robot sensing systems,Robots,Task analysis,在读,已读,引用,综述,重要文章},
  file = {/Users/liurongkai/Zotero/storage/U9AFJ3DP/Selvaggio et al_2021_Autonomy in Physical Human-Robot Interaction.pdf;/Users/liurongkai/Zotero/storage/RB5ZJ86Z/9501975.html}
}

@article{sharmaBiomechanicalTrajectoryOptimization2022,
  title = {Biomechanical {{Trajectory Optimization}} of {{Human Sit-to-Stand Motion With Stochastic Motion Planning Framework}}},
  author = {Sharma, Bibhu and Pillai, Branesh M. and Suthakorn, Jackrit},
  date = {2022-11},
  journaltitle = {IEEE Transactions on Medical Robotics and Bionics},
  shortjournal = {IEEE Trans. Med. Robot. Bionics},
  volume = {4},
  number = {4},
  pages = {1022--1033},
  issn = {2576-3202},
  doi = {10.1109/TMRB.2022.3205509},
  url = {https://ieeexplore.ieee.org/document/9882381/},
  urldate = {2023-10-30},
  abstract = {Trajectory optimization has been an important approach in biomechanics for the analysis and prediction of the limb movement. Such approaches have paved the way for the motion planning of biped and quadruped robots as well. Most of these methods are deterministic, utilizing first-order iterative gradient-based algorithms incorporating the constrained differentiable objective functions. However, the limitation of prevailing methods concerning differentiability hinders the implementation of non-differentiable objective functions such as metabolic energy expenditure (MEE) function, which is highly relevant for physiological systems and can even be implemented across the muscular space. This paper consolidates the implementation of the prevalent direct collocation-based optimal control method with the stochastic trajectory optimization method based on Policy Improvement with Path Integral (PI2) for comprehending the human sit-to-stand (STS) motion. PI2 method, which utilizes reinforcement learning of Dynamic Movement Primitive (DMP) to learn a goal-based trajectory is implemented and validated by comparing with the experimental result in joint-space and muscle-space.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/YHL5WKUB/Sharma 等 - 2022 - Biomechanical Trajectory Optimization of Human Sit.pdf}
}

@inproceedings{sharmaPhysicalHumanRobotInteraction2022,
  title = {Physical {{Human-Robot Interaction}} ({{pHRI}}) through {{Admittance Control}} of {{Dynamic Movement Primitives}} in {{Sit-to-Stand Assistance Robot}}},
  booktitle = {2022 15th {{International Conference}} on {{Human System Interaction}} ({{HSI}})},
  author = {Sharma, Bibhu and Pillai, Branesh M. and Suthakorn, Jackrit},
  date = {2022-07-28},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Melbourne, Australia}},
  doi = {10.1109/HSI55341.2022.9869510},
  url = {https://ieeexplore.ieee.org/document/9869510/},
  urldate = {2023-12-28},
  abstract = {Physically assistance robots have been conceptualized to compensate or augment the human musculoskeletal function. However, due to the concerns of safety and effectiveness for physical human-robot interaction (pHRI) in such robots, compliant joints are preferred over the rigid joints. This paper illustrates the implementation of admittance control in a sit-tostand (STS) assistance robot. The 3-degrees of freedom (dof) robot comprises of ball screw-based linear actuators that are arranged in a parallel configuration. While the actuation system is preferable for strength and performance, the non-backdrivable characteristic corroborates the rigidity of the joint, making it unfavorable for human-robot interaction operation. To enhance compliance, force sensor-based admittance control system is implemented. Regarding motion planning, the trajectory were modeled as Dynamic Movement Primitives (DMP), which facilitates the implementation of admittance control. The proposed model is implemented in the robot prototype and validated by illustrating the force input and the motion output.},
  eventtitle = {2022 15th {{International Conference}} on {{Human System Interaction}} ({{HSI}})},
  isbn = {978-1-66546-822-0},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/T34H7JQM/Sharma 等 - 2022 - Physical Human-Robot Interaction (pHRI) through Ad.pdf}
}

@article{shefflerNeuromuscularElectricalStimulation2007,
  title = {Neuromuscular Electrical Stimulation in Neurorehabilitation},
  author = {Sheffler, Lynne R. and Chae, John},
  date = {2007-05},
  journaltitle = {Muscle \& Nerve},
  shortjournal = {Muscle Nerve},
  volume = {35},
  number = {5},
  pages = {562--590},
  issn = {0148639X, 10974598},
  doi = {10.1002/mus.20758},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/mus.20758},
  urldate = {2023-02-10},
  abstract = {This review provides a comprehensive overview of the clinical uses of neuromuscular electrical stimulation (NMES) for functional and therapeutic applications in subjects with spinal cord injury or stroke. Functional applications refer to the use of NMES to activate paralyzed muscles in precise sequence and magnitude to directly accomplish functional tasks. In therapeutic applications, NMES may lead to a specific effect that enhances function, but does not directly provide function. The specific neuroprosthetic or “functional” applications reviewed in this article include upper- and lowerlimb motor movement for self-care tasks and mobility, respectively, bladder function, and respiratory control. Specific therapeutic applications include motor relearning, reduction of hemiplegic shoulder pain, muscle strengthening, prevention of muscle atrophy, prophylaxis of deep venous thrombosis, improvement of tissue oxygenation and peripheral hemodynamic functioning, and cardiopulmonary conditioning. Perspectives on future developments and clinical applications of NMES are presented.},
  langid = {english},
  keywords = {引用,有价值},
  file = {/Users/liurongkai/Zotero/storage/IW8CRUPZ/Sheffler 和 Chae - 2007 - Neuromuscular electrical stimulation in neurorehab.pdf}
}

@article{shengIntegratedMultiModalSEMG2021,
  title = {Toward an {{Integrated Multi-Modal sEMG}}/{{MMG}}/{{NIRS Sensing System}} for {{Human}}–{{Machine Interface Robust}} to {{Muscular Fatigue}}},
  author = {Sheng, Xinjun and Ding, Xuecong and Guo, Weichao and Hua, Lei and Wang, Mian and Zhu, Xiangyang},
  date = {2021-02},
  journaltitle = {IEEE Sensors Journal},
  volume = {21},
  number = {3},
  pages = {3702--3712},
  issn = {1558-1748},
  doi = {10.1109/JSEN.2020.3023742},
  abstract = {The research on muscular activity based human-machine interface (HMI) is of great significance, such as controlling prosthetic hand to improve the life quality of amputee patients. However, the HMI performance is limited by muscular fatigue due to frequent muscle contraction. To overcome the drawback, this paper presents a multi-modal sensing system that can collect surface electromyography (sEMG), near-infrared spectroscopy(NIRS) and mechanomyography (MMG) simultaneously. To evaluate the performance of the multi-modal signal acquisition system, incremental isometric voluntary contractions experiment is carried out. The experimental results show that the proposed system can reliably obtain three kinds of muscle contraction information from the perspective of electrophysiology, oxygen metabolism and low-frequency vibration of myofiber. Furthermore, muscle fatigue induced experiment imitating HMI usage is performed, and it convincingly demonstrates a significantly (p{$<$}; 0.01) improved classification accuracy (CA) by using multi-modal features. The CA is compensated by 3.6\% 22.9\% in the presence of muscular fatigue. These results suggest that multi-modal sensing can improve the HMI performance and robustness. The outcomes of this study have great potential to promote the biomedical and clinical applications of human-machine interaction.},
  eventtitle = {{{IEEE Sensors Journal}}},
  keywords = {Detectors,Electrodes,Fatigue,human-machine interface,Light emitting diodes,mechanomyography (MMG),Multi-modal sensing,Muscles,muscular fatigue,near-infrared spectroscopy (NIRS),surface electromyography (sEMG),Vibrations,引用},
  file = {/Users/liurongkai/Zotero/storage/VPXX9T43/Sheng 等 - 2021 - Toward an Integrated Multi-Modal sEMGMMGNIRS Sen.pdf;/Users/liurongkai/Zotero/storage/6QS6MG97/9195496.html}
}

@book{sicilianoSpringerHandbookRobotics2016,
  title = {Springer {{Handbook}} of {{Robotics}}},
  editor = {Siciliano, Bruno and Khatib, Oussama},
  date = {2016},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-32552-1},
  url = {http://link.springer.com/10.1007/978-3-319-32552-1},
  urldate = {2021-07-20},
  isbn = {978-3-319-32550-7 978-3-319-32552-1},
  langid = {english},
  file = {/Users/liurongkai/Zotero/storage/5RRE2PW7/Siciliano 和 Khatib - 2016 - Springer Handbook of Robotics.pdf}
}

@article{siviyOpportunitiesChallengesDevelopment2022,
  title = {Opportunities and Challenges in the Development of Exoskeletons for Locomotor Assistance},
  author = {Siviy, Christopher and Baker, Lauren M. and Quinlivan, Brendan T. and Porciuncula, Franchino and Swaminathan, Krithika and Awad, Louis N. and Walsh, Conor J.},
  date = {2022-12-22},
  journaltitle = {Nature Biomedical Engineering},
  shortjournal = {Nat. Biomed. Eng},
  volume = {7},
  number = {4},
  pages = {456--472},
  issn = {2157-846X},
  doi = {10.1038/s41551-022-00984-1},
  url = {https://www.nature.com/articles/s41551-022-00984-1},
  urldate = {2023-12-16},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/R9LD8WWA/Siviy 等 - 2022 - Opportunities and challenges in the development of.pdf}
}

@online{SpinalCordInjury,
  title = {Spinal {{Cord Injury}} | {{ASIA Impairment Scale}} | {{Facing Disability}}},
  url = {https://facingdisability.com/spinal-cord-injury/asia-impairment-scale?https://facingdisability.com&gad_source=1&gclid=Cj0KCQiA2KitBhCIARIsAPPMEhI3xhFT395bsPK-XS12E9PYZiGoSgPfogDtspEKY9YP09od7FpciokaAhpXEALw_wcB},
  urldate = {2024-01-19},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Z9LTDSYT/asia-impairment-scale.html}
}

@article{stegallVariableDampingForce2017,
  title = {Variable {{Damping Force Tunnel}} for {{Gait Training Using ALEX III}}},
  author = {Stegall, Paul and Zanotto, Damiano and Agrawal, Sunil K.},
  date = {2017-07},
  journaltitle = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {2},
  number = {3},
  pages = {1495--1501},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2017.2671374},
  url = {http://ieeexplore.ieee.org/document/7858669/},
  urldate = {2023-12-16},
  abstract = {Haptic feedback not only affects the quality of training but can also influence the physical design of robotic gait trainers by determining how much force needs to be applied to the user and the nature of the force. This letter presents the design of a variable damping force tunnel and explores the effect of the shape and strength of the damping field using ALEX III, a treadmill-based exoskeleton developed at Columbia University. The study consists of 32 healthy subjects who were trained for 40 min in the device. The subjects were trained to follow a footpath with a 50\% increase in step height, so the foot would have 1.5 times the ground clearance. Subjects were assigned to one of four groups: linear high, linear low, parabolic high, and parabolic low. Linear or parabolic denotes the shape of the damping field, and high or low denotes the rate of change (strength) of the field based on error. It is shown that the new controller is capable of inducing gait adaptations in healthy individuals while walking in the device. All groups showed adaptations in step height, while only the high strength groups showed changes in normalized error area, a measure of how closely the desired path was followed.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/6RRK3S28/Stegall 等 - 2017 - Variable Damping Force Tunnel for Gait Training Us.pdf}
}

@article{sulzerHighlyBackdrivableLightweight2009,
  title = {A {{Highly Backdrivable}}, {{Lightweight Knee Actuator}} for {{Investigating Gait}} in {{Stroke}}},
  author = {Sulzer, James S. and Roiz, Ronald A. and Peshkin, Michael A. and Patton, James L.},
  date = {2009-06},
  journaltitle = {IEEE Transactions on Robotics},
  volume = {25},
  number = {3},
  pages = {539--548},
  issn = {1941-0468},
  doi = {10.1109/TRO.2009.2019788},
  abstract = {Many of those who survive a stroke develop a gait disability known as stiff-knee gait (SKG). Characterized by reduced knee flexion angle during swing, people with SKG walk with poor energy efficiency and asymmetry due to the compensatory mechanisms required to clear the foot. Previous modeling studies have shown that knee flexion activity directly before the foot leaves the ground, and this should result in improved knee flexion angle during swing. The goal of this research is to physically test this hypothesis using robotic intervention. We developed a device that is capable of assisting knee flexion torque before swing but feels imperceptible (transparent) for the rest of the gait cycle. This device uses sheathed Bowden cable to control the deflection of a compliant torsional spring in a configuration known as a series elastic remote knee actuator (SERKA). In this investigation, we describe the design and evaluation of SERKA, which includes a pilot experiment on stroke subjects. SERKA could supply a substantial torque (12 N middot m) in less than 20 ms, with a maximum torque of 41 N middot m. The device resisted knee flexion imperceptibly when desired, at less than 1 N middot m rms torque during normal gait. With the remote location of the actuator, the user experiences a mass of only 1.2 kg on the knee. We found that the device was capable of increasing both peak knee flexion angle and velocity during gait in stroke subjects. Thus, the SERKA is a valid experimental device that selectively alters knee kinetics and kinematics in gait after stroke.},
  eventtitle = {{{IEEE Transactions}} on {{Robotics}}},
  keywords = {Actuators,Cable shielding,Compliant actuators,Energy efficiency,Foot,gait,Kinetic theory,Knee,orthotics,Robots,Series Elastic Remote Knee Actuator (SERKA),Springs,stiff-knee gait (SKG),stroke,Testing,Torque,引用},
  file = {/Users/liurongkai/Zotero/storage/QK6NHSJM/Sulzer et al_2009_A Highly Backdrivable, Lightweight Knee Actuator for Investigating Gait in.pdf;/Users/liurongkai/Zotero/storage/TSPZZYUG/4840399.html}
}

@article{suppiahFuzzyInferenceSystem2022,
  title = {Fuzzy Inference System ({{FIS}}) - Long Short-Term Memory ({{LSTM}}) Network for Electromyography ({{EMG}}) Signal Analysis},
  author = {Suppiah, Ravi and Kim, Noori and Sharma, Anurag and Abidi, Khalid},
  date = {2022-11-01},
  journaltitle = {Biomedical Physics \& Engineering Express},
  shortjournal = {Biomed. Phys. Eng. Express},
  volume = {8},
  number = {6},
  pages = {065032},
  issn = {2057-1976},
  doi = {10.1088/2057-1976/ac9e04},
  url = {https://iopscience.iop.org/article/10.1088/2057-1976/ac9e04},
  urldate = {2024-01-07},
  abstract = {Abstract             A wide range of application domains,s such as remote robotic control, rehabilitation, and remote surgery, require capturing neuromuscular activities. The reliability of the application is highly dependent on an ability to decode intentions accurately based on captured neuromuscular signals. Physiological signals such as Electromyography (EMG) and Electroencephalography (EEG) generated by neuromuscular activities contain intrinsic patterns for users’ particular actions. Such actions can generally be classified as motor states, such as Forward, Reverse, Hand-Grip, and Hand-Release. To classify these motor states truthfully, the signals must be captured and decoded correctly. This paper proposes a novel classification technique using a Fuzzy Inference System (FIS) and a Long Short-Term Memory (LSTM) network to classify the motor states based on EMG signals. Existing EMG signal classification techniques generally rely on features derived from data captured at a specific time instance. This typical approach does not consider the temporal correlation of the signal in the entire window. This paper proposes an LSTM with a Fuzzy Logic method to classify four major hand movements: forward, reverse, raise, and lower. Features associated with the pattern generated throughout the motor state movement were extracted by exploring published data within a given time window. The classification results can achieve a 91.3\% accuracy for the 4-way action (Forward/Reverse/GripUp/RelDown) and 95.1\% (Forward/Reverse Action) and 96.7\% (GripUp/RelDown action) for 2-way actions. The proposed mechanism demonstrates high-level, human-interpretable results that can be employed in rehabilitation or medical-device industries.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/5PYF9TML/Suppiah 等 - 2022 - Fuzzy inference system (FIS) - long short-term mem.pdf}
}

@article{suRecentAdvancementsMultimodal2023,
  title = {Recent Advancements in Multimodal Human–Robot Interaction},
  author = {Su, Hang and Qi, Wen and Chen, Jiahao and Yang, Chenguang and Sandoval, Juan and Laribi, Med Amine},
  date = {2023-05-11},
  journaltitle = {Frontiers in Neurorobotics},
  shortjournal = {Front. Neurorobot.},
  volume = {17},
  pages = {1084000},
  issn = {1662-5218},
  doi = {10.3389/fnbot.2023.1084000},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2023.1084000/full},
  urldate = {2024-01-13},
  abstract = {Robotics have advanced significantly over the years, and human–robot interaction (HRI) is now playing an important role in delivering the best user experience, cutting down on laborious tasks, and raising public acceptance of robots. New HRI approaches are necessary to promote the evolution of robots, with a more natural and flexible interaction manner clearly the most crucial. As a newly emerging approach to HRI, multimodal HRI is a method for individuals to communicate with a robot using various modalities, including voice, image, text, eye movement, and touch, as well as bio-signals like EEG and ECG. It is a broad field closely related to cognitive science, ergonomics, multimedia technology, and virtual reality, with numerous applications springing up each year. However, little research has been done to summarize the current development and future trend of HRI. To this end, this paper systematically reviews the state of the art of multimodal HRI on its applications by summing up the latest research articles relevant to this field. Moreover, the research development in terms of the input signal and the output signal is also covered in this manuscript.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/FKQH925H/Su 等 - 2023 - Recent advancements in multimodal human–robot inte.pdf}
}

@inproceedings{szafirConnectingHumanRobotInteraction2021,
  title = {Connecting {{Human-Robot Interaction}} and {{Data Visualization}}},
  booktitle = {Proceedings of the 2021 {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  author = {Szafir, Daniel and Szafir, Danielle Albers},
  date = {2021-03-08},
  pages = {281--292},
  publisher = {{ACM}},
  location = {{Boulder CO USA}},
  doi = {10.1145/3434073.3444683},
  url = {https://dl.acm.org/doi/10.1145/3434073.3444683},
  urldate = {2024-01-07},
  eventtitle = {{{HRI}} '21: {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}}},
  isbn = {978-1-4503-8289-2},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/9N873ZH3/Szafir_Szafir_2021_Connecting Human-Robot Interaction and Data Visualization.pdf}
}

@article{tadeleSafetyDomesticRobotics2014,
  title = {The {{Safety}} of {{Domestic Robotics}}: {{A Survey}} of {{Various Safety-Related Publications}}},
  shorttitle = {The {{Safety}} of {{Domestic Robotics}}},
  author = {Tadele, Tadele Shiferaw and De Vries, Theo and Stramigioli, Stefano},
  date = {2014-09},
  journaltitle = {IEEE Robotics \& Automation Magazine},
  shortjournal = {IEEE Robot. Automat. Mag.},
  volume = {21},
  number = {3},
  pages = {134--142},
  issn = {1070-9932},
  doi = {10.1109/MRA.2014.2310151},
  url = {http://ieeexplore.ieee.org/document/6880806/},
  urldate = {2024-01-14},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/R8I4XUFG/Tadele 等 - 2014 - The Safety of Domestic Robotics A Survey of Vario.pdf}
}

@article{tanApplyingAdaptiveControlb,
  title = {Applying {{Adaptive Control}} in {{Modeling Human Motion Behaviors}} in {{Reinforcement Robotic Learning}} from {{Demonstrations}}},
  author = {Tan, Huan and Zhao, Yang and Kannan, Balajee},
  abstract = {In this paper, we propose to use an adaptive control method as the basis of a reinforcement learning algorithm for robotic imitation learning. In the learning stage, robots use adaptive control method-based reinforcement learning algorithm to learn the parameters of dynamical systems. In the generation stage, robots use the learned dynamic system parameters and the pre-defined controller to drive the configuration states of the robot to move along desired state trajectories. One simulation experiment and one practical experiment on a robot are carried out to validate the effectiveness of our algorithm. The experimental results validate that the learning of the system parameters converges very fast and the learning results can improve the system performance of generating similar motion trajectories.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/BY7XI3UM/Tan 等 - Applying Adaptive Control in Modeling Human Motion.pdf}
}

@article{tangFittsLawModulated2018,
  title = {Fitts’ {{Law}} Is Modulated by Movement History},
  author = {Tang, Rixin and Shen, Bingyao and Sang, Zhiqin and Song, Aixia and Goodale, Melvyn A.},
  date = {2018-10},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {5},
  pages = {1833--1839},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1367-8},
  url = {http://link.springer.com/10.3758/s13423-017-1367-8},
  urldate = {2024-02-07},
  abstract = {Fitts’ Law is one of the most robust and wellstudied principles in psychology. It holds that movement time (MT) for target-directed aiming movements increases as a function of target distance and decreases as a function of target width. The purpose of this study was to determine whether Fitts’ Law is affected not only by the demands of the target on the current trial but also by the requirements for performance on the previous trial. Experiments 1 and 2 examined trial-totrial effects of varying target width; Experiment 3 examined trial-to-trial effects of varying target distance. The findings from Experiments 1 and 2 showed that moving a finger or cursor towards a large object on a previous trial shortened the movement time on the current trial, whereas the opposite occurred with a small object. In contrast, target distance on the previous trial had no effect on movement time on the current trial. These findings suggest that performance on trial n has a clear and predictable effect on trial n+1 (at least for target width) and that Fitts’ Law as it is normally expressed does not accurately predict performance when the width of the target varies from trial to trial.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/9WTCP3NH/Tang 等 - 2018 - Fitts’ Law is modulated by movement history.pdf}
}

@article{terryFunctionalAnatomyShoulder2000,
  title = {Functional {{Anatomy}} of the {{Shoulder}}},
  author = {Terry, Glenn C. and Chopp, Thomas M.},
  date = {2000},
  journaltitle = {Journal of Athletic Training},
  shortjournal = {J Athl Train},
  volume = {35},
  number = {3},
  eprint = {16558636},
  eprinttype = {pmid},
  pages = {248--255},
  issn = {1062-6050},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1323385/},
  urldate = {2024-01-20},
  abstract = {Objective: Movements of the human shoulder represent the result of a complex dynamic interplay of structural bony anatomy and biomechanics, static ligamentous and tendinous restraints, and dynamic muscle forces. Injury to 1 or more of these components through overuse or acute trauma disrupts this complex interrelationship and places the shoulder at increased risk. A thorough understanding of the functional anatomy of the shoulder provides the clinician with a foundation for caring for athletes with shoulder injuries. Data Sources: We searched MEDLINE for the years 1980 to 1999, using the key words “shoulder,” “anatomy,” “glenohumeral joint,” “acromioclavicular joint,” “sternoclavicular joint,” “scapulothoracic joint,” and “rotator cuff.” Data Synthesis: We examine human shoulder movement by breaking it down into its structural static and dynamic components. Bony anatomy, including the humerus, scapula, and clavicle, is described, along with the associated articulations, providing the clinician with the structural foundation for understanding how the static ligamentous and dynamic muscle forces exert their effects. Commonly encountered athletic injuries are discussed from an anatomical standpoint. Conclusions/Recommendations: Shoulder injuries represent a significant proportion of athletic injuries seen by the medical provider. A functional understanding of the dynamic interplay of biomechanical forces around the shoulder girdle is necessary and allows for a more structured approach to the treatment of an athlete with a shoulder injury.},
  pmcid = {PMC1323385},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TIW8YACG/Terry_Chopp_2000_Functional Anatomy of the Shoulder.pdf}
}

@article{thorpUpperBodyBasedPower2016d,
  title = {Upper {{Body-Based Power Wheelchair Control Interface}} for {{Individuals With Tetraplegia}}},
  author = {Thorp, Elias B. and Abdollahi, Farnaz and Chen, David and Farshchiansadegh, Ali and Lee, Mei-Hua and Pedersen, Jessica P. and Pierella, Camilla and Roth, Elliot J. and Seáñez Gonzáles, Ismael and Mussa-Ivaldi, Ferdinando A.},
  date = {2016-02},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {24},
  number = {2},
  pages = {249--260},
  issn = {1558-0210},
  doi = {10.1109/TNSRE.2015.2439240},
  url = {10.1109/TNSRE.2015.2439240},
  abstract = {Many power wheelchair control interfaces are not sufficient for individuals with severely limited upper limb mobility. The majority of controllers that do not rely on coordinated arm and hand movements provide users a limited vocabulary of commands and often do not take advantage of the user's residual motion. We developed a body-machine interface (BMI) that leverages the flexibility and customizability of redundant control by using high dimensional changes in shoulder kinematics to generate proportional control commands for a power wheelchair. In this study, three individuals with cervical spinal cord injuries were able to control a power wheelchair safely and accurately using only small shoulder movements. With the BMI, participants were able to achieve their desired trajectories and, after five sessions driving, were able to achieve smoothness that was similar to the smoothness with their current joystick. All participants were twice as slow using the BMI however improved with practice. Importantly, users were able to generalize training controlling a computer to driving a power wheelchair, and employed similar strategies when controlling both devices. Overall, this work suggests that the BMI can be an effective wheelchair control interface for individuals with high-level spinal cord injuries who have limited arm and hand control.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Systems}} and {{Rehabilitation Engineering}}},
  keywords = {Assistive devices,body–machine interface,Computers,Electronic mail,Injuries,Shoulder,spinal cord injury,Spinal cord injury,Training,wheelchair control,Wheelchairs,已读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/RB4HEDZD/Thorp et al_2016_Upper Body-Based Power Wheelchair Control Interface for Individuals With.pdf;/Users/liurongkai/Zotero/storage/69FTWQBK/7115135.html}
}

@article{tigraNovelEMGInterface2018,
  title = {A Novel {{EMG}} Interface for Individuals with Tetraplegia to Pilot Robot Hand Grasping},
  author = {Tigra, Wafa and Navarro, Benjamin and Cherubini, Andrea and Gorron, Xavier and Gélis, Anthony and Fattal, Charles and Guiraud, David and Azevedo Coste, Christine},
  date = {2018},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  volume = {26},
  number = {2},
  pages = {291--298},
  publisher = {{IEEE Institute of Electrical and Electronics Engineers}},
  doi = {10.1109/TNSRE.2016.2609478},
  url = {https://hal.archives-ouvertes.fr/lirmm-01373668},
  urldate = {2022-12-17},
  abstract = {This article introduces a new human-machine interface for individuals with tetraplegia. We investigated the feasibility of piloting an assistive device by processing supra-lesional muscle responses online. The ability to voluntarily contract a set of selected muscles was assessed in five spinal cord-injured subjects through electromyographic (EMG) analysis. Two subjects were also asked to use the EMG interface to control palmar and lateral grasping of a robot hand. The use of different muscles and control modalities was also assessed. These preliminary results open the way to new interface solutions for high-level spinal cord-injured patients.},
  keywords = {Control,EMG,Grip function,Robot hand,Tetraplegia,引用},
  file = {/Users/liurongkai/Zotero/storage/ESZ2N77Z/Tigra et al_2018_A novel EMG interface for individuals with tetraplegia to pilot robot hand.pdf}
}

@article{tongLSTMBasedLowerLimbs2020,
  title = {{{LSTM-Based Lower Limbs Motion Reconstruction Using Low-Dimensional Input}} of {{Inertial Motion Capture System}}},
  author = {Tong, Lina and Liu, Rongkai and Peng, Liang},
  date = {2020-04-01},
  journaltitle = {IEEE Sensors Journal},
  shortjournal = {IEEE Sensors J.},
  volume = {20},
  number = {7},
  pages = {3667--3677},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2019.2959639},
  url = {https://ieeexplore.ieee.org/document/8932413/},
  urldate = {2020-10-27},
  abstract = {Motion capture system has been widely used in virtual reality and rehabilitation area. This study proposed a data-driven method using low-dimensional input of inertial motion capture system to reconstruct human lower-limb motions. The long short-term memory (LSTM) neural network was used and an ensemble LSTM architecture was involved to improve reconstruction performance. Besides, the selection of optimal sensor configuration scheme and time-step parameters of LSTM network was discussed in detail. The reconstruction experiment shows that the method could get the lowest reconstruction joint angle root mean square (RMS) errors of 4.031◦ on separated motion dataset, and 5.105◦ on completely new dataset of synthetic motions using ensemble LSTM model with 18 base learner and three sensors units. The computational consumption test shows that the single and ensemble LSTM model spend 0.15ms and 0.91ms respectively to predict next frame. These findings demonstrate that the proposed method is effective and efficient for motions reconstruction of lower limbs.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Z5IP4I28/Tong 等。 - 2020 - LSTM-Based Lower Limbs Motion Reconstruction Using.pdf}
}

@inproceedings{torretresolsPOMDPbasedControlHybrid2022,
  title = {Towards a {{POMDP-based Control}} in {{Hybrid Brain-Computer Interfaces}}},
  booktitle = {{{IEEE}} International Conference on Systems, Man, and Cybernetics ({{SMC}})},
  author = {Torre Tresols, Juan Jesus and Chanel, Caroline P C and Dehais, Frédéric},
  date = {2022-10},
  location = {{Prague, Czech Republic}},
  url = {https://hal.archives-ouvertes.fr/hal-03788771},
  urldate = {2022-11-20},
  abstract = {Brain-Computer Interfaces (BCI) provide a unique communication channel between the brain and computer systems. After extensive research and implementation on ample fields of application, numerous challenges to assure reliable and quick data processing have resulted in the hybrid BCI (hBCI) paradigm, consisting on the combination of two BCI systems. However, not all challenges have been properly addressed (e.g. re-calibration, idle-state modelling, adaptive thresholds, etc) to allow hBCI implementation outside of the lab. In this paper, we review electroencephalography based hBCI studies and state potential limitations. We propose a sequential decision-making framework based on Partially Observable Markov Decision Process (POMDP) to design and to control hBCI systems. The POMDP framework is an excellent candidate to deal with the limitations raised above. To illustrate our opinion, an example of architecture using a POMDP-based hBCI control system is provided, and future directions are discussed. We believe this framework will encourage research efforts to provide relevant means to combine information from BCI systems and push BCI out of the laboratory.},
  keywords = {EEG,Hybrid BCI,POMDP,引用},
  file = {/Users/liurongkai/Zotero/storage/B3FR8LSE/Torre Tresols et al_2022_Towards a POMDP-based Control in Hybrid Brain-Computer Interfaces.pdf}
}

@book{tozerenHumanBodyDynamics2000,
  title = {Human Body Dynamics: Classical Mechanics and Human Movement},
  shorttitle = {Human Body Dynamics},
  author = {Tözeren, Aydin},
  date = {2000},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-98801-6},
  langid = {english},
  pagetotal = {315},
  keywords = {Human mechanics,引用},
  file = {/Users/liurongkai/Zotero/storage/RR59IY2T/Tözeren - 2000 - Human body dynamics classical mechanics and human.pdf}
}

@article{udupaSharedAutonomyAssistive2023,
  title = {Shared Autonomy in Assistive Mobile Robots: A Review},
  shorttitle = {Shared Autonomy in Assistive Mobile Robots},
  author = {Udupa, Sumukha and Kamat, Vineet R. and Menassa, Carol C.},
  date = {2023-08-18},
  journaltitle = {Disability and Rehabilitation: Assistive Technology},
  shortjournal = {Disability and Rehabilitation: Assistive Technology},
  volume = {18},
  number = {6},
  pages = {827--848},
  issn = {1748-3107, 1748-3115},
  doi = {10.1080/17483107.2021.1928778},
  url = {https://www.tandfonline.com/doi/full/10.1080/17483107.2021.1928778},
  urldate = {2023-11-28},
  abstract = {Purpose: Shared autonomy has played a major role in assistive mobile robotics as it has the potential to effectively balance user satisfaction and smooth functioning of systems by adapting itself to each user’s needs and preferences. Many shared control paradigms have been developed over the years. However, despite these advancements, shared control paradigms have not been widely adopted as there are several integral aspects that have not fully matured. The purpose of this paper is to discuss and review various aspects of shared control and the technologies leading up to the current advancements in shared control for assistive mobile robots. Methods: A comprehensive review of the literature was conducted following a dichotomy of studies from the pre-2000 and the post-2000 periods to focus on both the early developments and the current state of the art in this domain. Results: A systematic review of 135 research papers and 7 review papers selected from the literature was conducted. To facilitate the organization of the reviewed work, a 6-level ladder categorization was developed based on the extent of autonomy shared between the human and the robot in the use of assistive mobile robots. This taxonomy highlights the chronological improvements in this domain. Conclusion: It was found that most prior studies have focussed on basic functionalities, thus paving the way for research to now focus on the higher levels of the ladder taxonomy. It was concluded that further research in the domain must focus on ensuring safety in mobility and adaptability to varying environments.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TRAE56Z5/Udupa 等 - 2023 - Shared autonomy in assistive mobile robots a revi.pdf}
}

@article{vanbeersRoleExecutionNoise2004,
  title = {The {{Role}} of {{Execution Noise}} in {{Movement Variability}}},
  author = {family=Beers, given=Robert J., prefix=van, useprefix=true and Haggard, Patrick and Wolpert, Daniel M.},
  date = {2004-02},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {Journal of Neurophysiology},
  volume = {91},
  number = {2},
  pages = {1050--1063},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00652.2003},
  url = {https://www.physiology.org/doi/10.1152/jn.00652.2003},
  urldate = {2021-12-07},
  abstract = {The origin of variability in goal-directed movements is not well understood. Variability can originate from several neural processes such as target localization, movement planning, and movement execution. Here we examine variability resulting from noise in movement execution. In several experiments, subjects moved their unseen hand to visual targets, under conditions which were designed to minimize the variability expected from localization and planning processes. We tested short movements in 32 directions in a center-out reaching task. The variability in the movement endpoints and in the initial movement direction varied systematically with the movement direction, with some directions having up to twice the variability of others. In a second experiment we tested four movements in the same direction but with different extents. Here, the longer movements were systematically curved, and the endpoint ellipses were not aligned with the straight line between starting and end position, but they were roughly aligned with the last part of the trajectory. We show that the variability observed in these experiments cannot be explained by planning noise but is well explained by noise in movement execution. A combination of both signal-dependent and signal-independent noise in the amplitude of the motor commands and temporal noise in their duration can explain the observed variability. Our results suggest that, in general, execution noise accounts for at least a large proportion of movement variability.},
  langid = {english},
  keywords = {在读,引用,有价值,重要文章},
  file = {/Users/liurongkai/Zotero/storage/9XQ6M2YK/van Beers 等。 - 2004 - The Role of Execution Noise in Movement Variabilit.pdf}
}

@article{vantiltModelbasedControlExoskeletons2019,
  title = {Model-Based Control for Exoskeletons with Series Elastic Actuators Evaluated on Sit-to-Stand Movements},
  author = {Vantilt, Jonas and Tanghe, Kevin and Afschrift, Maarten and Bruijnes, Amber K.B.D and Junius, Karen and Geeroms, Joost and Aertbeliën, Erwin and De Groote, Friedl and Lefeber, Dirk and Jonkers, Ilse and De Schutter, Joris},
  date = {2019-12},
  journaltitle = {Journal of NeuroEngineering and Rehabilitation},
  shortjournal = {J NeuroEngineering Rehabil},
  volume = {16},
  number = {1},
  pages = {65},
  issn = {1743-0003},
  doi = {10.1186/s12984-019-0526-8},
  url = {https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-019-0526-8},
  urldate = {2023-12-16},
  abstract = {Background: Currently, control of exoskeletons in rehabilitation focuses on imposing desired trajectories to promote relearning of motions. Furthermore, assistance is often provided by imposing these desired trajectories using impedance controllers. However, lower-limb exoskeletons are also a promising solution for mobility problems of individuals in daily life. To develop an assistive exoskeleton which allows the user to be autonomous, i.e. in control of his motions, remains a challenge. This paper presents a model-based control method to tackle this challenge. Methods: The model-based control method utilizes a dynamic model of the exoskeleton to compensate for its own dynamics. After this compensation of the exoskeleton dynamics, the exoskeleton can provide a desired assistance to the user. While dynamic models of exoskeletons used in the literature focus on gravity compensation only, the need for modelling and monitoring of the ground contact impedes their widespread use. The control strategy proposed here relies on modelling of the full exoskeleton dynamics and of the contacts with the environment. A modelling strategy and general control scheme are introduced. Results: Validation of the control method on 15 non-disabled adults performing sit-to-stand motions shows that muscle effort and joint torques are similar in the conditions with dynamically compensated exoskeleton and without exoskeleton. The condition with exoskeleton in which the compensating controller was not active showed a significant increase in human joint torques and muscle effort at the knee and hip. Motor saturation occurred during the assisted condition, which limited the assistance the exoskeleton could deliver. Conclusions: This work presents the modelling steps and controller design to compensate the exoskeleton dynamics. The validation seems to indicate that the presented model-based controller is able to compensate the exoskeleton.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/57UCX8QP/Vantilt 等 - 2019 - Model-based control for exoskeletons with series e.pdf}
}

@online{ViconAwardWinning,
  title = {Vicon | {{Award Winning Motion Capture Systems}}},
  url = {https://www.vicon.com/},
  urldate = {2024-01-10},
  abstract = {Global leader in Motion Capture Cameras, software and Motion Capture Systems for the VFX, life science and engineering industries},
  langid = {american},
  organization = {{Vicon}},
  keywords = {引用}
}

@article{viteckovaGaitSymmetryMeasures2018,
  title = {Gait Symmetry Measures: {{A}} Review of Current and Prospective Methods},
  shorttitle = {Gait Symmetry Measures},
  author = {Viteckova, Slavka and Kutilek, Patrik and Svoboda, Zdenek and Krupicka, Radim and Kauler, Jan and Szabo, Zoltan},
  date = {2018-04},
  journaltitle = {Biomedical Signal Processing and Control},
  shortjournal = {Biomedical Signal Processing and Control},
  volume = {42},
  pages = {89--100},
  issn = {17468094},
  doi = {10.1016/j.bspc.2018.01.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1746809418300193},
  urldate = {2022-07-18},
  langid = {english},
  keywords = {引用,综述},
  file = {/Users/liurongkai/Zotero/storage/6N9C2PII/Viteckova et al_2018_Gait symmetry measures.pdf}
}

@article{vitorinodinizRachimeduralTraumaEpidemiology2016,
  title = {Rachimedural {{Trauma}}: {{Epidemiology And Complications}}},
  shorttitle = {Rachimedural {{Trauma}}},
  author = {Vitorino Diniz, Iraktania and Gonçalves de Brito, Karen Krystine and Souza Silva de Aguiar, Elizabeth and Alves da Silva, Mirian and Tamar Oliveira de Sousa, Alana and Duarte de Oliveira Matos, Suellen and family=Costa Andrade, given=Smalyanna Sgren, prefix=da, useprefix=true and Di Pace Neto, Celio Maroja and Vitorino Di Pace, Arthur and Vitorino Rodrigues Correia de Toledo, Irany and Malzac Freire de Santana, Emanuelle and family=Santos Oliveira, given=Simone Helena, prefix=dos, useprefix=true and Lopes Costa, Marta Miriam and Guimarães Oliveira Soares, Maria Júlia},
  date = {2016},
  journaltitle = {International Archives of Medicine},
  shortjournal = {Int Arch Med},
  issn = {17557682},
  doi = {10.3823/2022},
  url = {http://imed.pub/ojs/index.php/iam/article/view/1700},
  urldate = {2021-12-04},
  abstract = {Background: Traumatic spinal cord is a public health problem due to the high morbidity and mortality worldwide. The objective of this research was to characterize the profile demographic and clinical partner of people with TRM; analyze correlations between clinical features of traumatic injury level and its complications. Methods: Observational study, the cut cross-sectional with a quantitative approach, performed with 80 people with TRM. Data were analyzed using descriptive and inferential techniques statistics. Results: The results show correlation of spinal cord injury in lumbar level with accidents with firearms, of chest injury to car accidents and cervical injuries the diving in shallow water. Regarding complications, quadriplegia had greater influence as a risk factor for UP, spasticity, orthostatic hypotension, urinary complications, autonomic dysreflexia and intestinal disorders in relation to paraplegia, but showed a protective factor to pain syndromes. 1\enspace{}  Masters student in the Graduate Program in Nursing at the Federal University of Paraíba, João Pessoa, Paraíba, Brazil. 2\enspace{} Doctoral student in the Graduate Program in Nursing at the Federal University of Paraíba, João Pessoa, Paraíba, Brazil. 3\enspace{} Doctor in Nursing. Associate professor at Federal University of Campina Grande, Cuité, Paraíba, Brazil. 4\enspace{} Surgeon Dentist Specialized in Orthodontics at the Core for Studies and Dental Improvement. João Pessoa, Paraiba, Brazil. 5\enspace{} Graduate Student in Psychology at an University Center, João Pessoa, Paraiba, Brazil. 6\enspace{} Dermatology Nurse, Coordinator of the Hospital Clementino Fraga; Dermatology Commission, Joao Pessoa, Paraiba, Brazil. 7\enspace{} PhD in Nursing. Associate professor at Federal University of Paraíba. João Pessoa, Paraíba, Brazil. Contact information: Iraktania Vitorino Diniz. Address: Oceano Atlantico, nº 254, ap 303. CEP: 58102-252. Intermares, Cabedelo. Paraíba. Tel: +55 83 996941923.  iraktania@hotmail.com Conclusion: The absence of notification is a limiting factor for research and construction of new public policies aimed at preventing determinants external causes of TRM, as well as development of actions aimed at specialized care to minimize complications and improve quality of life in this population.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Q9KQAK7P/Vitorino Diniz 等。 - 2016 - Rachimedural Trauma Epidemiology And Complication.pdf}
}

@article{walterFrameworkLearningSemantic2014,
  title = {A Framework for Learning Semantic Maps from Grounded Natural Language Descriptions},
  author = {Walter, Matthew R. and Hemachandra, Sachithra and Homberg, Bianca and Tellex, Stefanie and Teller, Seth},
  date = {2014-08},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {33},
  number = {9},
  pages = {1167--1190},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364914537359},
  url = {http://journals.sagepub.com/doi/10.1177/0278364914537359},
  urldate = {2023-12-21},
  abstract = {This paper describes a framework that enables robots to efficiently learn human-centric models of their environment from natural language descriptions. Typical semantic mapping approaches are limited to augmenting metric maps with higherlevel properties of the robot’s surroundings (e.g. place type, object locations) that can be inferred from the robot’s sensor data, but do not use this information to improve the metric map. The novelty of our algorithm lies in fusing high-level knowledge that people can uniquely provide through speech with metric information from the robot’s low-level sensor streams. Our method jointly estimates a hybrid metric, topological, and semantic representation of the environment. This semantic graph provides a common framework in which we integrate information that the user communicates (e.g. labels and spatial relations) with metric observations from low-level sensors. Our algorithm efficiently maintains a factored distribution over semantic graphs based upon the stream of natural language and low-level sensor information. We detail the means by which the framework incorporates knowledge conveyed by the user’s descriptions, including the ability to reason over expressions that reference yet unknown regions in the environment. We evaluate the algorithm’s ability to learn human-centric maps of several different environments and analyze the knowledge inferred from language and the utility of the learned maps. The results demonstrate that the incorporation of information from free-form descriptions increases the metric, topological, and semantic accuracy of the recovered environment model.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/7S9CV2UU/Walter 等 - 2014 - A framework for learning semantic maps from ground.pdf}
}

@article{wanEEGformerTransformerBased2023,
  title = {{{EEGformer}}: {{A}} Transformer–Based Brain Activity Classification Method Using {{EEG}} Signal},
  shorttitle = {{{EEGformer}}},
  author = {Wan, Zhijiang and Li, Manyu and Liu, Shichang and Huang, Jiajin and Tan, Hai and Duan, Wenfeng},
  date = {2023-03-24},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front. Neurosci.},
  volume = {17},
  pages = {1148855},
  issn = {1662-453X},
  doi = {10.3389/fnins.2023.1148855},
  url = {https://www.frontiersin.org/articles/10.3389/fnins.2023.1148855/full},
  urldate = {2024-01-07},
  abstract = {Background: The effective analysis methods for steady-state visual evoked potential (SSVEP) signals are critical in supporting an early diagnosis of glaucoma. Most efforts focused on adopting existing techniques to the SSVEPs-based brain–computer interface (BCI) task rather than proposing new ones specifically suited to the domain. Method: Given that electroencephalogram (EEG) signals possess temporal, regional, and synchronous characteristics of brain activity, we proposed a transformer–based EEG analysis model known as EEGformer to capture the EEG characteristics in a unified manner. We adopted a one-dimensional convolution neural network (1DCNN) to automatically extract EEG-channel-wise features. The output was fed into the EEGformer, which is sequentially constructed using three components: regional, synchronous, and temporal transformers. In addition to using a large benchmark database (BETA) toward SSVEP-BCI application to validate model performance, we compared the EEGformer to current state-ofthe-art deep learning models using two EEG datasets, which are obtained from our previous study: SJTU emotion EEG dataset (SEED) and a depressive EEG database (DepEEG). Results: The experimental results show that the EEGformer achieves the best classification performance across the three EEG datasets, indicating that the rationality of our model architecture and learning EEG characteristics in a unified manner can improve model classification performance. Conclusion: EEGformer generalizes well to different EEG datasets, demonstrating our approach can be potentially suitable for providing accurate brain activity classification and being used in different application scenarios, such as SSVEP-based early glaucoma diagnosis, emotion recognition and depression discrimination.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/X2DBAZPB/Wan 等 - 2023 - EEGformer A transformer–based brain activity clas.pdf}
}

@article{wangDeep3DHuman2021,
  title = {Deep {{3D}} Human Pose Estimation: {{A}} Review},
  shorttitle = {Deep {{3D}} Human Pose Estimation},
  author = {Wang, Jinbao and Tan, Shujie and Zhen, Xiantong and Xu, Shuo and Zheng, Feng and He, Zhenyu and Shao, Ling},
  date = {2021-09},
  journaltitle = {Computer Vision and Image Understanding},
  shortjournal = {Computer Vision and Image Understanding},
  volume = {210},
  pages = {103225},
  issn = {10773142},
  doi = {10.1016/j.cviu.2021.103225},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1077314221000692},
  urldate = {2024-01-10},
  abstract = {Three-dimensional (3D) human pose estimation involves estimating the articulated 3D joint locations of a human body from an image or video. Due to its widespread applications in a great variety of areas, such as human motion analysis, human–computer interaction, robots, 3D human pose estimation has recently attracted increasing attention in the computer vision community, however, it is a challenging task due to depth ambiguities and the lack of in-the-wild datasets. A large number of approaches, with many based on deep learning, have been developed over the past decade, largely advancing the performance on existing benchmarks. To guide future development, a comprehensive literature review is highly desired in this area. However, existing surveys on 3D human pose estimation mainly focus on traditional methods and a comprehensive review on deep learning based methods remains lacking in the literature. In this paper, we provide a thorough review of existing deep learning based works for 3D pose estimation, summarize the advantages and disadvantages of these methods and provide an in-depth understanding of this area. Furthermore, we also explore the commonly-used benchmark datasets on which we conduct a comprehensive study for comparison and analysis. Our study sheds light on the state of research development in 3D human pose estimation and provides insights that can facilitate the future design of models and algorithms.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/V5HXIDSE/Wang 等 - 2021 - Deep 3D human pose estimation A review.pdf}
}

@article{wangDesignControlMINDWALKER2015,
  title = {Design and {{Control}} of the {{MINDWALKER Exoskeleton}}},
  author = {Wang, Shiqian and Wang, Letian and Meijneke, Cory and Van Asseldonk, Edwin and Hoellinger, Thomas and Cheron, Guy and Ivanenko, Yuri and La Scaleia, Valentina and Sylos-Labini, Francesca and Molinari, Marco and Tamburella, Federica and Pisotta, Iolanda and Thorsteinsson, Freygardur and Ilzkovitz, Michel and Gancet, Jeremi and Nevatia, Yashodhan and Hauffe, Ralf and Zanow, Frank and Van Der Kooij, Herman},
  date = {2015-03},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  shortjournal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
  volume = {23},
  number = {2},
  pages = {277--286},
  issn = {1534-4320, 1558-0210},
  doi = {10.1109/TNSRE.2014.2365697},
  url = {https://ieeexplore.ieee.org/document/6940308/},
  urldate = {2023-12-17},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Y6CXW25L/Wang 等 - 2015 - Design and Control of the MINDWALKER Exoskeleton.pdf}
}

@article{wangInteractiveWearableSystems2017b,
  title = {Interactive Wearable Systems for Upper Body Rehabilitation: A Systematic Review},
  shorttitle = {Interactive Wearable Systems for Upper Body Rehabilitation},
  author = {Wang, Qi and Markopoulos, Panos and Yu, Bin and Chen, Wei and Timmermans, Annick},
  date = {2017-12},
  journaltitle = {Journal of NeuroEngineering and Rehabilitation},
  shortjournal = {J NeuroEngineering Rehabil},
  volume = {14},
  number = {1},
  pages = {20},
  issn = {1743-0003},
  doi = {10.1186/s12984-017-0229-y},
  url = {http://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-017-0229-y},
  urldate = {2024-01-12},
  abstract = {Background: The development of interactive rehabilitation technologies which rely on wearable-sensing for upper body rehabilitation is attracting increasing research interest. This paper reviews related research with the aim: 1) To inventory and classify interactive wearable systems for movement and posture monitoring during upper body rehabilitation, regarding the sensing technology, system measurements and feedback conditions; 2) To gauge the wearability of the wearable systems; 3) To inventory the availability of clinical evidence supporting the effectiveness of related technologies. Method: A systematic literature search was conducted in the following search engines: PubMed, ACM, Scopus and IEEE (January 2010–April 2016). Results: Forty-five papers were included and discussed in a new cuboid taxonomy which consists of 3 dimensions: sensing technology, feedback modalities and system measurements. Wearable sensor systems were developed for persons in: 1) Neuro-rehabilitation: stroke (n = 21), spinal cord injury (n = 1), cerebral palsy (n = 2), Alzheimer (n = 1); 2) Musculoskeletal impairment: ligament rehabilitation (n = 1), arthritis (n = 1), frozen shoulder (n = 1), bones trauma (n = 1); 3) Others: chronic pulmonary obstructive disease (n = 1), chronic pain rehabilitation (n = 1) and other general rehabilitation (n = 14). Accelerometers and inertial measurement units (IMU) are the most frequently used technologies (84\% of the papers). They are mostly used in multiple sensor configurations to measure upper limb kinematics and/or trunk posture. Sensors are placed mostly on the trunk, upper arm, the forearm, the wrist, and the finger. Typically sensors are attachable rather than embedded in wearable devices and garments; although studies that embed and integrate sensors are increasing in the last 4 years. 16 studies applied knowledge of result (KR) feedback, 14 studies applied knowledge of performance (KP) feedback and 15 studies applied both in various modalities. 16 studies have conducted their evaluation with patients and reported usability tests, while only three of them conducted clinical trials including one randomized clinical trial. Conclusions: This review has shown that wearable systems are used mostly for the monitoring and provision of feedback on posture and upper extremity movements in stroke rehabilitation. The results indicated that accelerometers and IMUs are the most frequently used sensors, in most cases attached to the body through ad hoc contraptions for the purpose of improving range of motion and movement performance during upper body rehabilitation. Systems featuring sensors embedded in wearable appliances or garments are only beginning to emerge. Similarly, clinical evaluations are scarce and are further needed to provide evidence on effectiveness and pave the path towards implementation in clinical settings.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/HCYKW3MR/Wang 等 - 2017 - Interactive wearable systems for upper body rehabi.pdf}
}

@thesis{WangXiaZhiZhuLiWaiGuGeJiQiRenKongZhiXiTongRenJiGongRongCeLueYanJiu2019,
  type = {博士},
  title = {下肢助力外骨骼机器人控制系统人机共融策略研究},
  author = {王, 立坤},
  editora = {沈, 毅 and 杜, 志江},
  editoratype = {collaborator},
  date = {2019},
  institution = {{哈尔滨工业大学}},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2021&filename=1020401665.nh&v=},
  abstract = {下肢助力外骨骼机器人是一种可穿戴式设备,它的出现使得穿戴者增强在负重行走、托举搬运和边检巡逻的运动技能,其作用主要在穿戴者展现自身运动动作时,无阻碍增强穿戴者的耐力、提高穿戴者的负重能力、保护穿戴者运动肢体,进而,提高穿戴者的工作效率或战斗力。下肢助力外骨骼机器人可以在人体运动的同时有机融合人体的下肢和上身部分,这种可穿戴设备通常由两条拟人化机械腿、相应的支撑连接设备以及配套的软硬件设施等组成。本文致力于研究下肢助力外骨骼机器人控制系统的人机共融策略,从而提高下肢外骨骼机器人与穿戴者共存融合的能力。首先,基于人体生物工程学和人体解剖学,详细地分析了人体下肢关节运动和人体正常步态行走的特点。基于拉格朗日方程,对下肢助力外骨骼机器人的站立相和摆动相分别进行动力学建模。基于混杂自动机理论,给出下肢外骨骼机器人混杂动力学系统模型。设计了柔性关节外骨骼机器人、轻型下肢外骨骼机器人和重型下肢外骨骼机器人的控制系统。其次,设计了稀疏高斯过程的交互模型和周期运动的中枢模式发生器。根据策略改进和路径积分理论,以及协方差矩阵自适应策略,提出了基于人机交互的增量式轨迹基元学习算法Efficient PI2-CMA-ES,并给出了底层控制器的权重参数的更新方法,进而提出了一种下肢助力外骨骼机器人位置环的轨迹基元在线增强学习人机融合策略。再者,根据隐马尔可夫模型和分布式高斯过程,建立了用来辨识系统的空间变量的分布式高斯滤波和平滑的隐状态模型,结合在线增强学习的(1+1)-CMAES算法改进灵敏度放大控制算法,使得灵敏度放大因子可以自适应更新学习,测试了四种数据融合算法并搭建了完整的分布式框架,进而提出了一种下肢助力外骨骼机器人力矩环的灵敏度概率人机融合策略。最后,建立了单关节串联弹性驱动器模型。根据串联弹性驱动器可感知外部力矩的特点,人体与下肢助力外骨骼机器人的交互将被视为扰动,并经由扰动观测器来补偿。通过设计Q滤波器提高系统的鲁棒性,结合模型预测控制,提出了一种针对下肢助力外骨骼机器人串联弹性驱动器的基于扰动观测器的模型预测人机融合策略。另外,根据内模控制的特点,通过分布式高斯过程在线学习的方法建立了局部准确的内模模型。根据在线的数据流入和流出,保证了局部内模模型的准确性和实时性。从而提出了另一种针对下肢助力外骨骼机器人单关节串联弹性驱动器的自演变内模模型人机共融策略。},
  langid = {chinese},
  keywords = {Control system,Exoskeleton robot,Human-robot coexisting strategy,Series elastic actuator,串联弹性驱动器,人机共融策略 Probabilistic sensitivity,外骨骼机器人,引用,控制系统,概率灵敏度},
  annotation = {2 citations(CNKI)[2023-6-16]},
  file = {/Users/liurongkai/Zotero/storage/3H8JZZS5/下肢助力外骨骼机器人控制系统人机共融策略研究_王立坤.pdf}
}

@thesis{williamsonContinuousUncertainInteraction2006,
  type = {phdthesis},
  title = {Continuous {{Uncertain Interaction}}},
  author = {Williamson, John},
  date = {2006},
  institution = {{Dept. Computing Science,  University of Glasgow}},
  langid = {english},
  keywords = {引用,综述,重要文章},
  annotation = {titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation: titleTranslation:},
  file = {/Users/liurongkai/Zotero/storage/QKZ8MYIM/Williamson - Continuous Uncertain Interaction.pdf}
}

@inproceedings{winfreeDesignMinimallyConstraining2011,
  title = {Design of a Minimally Constraining, Passively Supported Gait Training Exoskeleton: {{ALEX II}}},
  shorttitle = {Design of a Minimally Constraining, Passively Supported Gait Training Exoskeleton},
  booktitle = {2011 {{IEEE International Conference}} on {{Rehabilitation Robotics}}},
  author = {Winfree, K. N. and Stegall, P. and Agrawal, S. K.},
  date = {2011-06},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Zurich}},
  doi = {10.1109/ICORR.2011.5975499},
  url = {http://ieeexplore.ieee.org/document/5975499/},
  urldate = {2023-12-16},
  abstract = {This paper discusses the design of a new, minimally constraining, passively supported gait training exoskeleton known as ALEX II. This device builds on the success and extends the features of the ALEX I device developed at the University of Delaware. Both ALEX (Active Leg EXoskeleton) devices have been designed to supply a controllable torque to a subject’s hip and knee joint. The current control strategy makes use of an assist-as-needed algorithm. Following a brief review of previous work motivating this redesign, we discuss the key mechanical features of the new ALEX device. A short investigation was conducted to evaluate the effectiveness of the control strategy and impact of the exoskeleton on the gait of six healthy subjects. This paper concludes with a comparison between the subjects’ gait both in and out of the exoskeleton.},
  eventtitle = {2011 {{IEEE}} 12th {{International Conference}} on {{Rehabilitation Robotics}}: {{Reaching Users}} \& the {{Community}} ({{ICORR}} 2011)},
  isbn = {978-1-4244-9862-8 978-1-4244-9863-5 978-1-4244-9861-1},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Z4PT77RL/Winfree 等 - 2011 - Design of a minimally constraining, passively supp.pdf}
}

@article{woolleyCharacteristicsGaitHemiplegia2015,
  title = {Characteristics of {{Gait}} in {{Hemiplegia}}},
  author = {Woolley, Sandra M.},
  date = {2015-02-23},
  journaltitle = {Topics in Stroke Rehabilitation},
  publisher = {{Taylor \& Francis}},
  doi = {10.1310/JB16-V04F-JAL5-H1UV},
  url = {https://www.tandfonline.com/doi/abs/10.1310/JB16-V04F-JAL5-H1UV},
  urldate = {2022-06-16},
  abstract = {The following review examines the walking patterns of patients who have hemiplegia, primarily as a result of a stroke. Attention is given to the changes in the distance and temporal factors of walk...},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/FBBK338K/JB16-V04F-JAL5-H1UV.html}
}

@article{worldhealthorganizationGuidelinesProvisionManual2008,
  title = {Guidelines on the Provision of Manual Wheelchairs in Less Resourced Settings},
  author = {{World Health Organization} and {International Society for Prosthetics and Orthotics} and {United States. Agency for International Development}},
  date = {2008},
  journaltitle = {Guide pour les services de fauteuils roulants manuels dans les régions à faibles revenus},
  shortjournal = {Guide pour les services de fauteuils roulants manuels dans les régions à faibles revenus},
  pages = {128},
  publisher = {{World Health Organization}},
  location = {{Geneva}},
  issn = {9789241547482},
  url = {https://iris.who.int/handle/10665/43960},
  urldate = {2023-12-20},
  langid = {english},
  keywords = {Developing Countries,Disabled Persons,economics supply and distribution standards,Guideline,rehabilitation,Wheelchairs,WHO guideline,引用},
  file = {/Users/liurongkai/Zotero/storage/KG7TFHSJ/World Health Organization 等 - 2008 - Guidelines on the provision of manual wheelchairs .pdf}
}

@inproceedings{xinxuHumanBehaviorUnderstanding2010,
  title = {Human Behavior Understanding for Video Surveillance: {{Recent}} Advance},
  shorttitle = {Human Behavior Understanding for Video Surveillance},
  booktitle = {2010 {{IEEE International Conference}} on {{Systems}}, {{Man}} and {{Cybernetics}}},
  author = {{Xin Xu} and Tang, J. and {Xiaoming Liu} and {Xiaolong Zhang}},
  date = {2010-10},
  pages = {3867--3873},
  publisher = {{IEEE}},
  location = {{Istanbul, Turkey}},
  doi = {10.1109/ICSMC.2010.5641773},
  url = {http://ieeexplore.ieee.org/document/5641773/},
  urldate = {2024-01-30},
  abstract = {With the wide applications of video cameras in surveillance, video analysis technologies have attracted the attention from the researchers in computer vision field. In video analysis, human behavior recognition and understanding is an important research direction. By recognition and understanding the human behaviors, we can predict and recognize the happening of crimes and help to the police or other agencies to react immediately. In the past, large amount of intensive papers have been published on human behavior understanding in videos. Generally speaking, the procedure of human behavior understanding can be divided into the following stages: human segmentation and tracking, and human behavior recognition. In this paper, we provide a comprehensive survey of the recent development of all these stages. We will also discuss the difficulties in behavior understanding and identify possible future directions.},
  eventtitle = {2010 {{IEEE International Conference}} on {{Systems}}, {{Man}} and {{Cybernetics}} - {{SMC}}},
  isbn = {978-1-4244-6586-6},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/SFBMMFZR/Xin Xu 等 - 2010 - Human behavior understanding for video surveillanc.pdf}
}

@online{XsensProductsMovella,
  title = {Xsens {{Products}} | {{Movella}}.Com},
  url = {https://www.movella.com/products/xsens?utm_feeditemid=&utm_device=c&utm_term=xsens&utm_source=google&utm_medium=ppc&utm_campaign=&hsa_cam=15264159507&hsa_grp=133365416361&hsa_mt=e&hsa_src=g&hsa_ad=561667538299&hsa_acc=1306794700&hsa_net=adwords&hsa_kw=xsens&hsa_tgt=kwd-312964997959&hsa_ver=3&utm_feeditemid=&utm_device=c&utm_term=xsens&utm_source=google&utm_medium=ppc&utm_campaign=Brand+%7C+All+%7C+Search&hsa_cam=15264159507&hsa_grp=133365416361&hsa_mt=e&hsa_src=g&hsa_ad=561667538299&hsa_acc=1306794700&hsa_net=adwords&hsa_kw=xsens&hsa_tgt=kwd-312964997959&hsa_ver=3&gad_source=1&gclid=CjwKCAiA44OtBhAOEiwAj4gpObFI98Bl6j7pq9GzCYFqgLR54hFZfUk9yAS6xiXJNRQiSeH4N_JOGxoCIdAQAvD_BwE},
  urldate = {2024-01-12},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/IY4HXEBJ/xsens.html}
}

@book{YangZhongGuoYangLaoFuWuLanPiShu201220212022,
  title = {中国养老服务蓝皮书(2012—2021)},
  author = {杨, 燕绥},
  date = {2022-02-25},
  publisher = {{中国老年学和老年医学学会老龄金融分会}},
  location = {{北京}},
  keywords = {引用}
}

@article{yanReviewAssistiveStrategies2015,
  title = {Review of Assistive Strategies in Powered Lower-Limb Orthoses and Exoskeletons},
  author = {Yan, Tingfang and Cempini, Marco and Oddo, Calogero Maria and Vitiello, Nicola},
  date = {2015-02},
  journaltitle = {Robotics and Autonomous Systems},
  shortjournal = {Robotics and Autonomous Systems},
  volume = {64},
  pages = {120--136},
  issn = {09218890},
  doi = {10.1016/j.robot.2014.09.032},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889014002176},
  urldate = {2023-05-11},
  abstract = {Starting from the early research in the 1960s, especially in the last two decades, orthoses and exoskeletons have been significantly developed. They are designed in different architectures to assist their users’ movements. The research literature has been more prolific on lower-limb devices: a main reason is that they address a basic but fundamental motion task, walking. Leg exoskeletons are simpler to design, compared to upper-limb counterparts, but still have particular cognitive and physical requirements from the emerging human–robot interaction systems. In the state of the art, different control strategies and approaches can be easily found: it is still a challenge to develop an assistive strategy which makes the exoskeleton supply efficient and natural assistance. So, this paper aims to provide a systematic overview of the assistive strategies utilized by active locomotion–augmentation orthoses and exoskeletons. Based on the literature collected from Web of Science and Scopus, we have studied the main robotic devices with a focus on the way they are controlled to deliver assistance; the relevant validations are as well investigated, in particular experimentations with human in the loop. Finally current trends and major challenges in the development of an assistive strategy are concluded and discussed.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/I8PGN9PB/Yan 等 - 2015 - Review of assistive strategies in powered lower-li.pdf}
}

@article{yelnikClinicalGuideAssess1999,
  title = {A {{Clinical Guide}} to {{Assess}} the {{Role}} of {{Lower Limb Extensor Overactivity}} in {{Hemiplegic Gait Disorders}}},
  author = {Yelnik, A. and Albert, T. and Bonan, I. and Laffont, I.},
  date = {1999-03},
  journaltitle = {Stroke},
  shortjournal = {Stroke},
  volume = {30},
  number = {3},
  pages = {580--585},
  issn = {0039-2499, 1524-4628},
  doi = {10.1161/01.STR.30.3.580},
  url = {https://www.ahajournals.org/doi/10.1161/01.STR.30.3.580},
  urldate = {2022-06-16},
  abstract = {Background and Purpose—The aim of this study was to assess the role of knee and ankle extensor overactivity in the hemiplegic gait observed in stroke victims and to propose a clinical guide for selecting patients before treatment of a supposed disabling spasticity. Methods—A standardized physical examination procedure was performed in 135 consecutive stroke patients. All patients were able to walk without human assistance. The period after stroke ranged from 3 to 24 months (mean, 11.5Ϯ7.25 months). Spasticity was evaluated with the stroke victim in sitting position and during walking. Overactivity of the quadriceps was considered disabling when inducing inability to flex the knee during the swing phase despite adequate control of knee flexion in sitting and standing positions; overactivity of the triceps surae was considered to be disabling when heel strike was not possible despite good control of the ankle flexion in sitting position; triceps retraction was also considered. Results—Disabling overactivity was observed in 56 (41.5\%) patients: 11 times for the quadriceps femoris, 21 times for the triceps surae, and 21 times for both muscles. It was considered to be the main disorder impairing gait among only 16 (12\%) patients: 9 for the quadriceps alone, 3 for the triceps alone, and 4 for both. Sitting spasticity of the lower limb was not predictive of disabling overactivity during walking. Conclusions—Extensor muscle overactivity is one of the components of gait disorders in stroke patients. The difficulty in assessing spasticity and its real causal effect in gait disturbances are discussed. A clinical guide is proposed. (Stroke. 1999;30:580-585.)},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/3J8YX4R4/Yelnik 等。 - 1999 - A Clinical Guide to Assess the Role of Lower Limb .pdf}
}

@article{yoshiokaBiomechanicalAnalysisRelation2009,
  title = {Biomechanical Analysis of the Relation between Movement Time and Joint Moment Development during a Sit-to-Stand Task},
  author = {Yoshioka, Shinsuke and Nagano, Akinori and Hay, Dean C and Fukashiro, Senshi},
  date = {2009},
  journaltitle = {BioMedical Engineering OnLine},
  shortjournal = {BioMed Eng OnLine},
  volume = {8},
  number = {1},
  pages = {27},
  issn = {1475-925X},
  doi = {10.1186/1475-925X-8-27},
  url = {http://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-8-27},
  urldate = {2023-12-29},
  abstract = {Background: Slowness of movement is a factor that may cause a decrease of quality of daily life. Mobility in the elderly and people with movement impairments may be improved by increasing the quickness of fundamental locomotor tasks. Because it has not been revealed how much muscle strength is required to improve quickness, the purpose of this study was to reveal the relation between movement time and the required muscle strength in a sit to stand (STS) task. Previous research found that the sum of the peak hip and knee joint moments was relatively invariant throughout a range of movement patterns (Yoshioka et al., 2007, Biomedical Engineering Online 6:26). The sum of the peak hip and knee joint moment is an appropriate index to evaluate the muscle strength required for an STS task, since the effect of the movement pattern variation can be reduced, that is, the results can be evaluated purely from the viewpoint of the movement times. Therefore, the sum of the peak hip and knee joint moment was used as the index to indicate the required muscle strength. Methods: Experimental kinematics data were collected from 11 subjects. The time at which the vertical position of the right shoulder fell outside three standard deviations of the vertical positions during the static initial posture was regarded as the start time. The time at which the vertical position fell within three standard deviations of the vertical positions during static upright standing posture was regarded as the finish time. Each movement time of the experimental movements was linearly lengthened and shortened through post-processing. Combining the experimental procedure and the post-processing, movements having various movement patterns and a wide range of movement times were obtained. The joint moment and the static and inertial components of the joint moment were calculated with an inverse dynamics method. The static component reflects the gravitational and/or external forces, while the inertial component reflects the acceleration of the body. Results: The quantitative relation between the movement time and the sum of the peak hip and knee joint moments were obtained. As the STS movement time increased, the joint moments decreased exponentially and converged to the static component (1.51 \textasciitilde{} 1.54 N.m/kg). When the movement time was the longest (movement time: 7.0 seconds), the joint moments (1.57 N.m/kg) closely corresponded to the minimum of 1.53 N.m/kg as reported by Yoshioka et al.. Conclusion: The key findings of this study are as follows. (1) The minimum required joint moment for an STS task is essentially equivalent to the static component of the joint moment. (2) For fast and moderate speed movements (less than 2.5 seconds), joint moments increased exponentially as the movement speed increased. (3) For slow movements greater than 2.5 seconds, the joint moments were relatively constant. The results of this STS research has practical applications, especially in rehabilitations and exercise prescription where improved movement time is an intended target, since the required muscle strength can be quantitatively estimated.},
  langid = {english},
  keywords = {重要文章},
  file = {/Users/liurongkai/Zotero/storage/TB6CQJEE/Yoshioka 等 - 2009 - Biomechanical analysis of the relation between mov.pdf}
}

@article{YouHumanmachineSharedAutonomy2022,
  title = {Human-machine shared autonomy approach for non-full-time effective human decisions},
  author = {游, 诗艺 and 康, 宇 and 赵, 云波 and 张, 倩倩},
  date = {2022-12-01},
  journaltitle = {SCIENTIA SINICA Informationis},
  shortjournal = {Sci. Sin.-Inf.},
  volume = {52},
  number = {12},
  pages = {2165},
  issn = {1674-7267},
  doi = {10.1360/SSI-2022-0225},
  url = {https://engine.scichina.com/doi/10.1360/SSI-2022-0225},
  urldate = {2023-12-16},
  langid = {chinese},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/Q6GSCZI4/游 等 - 2022 - Human-machine shared autonomy approach for non-ful.pdf}
}

@article{youngPOMDPbasedStatisticalSpoken2012,
  title = {{{POMDP-based Statistical Spoken Dialogue Systems}}: A {{Review}}},
  author = {Young, Steve and Gasˇic, Milica and Thomson, Blaise and Williams, Jason D},
  date = {2012},
  journaltitle = {PROC IEEE},
  abstract = {Statistical dialogue systems are motivated by the need for a data-driven framework that reduces the cost of laboriously hand-crafting complex dialogue managers and that provides robustness against the errors created by speech recognisers operating in noisy environments. By including an explicit Bayesian model of uncertainty and by optimising the policy via a reward-driven process, partially observable Markov decision processes (POMDPs) provide such a framework. However, exact model representation and optimisation is computationally intractable. Hence, the practical application of POMDP-based systems requires efficient algorithms and carefully constructed approximations. This review article provides an overview of the current state of the art in the development of POMDP-based spoken dialogue systems.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/QIQ2X52D/Young 等 - 2012 - POMDP-based Statistical Spoken Dialogue Systems a.pdf}
}

@article{youngStateArtFuture2017,
  title = {State of the {{Art}} and {{Future Directions}} for {{Lower Limb Robotic Exoskeletons}}},
  author = {Young, Aaron J. and Ferris, Daniel P.},
  date = {2017-02},
  journaltitle = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
  shortjournal = {IEEE Trans. Neural Syst. Rehabil. Eng.},
  volume = {25},
  number = {2},
  pages = {171--182},
  issn = {1534-4320, 1558-0210},
  doi = {10.1109/TNSRE.2016.2521160},
  url = {https://ieeexplore.ieee.org/document/7393837/},
  urldate = {2023-12-16},
  abstract = {Research on robotic exoskeletons has rapidly expanded over the previous decade. Advances in robotic hardware and energy supplies have enabled viable prototypes for human testing. This review paper describes current lower limb robotic exoskeletons, with specific regard to common trends in the field. The preponderance of published literature lacks rigorous quantitative evaluations of exoskeleton performance, making it difficult to determine the disadvantages and drawbacks of many of the devices. We analyzed common approaches in exoskeleton design and the convergence, or lack thereof, with certain technologies. We focused on actuators, sensors, energy sources, materials, and control strategies. One of the largest hurdles to be overcome in exoskeleton research is the user interface and control. More intuitive and flexible user interfaces are needed to increase the success of robotic exoskeletons. In the last section, we discuss promising future solutions to the major hurdles in exoskeleton control. A number of emerging technologies could deliver substantial advantages to existing and future exoskeleton designs. We conclude with a listing of the advantages and disadvantages of the emerging technologies and discuss possible futures for the field.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/4QWCD49L/Young 和 Ferris - 2017 - State of the Art and Future Directions for Lower L.pdf}
}

@inproceedings{zanottoAdaptiveAssistasneededController2014a,
  title = {Adaptive Assist-as-Needed Controller to Improve Gait Symmetry in Robot-Assisted Gait Training},
  booktitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zanotto, Damiano and Stegall, Paul and Agrawal, Sunil K.},
  date = {2014},
  pages = {724--729},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2014.6906934},
  abstract = {This paper introduces the overall design of ALEX III, the third generation of Active Leg Exoskeletons developed by our group. ALEX III is the first treadmill-based rehabilitation robot featuring 12 actively controlled degrees of freedom (DOF): 4 at the pelvis and 4 at each leg. As a first application of the device, we present an adaptive controller aimed to improve gait symmetry in hemiparetic subjects. The controller continuously modulates the assistive force applied to the impaired leg, based on the outputs of kernel-based non-linear filters, which learn the movements of the healthy leg. To test the effectiveness of the controller, we induced asymmetry in the gait of three young healthy subjects adding ankle weights (2.3kg). Results on kinematic data showed that gait symmetry was recovered when the controller was active.},
  eventtitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  keywords = {Foot,Force,Hip,Joints,Knee,Legged locomotion,在读,引用,有价值},
  file = {/Users/liurongkai/Zotero/storage/PC5MSQ2L/Zanotto et al_2014_Adaptive assist-as-needed controller to improve gait symmetry in robot-assisted.pdf;/Users/liurongkai/Zotero/storage/766F56NS/6906934.html}
}

@article{zhangHumanintheloopOptimizationExoskeleton2017a,
  title = {Human-in-the-Loop Optimization of Exoskeleton Assistance during Walking},
  author = {Zhang, Juanjuan and Fiers, Pieter and Witte, Kirby A. and Jackson, Rachel W. and Poggensee, Katherine L. and Atkeson, Christopher G. and Collins, Steven H.},
  date = {2017-06-23},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {356},
  number = {6344},
  pages = {1280--1284},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aal5054},
  url = {https://www.science.org/doi/10.1126/science.aal5054},
  urldate = {2023-12-16},
  abstract = {Optimum human input                            Exoskeletons can be used to augment human abilities—for example, to lift very heavy loads or to provide greater endurance. For each user, though, a device will need to be adjusted for optimum effect, which can be time-consuming. Zhang               et al.               show that the human can be included in the optimization process, with real-time adaptation of an ankle exoskeleton (see the Perspective by Malcolm               et al.               ). By using indirect calorimetry to measure metabolic rates, the authors were able to adjust the torque provided by the device while users were walking, running, and carrying a load.                                         Science               , this issue p.               1280               ; see also p.               1230                        ,              An exoskeleton control system can optimize itself by measuring and minimizing human energy use during walking.           ,              Exoskeletons and active prostheses promise to enhance human mobility, but few have succeeded. Optimizing device characteristics on the basis of measured human performance could lead to improved designs. We have developed a method for identifying the exoskeleton assistance that minimizes human energy cost during walking. Optimized torque patterns from an exoskeleton worn on one ankle reduced metabolic energy consumption by 24.2 ± 7.4\% compared to no torque. The approach was effective with exoskeletons worn on one or both ankles, during a variety of walking conditions, during running, and when optimizing muscle activity. Finding a good generic assistance pattern, customizing it to individual needs, and helping users learn to take advantage of the device all contributed to improved economy. Optimization methods with these features can substantially improve performance.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/D76YWU5L/Zhang 等 - 2017 - Human-in-the-loop optimization of exoskeleton assi.pdf}
}

@inproceedings{zhangHumanRobotSharedControl2022,
  title = {Human-{{Robot Shared Control}} for {{Surgical Robot Based}} on {{Context-Aware Sim-to-Real Adaptation}}},
  booktitle = {2022 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Zhang, Dandan and Wu, Zicong and Chen, Junhong and Zhu, Ruiqi and Munawar, Adnan and Xiao, Bo and Guan, Yuan and Su, Hang and Hong, Wuzhou and Guo, Yao and Fischer, Gregory S. and Lo, Benny and Yang, Guang-Zhong},
  date = {2022-05-23},
  pages = {7694--7700},
  publisher = {{IEEE}},
  location = {{Philadelphia, PA, USA}},
  doi = {10.1109/ICRA46639.2022.9812379},
  url = {https://ieeexplore.ieee.org/document/9812379/},
  urldate = {2024-02-01},
  abstract = {Human-robot shared control, which integrates the advantages of both humans and robots, is an effective approach to facilitate efficient surgical operation. Learning from demonstration (LfD) techniques can be used to automate some of the surgical subtasks for the construction of the shared control framework. However, a sufficient amount of data is required for the robot to learn the manoeuvres. Using a surgical simulator to collect data is a less resource-demanding approach. With sim-to-real adaptation, the manoeuvres learned from a simulator can be transferred to a physical robot. To this end, we propose a sim-to-real adaptation method to construct a humanrobot shared control framework for robotic surgery.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-72819-681-7},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/UXAPP93Z/Zhang 等 - 2022 - Human-Robot Shared Control for Surgical Robot Base.pdf}
}

@thesis{ZhangMianXiangRenJiXuGuanJueCeDeHunHeZhiNengFangFaYanJiu2021,
  type = {博士},
  title = {面向人机序贯决策的混合智能方法研究},
  author = {张, 倩倩},
  editora = {康, 宇 and 赵, 云波},
  editoratype = {collaborator},
  date = {2021},
  institution = {{中国科学技术大学}},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2023&filename=1022035052.nh&v=},
  abstract = {随着人工智能技术的发展,机器智能得到不断的提高,随之而来的则是机器智能得以在各行各业应用发展。在此进程中,不可避免的会遇到机器自主性不足以解决本身该由人类解决或者人类必须参与决策的情况,考虑此种场景下人类智能和机器智能共同作用的决策问题则显得尤为重要和有意义。更具体地,序贯决策问题作为一类具有时序性和多阶段性的动态决策问题,其发展与当下人工智能时代下的工程应用、生产生活等领域息息相关。人的作用体现在序贯决策问题的两方面,一则,人本身属于序贯决策问题模型中的一部分,即该类问题是离不开人的如微创外科手术等;二则,人的相关信息不体现在序贯决策问题模型中,而是因人独特的认知能力使得其可以出现在问题的求解办法中,达到改善问题求解的目的如人对机器搜救系统的引导等,本文将上述两种场景统称为“人机序贯决策问题。针对人机序贯决策问题,由于人类智能和机器智能本质上的区别,数学表达上的巨大差异,使得人和机器共同作用于问题求解时,不可避免的因为协调原因造成决策质量不高甚至决策失误的现象。然而直接应用传统人机系统的控制算法不能有效处理这些问题,从而引起机器代理失效,人力浪费,甚至还会造成决策系统性能恶化甚至崩溃。因此,亟需设计有效的人机混合智能算法来解决这些问题。本文以人机序贯决策问题为研究对象,围绕人机混合智能控制中的决策权限划分、介入控制触发切换时机和共享控制混合人机决策动作程度三个问题展开研究,旨在提出有效的人机混合智能算法来改善提升人机序贯决策问题的求解。本文的研究工作主要包括以下几个方面:1.提出了基于强化学习方法的人机混合智能控制框架。通过将机器代理的决策和人类的决策以可信性和安全性为评价指标进行仲裁选择,以确定更优的待执行决策动作。同时考虑了基于模型的强化学习子系统和基于无模型的强化学习子系统,为适应广泛的序贯决策应用场景提供了更多可能。2.针对人机序贯决策中的介入控制问题,提出了自主性及自主性边界的概念,通过将自主性边界的求解形式化为与任务目标相关的常规优化问题进行讨论判定,优化介入控制的控制方案和算法,实现人机序贯决策中人介入机器场景和机器介入人场景下的决策性能提升。3.针对人机序贯决策中的共享控制问题,提出了基于自主性边界的混合参数优化设计方案,通过自适应调节混合参数大小直接影响最终待执行动作的生成。考虑了人机动作的融合程度,使得最优解在人的动作空间和机器的动作空间所共同张成的扩展空间中出现,为决策质量的提升提供了扩展空间。4.针对介入控制和共享控制中所估计的自主性边界值可能存在单值估计不准确的问题,提出了基于贝叶斯神经网络的不确定性估计办法,获得自主性边界的概率分布信息并用于决策动作生成,利用自主性边界的不确定性优化设计人机混合智能算法,既使得决策动作的优化存在更多选择,也更加符合人们对决策边界的模糊性思考。综上所述,本文面向人机序贯决策对混合智能算法所面临的问题进行了系统性的研究,创新性地提出了对应的解决方案,推动了人机序贯决策求解和混合智能算法的进一步发展。},
  langid = {chinese},
  keywords = {Arbitration mechanism,Autonomous boundary,Hybrid intelligent algo-rithm,Reinforcement learning,Shared control,Traded control,人机序贯决策,介入控制,仲裁机制,共享控制,引用,强化学习 Human-machine sequential decision-making,混合智能算法,自主性边界},
  file = {/Users/liurongkai/Zotero/storage/TJEEINRD/面向人机序贯决策的混合智能方法研究_张倩倩.caj}
}

@inproceedings{zhangUnderstandingInteractionsSmart2022,
  title = {Understanding {{Interactions}} for {{Smart Wheelchair Navigation}} in {{Crowds}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zhang, Bingqing and Barbareschi, Giulia and Ramirez Herrera, Roxana and Carlson, Tom and Holloway, Catherine},
  date = {2022-04-29},
  pages = {1--16},
  publisher = {{ACM}},
  location = {{New Orleans LA USA}},
  doi = {10.1145/3491102.3502085},
  url = {https://dl.acm.org/doi/10.1145/3491102.3502085},
  urldate = {2022-12-16},
  abstract = {Shared control wheelchairs can help users to navigate through crowds by enabling the person to drive the wheelchair while receiving support in avoiding pedestrians. To date, research into shared control has largely overlooked the perspectives of wheelchair users. In this paper, we present two studies that aim to address this gap. The frst study involved a series of semi-structured interviews with wheelchair users which highlighted the presence of two diferent interaction loops, one between the user and the wheelchair and a second one between the user and the crowd. In the second study we engaged with wheelchair users and designers to co-design appropriate feedback loops for future shared control interaction interfaces.},
  eventtitle = {{{CHI}} '22: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-9157-3},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TSMGYUHP/chi22_final.pdf}
}

@article{ZhaoQianTanKongZhiZhongDeGongXiangXinXiHeGongXiangZiZhu2021,
  title = {浅谈控制中的共享信息和共享自主},
  author = {赵, 云波 and 康, 宇 and 朱, 进},
  date = {2021-07},
  journaltitle = {系统与控制纵横},
  volume = {8},
  number = {1},
  pages = {66--72},
  url = {http://staff.ustc.edu.cn/~ybzhao1/assets/pdf/2021-%E6%B5%85%E8%B0%88%E6%8E%A7%E5%88%B6%E4%B8%AD%E7%9A%84%E5%85%B1%E4%BA%AB%E4%BF%A1%E6%81%AF%E5%92%8C%E5%85%B1%E4%BA%AB%E8%87%AA%E4%B8%BB.pdf},
  urldate = {2023-06-08},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/G7YBRW48/2021-浅谈控制中的共享信息和共享自主.pdf}
}

@inproceedings{zhengEEGbasedEmotionClassification2014,
  title = {{{EEG-based}} Emotion Classification Using Deep Belief Networks},
  booktitle = {2014 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})},
  author = {Zheng, Wei-Long and Zhu, Jia-Yi and Peng, Yong and Lu, Bao-Liang},
  date = {2014-07},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Chengdu, China}},
  doi = {10.1109/ICME.2014.6890166},
  url = {http://ieeexplore.ieee.org/document/6890166/},
  urldate = {2024-01-07},
  abstract = {In recent years, there are many great successes in using deep architectures for unsupervised feature learning from data, especially for images and speech. In this paper, we introduce recent advanced deep learning models to classify two emotional categories (positive and negative) from EEG data. We train a deep belief network (DBN) with differential entropy features extracted from multichannel EEG as input. A hidden markov model (HMM) is integrated to accurately capture a more reliable emotional stage switching. We also compare the performance of the deep models to KNN, SVM and Graph regularized Extreme Learning Machine (GELM). The average accuracies of DBN-HMM, DBN, GELM, SVM, and KNN in our experiments are 87.62\%, 86.91\%, 85.67\%, 84.08\%, and 69.66\%, respectively. Our experimental results show that the DBN and DBN-HMM models improve the accuracy of EEGbased emotion classification in comparison with the state-ofthe-art methods.},
  eventtitle = {2014 {{IEEE International Conference}} on {{Multimedia}} and {{Expo}} ({{ICME}})},
  isbn = {978-1-4799-4761-4},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/YZCUAPG3/Zheng 等 - 2014 - EEG-based emotion classification using deep belief.pdf}
}

@online{zhengPOMDPModelLearning2018a,
  title = {{{POMDP Model Learning}} for {{Human Robot Collaboration}}},
  author = {Zheng, Wei and Wu, Bo and Lin, Hai},
  date = {2018-03-29},
  eprint = {1803.11300},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1803.11300},
  urldate = {2024-01-30},
  abstract = {Recent years have seen human robot collaboration (HRC) quickly emerged as a hot research area at the intersection of control, robotics, and psychology. While most of the existing work in HRC focused on either low-level human-aware motion planning or HRC interface design, we are particularly interested in a formal design of HRC with respect to high-level complex missions, where it is of critical importance to obtain an accurate and meanwhile tractable human model. Instead of assuming the human model is given, we ask whether it is reasonable to learn human models from observed perception data, such as the gesture, eye movements, head motions of the human in concern. As our initial step, we adopt a partially observable Markov decision process (POMDP) model in this work as mounting evidences have suggested Markovian properties of human behaviors from psychology studies. In addition, POMDP provides a general modeling framework for sequential decision making where states are hidden and actions have stochastic outcomes. Distinct from the majority of POMDP model learning literature, we do not assume that the state, the transition structure or the bound of the number of states in POMDP model is given. Instead, we use a Bayesian non-parametric learning approach to decide the potential human states from data. Then we adopt an approach inspired by probably approximately correct (PAC) learning to obtain not only an estimation of the transition probability but also a confidence interval associated to the estimation. Then, the performance of applying the control policy derived from the estimated model is guaranteed to be sufficiently close to the true model. Finally, data collected from a driver-assistance test-bed are used to train the model, which illustrates the effectiveness of the proposed learning method.},
  pubstate = {preprint},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Robotics,引用},
  file = {/Users/liurongkai/Zotero/storage/ZWDNNCXM/Zheng et al_2018_POMDP Model Learning for Human Robot Collaboration.pdf;/Users/liurongkai/Zotero/storage/UTGHJWSK/1803.html}
}

@article{zhengSurfaceElectromyographyNatural2022,
  title = {Surface {{Electromyography}} as a {{Natural Human}}–{{Machine Interface}}: {{A Review}}},
  shorttitle = {Surface {{Electromyography}} as a {{Natural Human}}–{{Machine Interface}}},
  author = {Zheng, Mingde and Crouch, Michael S. and Eggleston, Michael S.},
  date = {2022-05},
  journaltitle = {IEEE Sensors Journal},
  volume = {22},
  number = {10},
  pages = {9198--9214},
  issn = {1558-1748},
  doi = {10.1109/JSEN.2022.3165988},
  abstract = {Surface electromyography (sEMG) is a non-invasive method of measuring neuromuscular potentials generated when the brain instructs the body to perform both fine and coarse locomotion. This technique has seen extensive investigation over the last two decades, with significant advances in both the hardware and signal processing methods used to collect and analyze sEMG signals. While early work focused mainly on medical applications, there has been growing interest in utilizing sEMG as a sensing modality to enable next-generation, high-bandwidth, and natural human-machine interfaces. In the first part of this review, we briefly overview the human skeletomuscular physiology that gives rise to sEMG signals followed by a review of developments in sEMG acquisition hardware. Special attention is paid towards the fidelity of these devices as well as form factor, as recent advances have pushed the limits of user comfort and high-bandwidth acquisition. In the second half of the article, we explore work quantifying the information content of natural human gestures and then review the various signal processing and machine learning methods developed to extract information in sEMG signals. Finally, we discuss the future outlook in this field, highlighting the key gaps in current methods to enable seamless natural interactions between humans and machines.},
  eventtitle = {{{IEEE Sensors Journal}}},
  keywords = {Data analytics,Electrodes,Electromyography,Hardware,human-machine interface,machine learning,Muscles,myoelectrics,natural interface,Optical fiber sensors,Sensors,Skin,surface electromyography,引用},
  file = {/Users/liurongkai/Zotero/storage/PZ5MY59V/Zheng 等 - 2022 - Surface Electromyography as a Natural Human–Machin.pdf;/Users/liurongkai/Zotero/storage/LBYHKEKF/9751758.html}
}

@article{zhongGaitSymmetryEnhancement2022,
  title = {Toward {{Gait Symmetry Enhancement}} via a {{Cable-Driven Exoskeleton Powered}} by {{Series Elastic Actuators}}},
  author = {Zhong, Bin and Guo, Kaiqi and Yu, Haoyong and Zhang, Mingming},
  date = {2022-04},
  journaltitle = {IEEE Robotics and Automation Letters},
  volume = {7},
  number = {2},
  pages = {786--793},
  issn = {2377-3766},
  doi = {10.1109/LRA.2021.3130639},
  abstract = {Gait rehabilitation is essential for chronic stroke patients to regain independent walking ability and quality of life, of which symmetry is regarded as a gold standard of gait quality. In this letter, a cable-driven lower limb exoskeleton powered by series elastic actuators (SEAs) has been developed, and a generalized gait-phase-based assistive strategy has been presented to enhance the gait symmetry of chronic stroke patients in the future. This strategy features a parameterized assistive force generation method that allows individuals customization to achieve more synchronized assistance with their walking gait patterns. A compliant human-robot interaction is guaranteed by SEA, and the exoskeleton exhibits low passive impedance and good transparency. The proposed assistive strategy was evaluated with five able-bodied subjects walking with the assistance from exoskeleton while adding artificial impairments to mimic a pathological gait with deficits (i.e., reduced knee flexion and foot-drop). Experimental results proved its efficacy in enhancing temporal walking gait symmetry to the levels comparable to participants’ normal gait.},
  eventtitle = {{{IEEE Robotics}} and {{Automation Letters}}},
  keywords = {Actuators,cable-driven,Exoskeletons,Force,Gait symmetry enhancement,Knee,Legged locomotion,lower limb exoskeleton,Springs,Stroke (medical condition),stroke rehabilitation,walking assistance,引用},
  file = {/Users/liurongkai/Zotero/storage/2L99GXFN/Zhong et al_2022_Toward Gait Symmetry Enhancement via a Cable-Driven Exoskeleton Powered by.pdf;/Users/liurongkai/Zotero/storage/6NS5RH24/Zhong 等。 - 2022 - Toward Gait Symmetry Enhancement via a Cable-Drive.pdf;/Users/liurongkai/Zotero/storage/FL9NABEG/9627581.html}
}

@online{ZhongGuoCanJiRenFuLiJiJinHuiHuoJuan600WanYuanBangFuPinKunZhiCanRenShi_GunDongXinWen_ZhongGuoZhengFuWanga,
  title = {中国残疾人福利基金会 获捐600万元帮扶贫困肢残人士\_滚动新闻\_中国政府网},
  url = {https://www.gov.cn/xinwen/2018-06/01/content_5295524.htm},
  urldate = {2024-03-08},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/B2ULUCYE/content_5295524.html}
}

@online{ZhongGuoZhiZao2025,
  title = {中国制造2025},
  url = {https://www.gov.cn/zhuanti/2016/MadeinChina2025-plan/},
  urldate = {2023-12-16},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/TSWTT2KA/MadeinChina2025-plan.html}
}

@article{zhouNonInvasiveHumanMachineInterface2022,
  title = {Non-{{Invasive Human-Machine Interface}} ({{HMI}}) {{Systems With Hybrid On-Body Sensors}} for {{Controlling Upper-Limb Prosthesis}}: {{A Review}}},
  shorttitle = {Non-{{Invasive Human-Machine Interface}} ({{HMI}}) {{Systems With Hybrid On-Body Sensors}} for {{Controlling Upper-Limb Prosthesis}}},
  author = {Zhou, Hao and Alici, Gursel},
  date = {2022-06},
  journaltitle = {IEEE Sensors Journal},
  volume = {22},
  number = {11},
  pages = {10292--10307},
  issn = {1558-1748},
  doi = {10.1109/JSEN.2022.3169492},
  abstract = {In this work, we present a systematic review on non-invasive HMIs employing hybrid wearable sensor modalities for recognition of upper limb intentions. Different combinations of the sensors are investigated. As sEMG is dominant in the applications of externally powered prosthetic hands, it is involved in most hybrid sensor combinations. The combined use of sEMG and IMU is most studied in the literature as IMU is easy to be integrated. Though limited, the investigation on other hybrid modalities has been drawing more and more research attention and efforts, especially those with FMG and NIRS. For all the reported hybrid sensors, it is verified that this strategy can enrich the information of user intention and help the pattern recognition and/or intensity regulation of robotic hand/arm prosthesis. Though it is the trend, the development of these hybrid-sensor-based HMIs are still at the preliminary stage. More dedicated sensor fusion models and system architectures as well as new hybrid features and algorithms need to be developed to make the best use of each sensing modality’s strength to achieve robust and stable user intention recognition, which is essential for the progress and user acceptance of upper limb prosthesis.},
  eventtitle = {{{IEEE Sensors Journal}}},
  keywords = {adaptive learning,Biosensors,Electroencephalography,HMI,Human-machine-interface,hybrid modalities,multi-modal,Muscles,Robot sensing systems,robustness,Robustness,sEMG + FMG,sEMG + MMG,sEMG + NIRS,sEMG + SMG,sensor fusion,Sensor systems,Sensors,upper limb prosthesis,引用},
  file = {/Users/liurongkai/Zotero/storage/ZA2XE98U/Zhou 和 Alici - 2022 - Non-Invasive Human-Machine Interface (HMI) Systems.pdf;/Users/liurongkai/Zotero/storage/7NEZ44Y2/9761870.html}
}

@article{zuoOnlineMonitoringHuman2023,
  title = {Online {{Monitoring}} for {{Human Sit-to-Stand Movement Based}} on {{Karush-Kuhn-Tucker Optimized Zonotope Set-Membership Filter}}},
  author = {Zuo, Jie and Yang, Bo and Xiao, Xiling and Sun, Chengcheng and Huang, Jian},
  date = {2023},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  shortjournal = {IEEE Trans. Biomed. Eng.},
  pages = {1--12},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2023.3317890},
  url = {https://ieeexplore.ieee.org/document/10258353/},
  urldate = {2023-12-01},
  abstract = {As the global aging population continues to grow, there has been a significant increase in the number of fallrelated injuries among the elderly, primarily due to reduced muscle strength and balance control, especially during sit-to-stand (STS) movements. Intelligent wearable robots have the potential to provide fall prevention assistance to individuals at risk, but an accurate and timely assessment of human movement stability is essential. This paper presents a fall prediction algorithm for STS movements based on the Karush-Kuhn-Tucker (KKT) optimized zonotope set-membership filter (KKT-ZSMF), enabling real-time assessment of human stability. To quantify the feasible stability region of human STS movement, a mathematical model is proposed based on dynamic stability theory. Additionally, an online fall-prediction approach is developed, utilizing the zonotope setmembership filter to iteratively update the set that represents the instantaneous stability region. The approach incorporates a KKT optimization algorithm to compute the optimal convex hull, thereby enhancing the accuracy and efficiency of the set-membership filter. Experimental validation is conducted with the participation of 13 subjects including 5 elderly subjects, comparing the performance of the proposed KKT-ZSMF algorithm with other relevant methods. The results confirm the accuracy and real-time performance of the KKT-ZSMF algorithm for predicting human STS movement stability, achieving an overall prediction accuracy of 93.49\% and a runtime of no more than 7.91 ms. These findings demonstrate the suitability of the algorithm for fall prevention assistance in daily activities.},
  langid = {english},
  keywords = {引用},
  file = {/Users/liurongkai/Zotero/storage/DT9QYGBA/Zuo 等 - 2023 - Online Monitoring for Human Sit-to-Stand Movement .pdf}
}
